{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36cc7f5",
   "metadata": {},
   "source": [
    "Notebook que permite generar los datos desde un notebook, por ejemplo, en Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bbfcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entorno detectado: Local\n",
      "üìÅ Ruta base: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\n",
      "üìÅ Ruta datasets: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\n",
      "üìÅ Ruta modelos: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\models\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import IPython\n",
    "\n",
    "def detectar_entorno_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def configurar_rutas(base_local=None, base_colab=\"/content/drive/MyDrive/ia_thermal_colab\", verbose=True):\n",
    "    IN_COLAB = detectar_entorno_colab()\n",
    "\n",
    "    if IN_COLAB:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        base_path = Path(base_colab)\n",
    "    else:\n",
    "        # ‚ö†Ô∏è Si no se pasa base_local, usar el directorio del notebook\n",
    "        if base_local is None:\n",
    "            base_path = Path.cwd()\n",
    "        else:\n",
    "            base_path = Path(base_local).expanduser().resolve()\n",
    "\n",
    "    datasets_path = base_path / \"datasets\"\n",
    "    models_path = base_path / \"models\"\n",
    "    datasets_path.mkdir(parents=True, exist_ok=True)\n",
    "    models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"‚úÖ Entorno detectado:\", \"Colab\" if IN_COLAB else \"Local\")\n",
    "        print(\"üìÅ Ruta base:\", base_path)\n",
    "        print(\"üìÅ Ruta datasets:\", datasets_path)\n",
    "        print(\"üìÅ Ruta modelos:\", models_path)\n",
    "\n",
    "    return IN_COLAB, base_path, datasets_path, models_path\n",
    "\n",
    "# üü¢ Llamada principal\n",
    "IN_COLAB, BASE_PATH, DATASETS_PATH, MODELS_PATH = configurar_rutas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baea8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Par√°metros del repositorio\n",
    "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia si usas otro repo\n",
    "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "CLONE_PATH = BASE_PATH / REPO_NAME  # Usamos Path (de pathlib)\n",
    "\n",
    "def clonar_repo_si_no_existe(repo_url: str, clone_path: Path):\n",
    "    if not clone_path.exists():\n",
    "        print(f\"üì• Clonando repositorio en {clone_path}...\")\n",
    "        os.system(f\"git clone {repo_url} {clone_path}\")\n",
    "    else:\n",
    "        print(f\"üìÇ Repositorio ya clonado en: {clone_path}\")\n",
    "\n",
    "def instalar_requirements(clone_path: Path):\n",
    "    req_path = clone_path / \"requirements.txt\"\n",
    "    if req_path.exists():\n",
    "        print(\"üì¶ Instalando dependencias desde requirements.txt...\")\n",
    "        os.system(f\"pip install -r {req_path}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No se encontr√≥ requirements.txt en el repositorio.\")\n",
    "\n",
    "def reiniciar_entorno_colab():\n",
    "    print(\"üîÑ Reiniciando entorno para aplicar los cambios...\")\n",
    "    display(IPython.display.Javascript('''google.colab.restartRuntime()'''))\n",
    "\n",
    "# üß™ Ejecutar solo en Colab\n",
    "if IN_COLAB:\n",
    "    clonar_repo_si_no_existe(GIT_REPO_URL, CLONE_PATH)\n",
    "    instalar_requirements(CLONE_PATH)\n",
    "    reiniciar_entorno_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dee9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as est√°ndar\n",
    "import os, sys, time, json, platform\n",
    "from datetime import datetime\n",
    "from typing import Sequence, Union, Optional\n",
    "\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# NumPy y ciencia de datos\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch y entrenamiento\n",
    "import torch\n",
    "from torch import nn, amp\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch._dynamo\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# Optimizaci√≥n\n",
    "import optuna\n",
    "\n",
    "# A√±adir rutas del proyecto (de forma portable)\n",
    "sys.path.append(str(BASE_PATH))\n",
    "sys.path.append(str(BASE_PATH / \"ia_thermal\"))\n",
    "sys.path.append(str(BASE_PATH / \"ia_thermal\" / \"ismaelgallo\"))\n",
    "sys.path.append(str(BASE_PATH.parent))\n",
    "\n",
    "# M√≥dulos propios del proyecto\n",
    "from architectures.convlstm import *\n",
    "from Dataset_Class_convlstm import *\n",
    "from plot_functions import *\n",
    "from Physics_Loss import *\n",
    "from utils import *\n",
    "from scripts.PCB_solver_tr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96214bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Montar Google Drive y configurar rutas en Colab\n",
    "def mount_drive():\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    except ImportError:\n",
    "        print(\"No se detecta entorno Colab. Aseg√∫rate de montar tu directorio manualmente si usas otro entorno.\")\n",
    "\n",
    "mount_drive()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajusta la ruta al directorio de scripts si es necesario\n",
    "scripts_dir = Path('scripts').resolve()\n",
    "if scripts_dir.exists():\n",
    "    sys.path.append(str(scripts_dir))\n",
    "\n",
    "# Directorio en MyDrive para guardar datasets\n",
    "drive_root = Path('/content/drive/MyDrive')\n",
    "datasets_dir = drive_root / 'datasets'\n",
    "datasets_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÇ Guardando datasets en: {datasets_dir}\")\n",
    "\n",
    "# %%\n",
    "# # Importar m√≥dulos del proyecto\n",
    "# from PCB_solver_tr import PCB_case_2\n",
    "# from Dataset_Class_convlstm import PCBDataset_convlstm\n",
    "\n",
    "# %%\n",
    "# Par√°metros de generaci√≥n\n",
    "torch.manual_seed(0)\n",
    "numpy_seed = np.random.seed(0)\n",
    "solver = 'transient'  # 'steady' o 'transient'\n",
    "n_train = 2500\n",
    "n_validation = 500\n",
    "n_test = 50\n",
    "n_data = n_train + n_test + n_validation\n",
    "\n",
    "time_sim = 500\n",
    "dt = 1\n",
    "T_init = 298.0\n",
    "nodes_side = 13\n",
    "\n",
    "# √çndices de partici√≥n\n",
    "eval_slice = slice(n_test + n_train, n_data)\n",
    "train_slice = slice(n_test, n_test + n_train)\n",
    "test_slice  = slice(0, n_test)\n",
    "\n",
    "# %%\n",
    "def generate_unique_cases(n_samples):\n",
    "    seen = set()\n",
    "    Q_list, T_int_list, T_env_list = [], [], []\n",
    "    while len(Q_list) < n_samples:\n",
    "        Q = tuple(np.random.uniform(0.5, 1.5, 4).round(6))\n",
    "        T_int = tuple(np.random.uniform(270, 320, 4).round(2))\n",
    "        T_env = round(float(np.random.uniform(270, 320)), 2)\n",
    "        key = Q + T_int + (T_env,)\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            Q_list.append(Q)\n",
    "            T_int_list.append(T_int)\n",
    "            T_env_list.append(T_env)\n",
    "    return np.array(Q_list), np.array(T_int_list), np.array(T_env_list)\n",
    "\n",
    "Q_rand, T_int_rand, T_env_rand = generate_unique_cases(n_data)\n",
    "\n",
    "# %%\n",
    "# Generaci√≥n de secuencias de entrada y salida\n",
    "time_start = time.time()\n",
    "input_seq, output_seq = [], []\n",
    "for i in range(n_data):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Generando caso {i}/{n_data}, tiempo: {time.time() - time_start:.1f}s\")\n",
    "    T_sim, *_ = PCB_case_2(\n",
    "        solver=solver, display=False, time=time_sim, dt=dt, T_init=T_init,\n",
    "        Q_heaters=Q_rand[i], T_interfaces=T_int_rand[i], Tenv=T_env_rand[i]\n",
    "    )\n",
    "    T_sim = T_sim.reshape(-1, nodes_side, nodes_side).astype(np.float32)\n",
    "    output_seq.append(T_sim)\n",
    "\n",
    "    seq_len = T_sim.shape[0]\n",
    "    case_inputs = []\n",
    "    for t in range(seq_len):\n",
    "        T_map = np.zeros((nodes_side, nodes_side), dtype=np.float32)\n",
    "        Q_map = np.zeros((nodes_side, nodes_side), dtype=np.float32)\n",
    "        T_env_map = np.full((nodes_side, nodes_side), T_env_rand[i], dtype=np.float32)\n",
    "        T_map[0,0], T_map[0,-1], T_map[-1,-1], T_map[-1,0] = T_int_rand[i]\n",
    "        Q_map[6,3], Q_map[3,6], Q_map[9,3], Q_map[9,9] = Q_rand[i]\n",
    "        T_prev = np.full((nodes_side, nodes_side), T_init, dtype=np.float32) if t == 0 else output_seq[-1][t-1]\n",
    "        case_inputs.append(np.stack([T_map, Q_map, T_env_map, T_prev], axis=0))\n",
    "    input_seq.append(np.stack(case_inputs, axis=0))\n",
    "print(f\"Tiempo generaci√≥n datos: {time.time() - time_start:.1f}s\")\n",
    "\n",
    "# %%\n",
    "# Convertir a tensores y crear datasets\n",
    "a = np.array(input_seq, dtype=np.float32)\n",
    "b = np.array(output_seq, dtype=np.float32)\n",
    "stats = {\n",
    "    'T_int_mean': T_int_rand.mean(), 'T_int_std': T_int_rand.std(),\n",
    "    'Q_mean': Q_rand.mean(),         'Q_std': Q_rand.std(),\n",
    "    'T_env_mean': T_env_rand.mean(),  'T_env_std': T_env_rand.std(),\n",
    "    'out_mean': b.mean(),            'out_std': b.std()\n",
    "}\n",
    "Tensor_in = torch.tensor(a)\n",
    "Tensor_out = torch.tensor(b)\n",
    "\n",
    "def make_dataset(idx):\n",
    "    return PCBDataset_convlstm(\n",
    "        T_interfaces=Tensor_in[idx,:,0], Q_heaters=Tensor_in[idx,:,1],\n",
    "        T_env=Tensor_in[idx,:,2],       T_outputs=Tensor_out[idx],\n",
    "        T_interfaces_mean=stats['T_int_mean'], T_interfaces_std=stats['T_int_std'],\n",
    "        Q_heaters_mean=stats['Q_mean'],         Q_heaters_std=stats['Q_std'],\n",
    "        T_env_mean=stats['T_env_mean'],         T_env_std=stats['T_env_std'],\n",
    "        T_outputs_mean=stats['out_mean'],       T_outputs_std=stats['out_std'],\n",
    "        return_bc=True\n",
    "    )\n",
    "\n",
    "# Crear splits\n",
    "dataset_train = make_dataset(train_slice)\n",
    "dataset_val   = make_dataset(eval_slice)\n",
    "dataset_test  = make_dataset(test_slice)\n",
    "\n",
    "# %%\n",
    "# Guardar datasets en MyDrive\n",
    "time_save = time.time()\n",
    "for split, ds in [('train', dataset_train), ('val', dataset_val), ('test', dataset_test), ('full', make_dataset(slice(None)))]:\n",
    "    file = datasets_dir / f\"PCB_convlstm_phy_6ch_{solver}_dataset_{split}.pth\"\n",
    "    torch.save(ds, file)\n",
    "    print(f\"‚úÖ Guardado '{file.name}' en '{file}' ({len(ds)} muestras)\")\n",
    "print(f\"Tiempo total guardado: {time.time() - time_save:.1f}s\")\n",
    "\n",
    "# %%\n",
    "print(\"¬°Dataset listo para usar en el notebook desde MyDrive!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismael_minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
