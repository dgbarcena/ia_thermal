{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d95600b",
      "metadata": {
        "id": "2d95600b"
      },
      "source": [
        "# Convolutional LSTM One To One Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70aa002e",
      "metadata": {
        "id": "70aa002e"
      },
      "source": [
        "Implementing a Convolutional LSTM with 6 entry channels being them `[T_int, Q_heat, T_env, T_prev, mask_interfaces, mask_heaters]`, all in shape `[T, 13, 13]`. It predices the full `T` sequence of the system"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "868ff05f",
      "metadata": {
        "id": "868ff05f"
      },
      "source": [
        "## Previous"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fd24f5",
      "metadata": {
        "id": "66fd24f5"
      },
      "source": [
        "\n",
        "Esta celda detecta si el c√≥digo se ejecuta en **Google Colab** o localmente, configura rutas base para guardar datasets y modelos, y crea los directorios necesarios si no existen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5fd7e198",
      "metadata": {
        "id": "5fd7e198",
        "outputId": "83cc4f07-01c0-49c1-dec0-976363cb5419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Entorno detectado: Colab\n",
            "üìÅ Ruta base: /content/drive/MyDrive/ia_thermal_colab\n",
            "üìÅ Ruta datasets: /content/drive/MyDrive/ia_thermal_colab/datasets\n",
            "üìÅ Ruta modelos: /content/drive/MyDrive/ia_thermal_colab/models\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import IPython\n",
        "\n",
        "def detectar_entorno_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "def configurar_rutas(base_local=None, base_colab=\"/content/drive/MyDrive/ia_thermal_colab\", verbose=True):\n",
        "    IN_COLAB = detectar_entorno_colab()\n",
        "\n",
        "    if IN_COLAB:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        base_path = Path(base_colab)\n",
        "    else:\n",
        "        # ‚ö†Ô∏è Si no se pasa base_local, usar el directorio del notebook\n",
        "        if base_local is None:\n",
        "            base_path = Path.cwd()\n",
        "        else:\n",
        "            base_path = Path(base_local).expanduser().resolve()\n",
        "\n",
        "    datasets_path = base_path / \"datasets\"\n",
        "    models_path = base_path / \"models\"\n",
        "    datasets_path.mkdir(parents=True, exist_ok=True)\n",
        "    models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"‚úÖ Entorno detectado:\", \"Colab\" if IN_COLAB else \"Local\")\n",
        "        print(\"üìÅ Ruta base:\", base_path)\n",
        "        print(\"üìÅ Ruta datasets:\", datasets_path)\n",
        "        print(\"üìÅ Ruta modelos:\", models_path)\n",
        "\n",
        "    return IN_COLAB, base_path, datasets_path, models_path\n",
        "\n",
        "# üü¢ Llamada principal\n",
        "IN_COLAB, BASE_PATH, DATASETS_PATH, MODELS_PATH = configurar_rutas()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8829ed36",
      "metadata": {
        "id": "8829ed36"
      },
      "source": [
        "\n",
        "Esta celda clona el repositorio del proyecto en Colab, instala las dependencias desde `requirements.txt` y reinicia el entorno para aplicar los cambios.\n",
        "\n",
        "üîß *Sugerencia*: podr√≠as separar la clonaci√≥n del repositorio y la instalaci√≥n en funciones para mayor claridad y reutilizaci√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3659cd44",
      "metadata": {
        "id": "3659cd44",
        "outputId": "6c350529-bfb7-4210-f83e-890473058e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Repositorio ya clonado en: /content/drive/MyDrive/ia_thermal_colab/ia_thermal\n",
            "üì¶ Instalando dependencias desde requirements.txt...\n",
            "üîÑ Reiniciando entorno para aplicar los cambios...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.restartRuntime()"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# üîÑ Par√°metros del repositorio\n",
        "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia si usas otro repo\n",
        "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "CLONE_PATH = BASE_PATH / REPO_NAME  # Usamos Path (de pathlib)\n",
        "\n",
        "def clonar_repo_si_no_existe(repo_url: str, clone_path: Path):\n",
        "    if not clone_path.exists():\n",
        "        print(f\"üì• Clonando repositorio en {clone_path}...\")\n",
        "        os.system(f\"git clone {repo_url} {clone_path}\")\n",
        "    else:\n",
        "        print(f\"üìÇ Repositorio ya clonado en: {clone_path}\")\n",
        "\n",
        "def instalar_requirements(clone_path: Path):\n",
        "    req_path = clone_path / \"requirements.txt\"\n",
        "    if req_path.exists():\n",
        "        print(\"üì¶ Instalando dependencias desde requirements.txt...\")\n",
        "        os.system(f\"pip install -r {req_path}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se encontr√≥ requirements.txt en el repositorio.\")\n",
        "\n",
        "def reiniciar_entorno_colab():\n",
        "    print(\"üîÑ Reiniciando entorno para aplicar los cambios...\")\n",
        "    display(IPython.display.Javascript('''google.colab.restartRuntime()'''))\n",
        "\n",
        "# üß™ Ejecutar solo en Colab\n",
        "if IN_COLAB:\n",
        "    clonar_repo_si_no_existe(GIT_REPO_URL, CLONE_PATH)\n",
        "    instalar_requirements(CLONE_PATH)\n",
        "    reiniciar_entorno_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc9afcf",
      "metadata": {
        "id": "bfc9afcf"
      },
      "source": [
        "\n",
        "Se importan todas las librer√≠as necesarias, tanto est√°ndar como personalizadas. Tambi√©n se configura el path para poder importar m√≥dulos espec√≠ficos seg√∫n el entorno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "59193a4a",
      "metadata": {
        "id": "59193a4a"
      },
      "outputs": [],
      "source": [
        "# Librer√≠as est√°ndar\n",
        "import os, sys, time, json, platform\n",
        "from datetime import datetime\n",
        "from typing import Sequence, Union, Optional\n",
        "\n",
        "# Visualizaci√≥n\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# NumPy y ciencia de datos\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch y entrenamiento\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Optimizaci√≥n\n",
        "import optuna\n",
        "\n",
        "# A√±adir rutas del proyecto (de forma portable)\n",
        "sys.path.append(str(BASE_PATH))\n",
        "sys.path.append(str(BASE_PATH / \"ia_thermal\"))\n",
        "sys.path.append(str(BASE_PATH / \"ia_thermal\" / \"ismaelgallo\"))\n",
        "sys.path.append(str(BASE_PATH.parent))\n",
        "\n",
        "# M√≥dulos propios del proyecto\n",
        "from architectures.convlstm import *\n",
        "from Dataset_Class_convlstm import *\n",
        "from plot_functions import *\n",
        "from Physics_Loss import *\n",
        "from utils import *\n",
        "from scripts.PCB_solver_tr import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f15d522",
      "metadata": {
        "id": "1f15d522"
      },
      "source": [
        "\n",
        "Esta celda detecta si hay una GPU disponible y selecciona `cuda` si es posible; de lo contrario, usa `cpu`. Muestra por pantalla qu√© dispositivo se est√° utilizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "52262b2f",
      "metadata": {
        "id": "52262b2f",
        "outputId": "90b71516-ae92-428e-91ab-bfd152decce1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìü Dispositivo seleccionado: cuda\n"
          ]
        }
      ],
      "source": [
        "def seleccionar_dispositivo(use_cuda: bool = True, verbose: bool = True) -> torch.device:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
        "    if verbose:\n",
        "        print(\"üìü Dispositivo seleccionado:\", device)\n",
        "    return device\n",
        "\n",
        "# Ejecuci√≥n\n",
        "device = seleccionar_dispositivo(use_cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8224edb2",
      "metadata": {
        "id": "8224edb2"
      },
      "source": [
        "\n",
        "Recopila informaci√≥n del sistema operativo, arquitectura, procesador, versi√≥n de Python, dispositivo de c√≥mputo y, si hay GPU disponible, tambi√©n su nombre, memoria y versi√≥n de CUDA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "202cd239",
      "metadata": {
        "id": "202cd239"
      },
      "outputs": [],
      "source": [
        "def get_system_specs(device: torch.device) -> dict:\n",
        "    specs = {\n",
        "        \"os\": platform.system(),\n",
        "        \"os_version\": platform.version(),\n",
        "        \"machine\": platform.machine(),\n",
        "        \"processor\": platform.processor(),\n",
        "        \"python_version\": platform.python_version(),\n",
        "        \"device\": str(device)\n",
        "    }\n",
        "    if torch.cuda.is_available():\n",
        "        specs[\"gpu_name\"] = torch.cuda.get_device_name(0)\n",
        "        specs[\"gpu_memory_total_GB\"] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
        "        specs[\"cuda_version\"] = torch.version.cuda\n",
        "    return specs\n",
        "\n",
        "# Obtener especificaciones del sistema\n",
        "system_specs = get_system_specs(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d60975",
      "metadata": {
        "id": "26d60975"
      },
      "source": [
        "\n",
        "Ajusta par√°metros visuales para gr√°ficos con matplotlib y seaborn, activando cuadr√≠cula, tama√±os de fuente adecuados y un estilo profesional para las figuras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "89f0cd3a",
      "metadata": {
        "id": "89f0cd3a",
        "outputId": "ac1308ed-5f30-49f7-d5d7-7353c9600d1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé® Estilo gr√°fico configurado con fondo blanco y paleta 'colorblind'.\n"
          ]
        }
      ],
      "source": [
        "def configurar_graficos(verbose=False):\n",
        "    plt.rcParams.update({\n",
        "        'text.usetex': False,\n",
        "        'font.family': 'serif',\n",
        "        'axes.labelsize': 12,\n",
        "        'axes.titlesize': 14,\n",
        "        'legend.fontsize': 12,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'axes.grid': True,\n",
        "        'grid.alpha': 0.75,\n",
        "        'grid.linestyle': '--',\n",
        "        'lines.linewidth': 2,\n",
        "    })\n",
        "    sns.set_context('paper')\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.set_palette('colorblind')  # Paleta con buen contraste y amigable\n",
        "    if verbose:\n",
        "        print(\"üé® Estilo gr√°fico configurado con fondo blanco y paleta 'colorblind'.\")\n",
        "\n",
        "configurar_graficos(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b93124",
      "metadata": {
        "id": "e5b93124"
      },
      "source": [
        "## Dataset import"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3667e7",
      "metadata": {
        "id": "0b3667e7"
      },
      "source": [
        "Define los hiperpar√°metros principales del experimento:\n",
        "\n",
        "- N√∫mero de muestras para entrenamiento, validaci√≥n y test.\n",
        "- Duraci√≥n de la simulaci√≥n en segundos (`time_sim`) y su resoluci√≥n temporal (`dt`).\n",
        "- Tama√±o del batch (`batch_size`), temperatura inicial (no cambiar el valor por defecto) y n√∫mero de nodos por lado del PCB.\n",
        "- La longitud de la secuencia temporal de salida se define como `time_sim + 1`.\n",
        "\n",
        "Este bloque establece los par√°metros que controlan c√≥mo se estructuran los datos y la simulaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a73e590a",
      "metadata": {
        "id": "a73e590a"
      },
      "outputs": [],
      "source": [
        "# ‚öôÔ∏è Par√°metros del conjunto de datos\n",
        "n_train = 1500    # N√∫mero de muestras para entrenamiento\n",
        "n_val = 200       # N√∫mero de muestras para validaci√≥n\n",
        "n_test = 20       # N√∫mero de muestras para test\n",
        "\n",
        "# ‚è±Ô∏è Par√°metros temporales\n",
        "time_sim = 500    # Duraci√≥n total de la simulaci√≥n (s)\n",
        "dt = 1            # Paso de tiempo (s)\n",
        "sequence_length = time_sim + 1  # Longitud de la secuencia temporal (incluye t=0)\n",
        "\n",
        "# üî• Condiciones f√≠sicas\n",
        "T_init = 298.0    # Temperatura inicial (K)\n",
        "nodes_side = 13   # N√∫mero de nodos por lado en la malla del PCB (13x13)\n",
        "\n",
        "# üì¶ Batch\n",
        "batch_size = 512  # Tama√±o del batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72fffc41",
      "metadata": {
        "id": "72fffc41"
      },
      "source": [
        "Carga los datasets de entrenamiento, validaci√≥n y test desde disco usando funciones personalizadas (`load_dataset_convlstm` y `load_trimmed_dataset_convlstm`), que tambi√©n preparan los datos para ser usados por PyTorch.\n",
        "\n",
        "Despu√©s, crea los `DataLoader` para cada conjunto de datos:\n",
        "\n",
        "- `train_loader`: con `shuffle=True` para entrenamiento.\n",
        "- `val_loader` y `test_loader`: sin barajar, para validaci√≥n y prueba.\n",
        "\n",
        "Estos objetos permiten iterar sobre los datos por batches durante el entrenamiento y evaluaci√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c3b5858c",
      "metadata": {
        "id": "c3b5858c",
        "outputId": "50b77fbb-eaa7-4002-943c-a287d2fd3376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cargando ConvLSTM transient dataset base desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_convlstm_6ch_transient_dataset.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo/Dataset_Class_convlstm.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(full_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cargando dataset train desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_convlstm_6ch_transient_dataset_train.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo/Dataset_Class_convlstm.py:370: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  base_dataset = torch.load(full_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Dataset movido a: CUDA\n",
            "‚úÖ Cargando dataset val desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_convlstm_6ch_transient_dataset_val.pth\n",
            "üì¶ Dataset movido a: CUDA\n",
            "‚úÖ Cargando dataset test desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_convlstm_6ch_transient_dataset_test.pth\n",
            "üì¶ Dataset movido a: CUDA\n"
          ]
        }
      ],
      "source": [
        "# if IN_COLAB:\n",
        "#   dir_path = BASE_PATH\n",
        "\n",
        "dataset = load_dataset_convlstm(base_path=BASE_PATH)\n",
        "\n",
        "dataset_train = load_trimmed_dataset_convlstm(base_path=BASE_PATH, dataset_type='train', max_samples=n_train, time_steps_output=sequence_length, to_device=True)\n",
        "dataset_val = load_trimmed_dataset_convlstm(base_path=BASE_PATH, dataset_type='val', max_samples=n_val, time_steps_output=sequence_length, to_device=True)\n",
        "dataset_test = load_trimmed_dataset_convlstm(base_path=BASE_PATH, dataset_type='test', max_samples=n_test, time_steps_output=sequence_length, to_device=True)\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0031bb20",
      "metadata": {
        "id": "0031bb20"
      },
      "source": [
        "Muestra las dimensiones del primer batch de entrada (`x_batch`) y de salida (`y_batch`) provenientes del `train_loader`.\n",
        "\n",
        "Esto es √∫til para verificar que los datos han sido cargados correctamente y tienen las dimensiones esperadas.\n",
        "\n",
        "Se detiene tras el primer batch usando `break`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "193c6f7d",
      "metadata": {
        "id": "193c6f7d",
        "outputId": "f219dd9a-d390-4dfc-c262-d71538a45990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_batch shape: torch.Size([512, 11, 6, 13, 13])\n",
            "y_batch shape: torch.Size([512, 11, 1, 13, 13])\n"
          ]
        }
      ],
      "source": [
        "for x_batch, y_batch in train_loader:\n",
        "    print(\"x_batch shape:\", x_batch.shape)\n",
        "    print(\"y_batch shape:\", y_batch.shape)\n",
        "    break  # Solo muestra el primer batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba69afe5",
      "metadata": {
        "id": "ba69afe5"
      },
      "source": [
        "Extrae un batch del `train_loader`, selecciona la √∫ltima imagen temporal del primer ejemplo y la muestra usando un mapa de calor (`imshow` con `cmap='hot'`).\n",
        "\n",
        "Esto permite visualizar la distribuci√≥n de temperatura final en el tiempo para ese ejemplo espec√≠fico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d8a29642",
      "metadata": {
        "id": "d8a29642",
        "outputId": "5aa060e0-5530-4081-9220-0836117a7333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Obtener primer batch\n",
        "x_batch, _ = next(iter(train_loader))\n",
        "\n",
        "# Seleccionar el √∫ltimo mapa de temperatura del primer ejemplo\n",
        "x_tfinal = x_batch[0, -1, -1]  # Shape: (C, H, W) -> (-1) para √∫ltimo paso temporal\n",
        "\n",
        "# Mostrar el mapa t√©rmico\n",
        "plt.imshow(x_tfinal.cpu().numpy(), cmap='hot', interpolation='nearest')\n",
        "plt.title(\"Temperatura final (√∫ltimo paso temporal)\")\n",
        "plt.colorbar(label=\"Temperatura (K)\")\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147eb34c",
      "metadata": {
        "id": "147eb34c"
      },
      "source": [
        "## Non-physics ConvLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ddb95c",
      "metadata": {
        "id": "99ddb95c"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886d959b",
      "metadata": {
        "id": "886d959b"
      },
      "source": [
        "Define los hiperpar√°metros del entrenamiento:\n",
        "\n",
        "- N√∫mero de √©pocas (`epochs`)\n",
        "- Tasa de aprendizaje inicial (`lr`) y su factor de decaimiento (`lrdecay`)\n",
        "- Paciencia para reducir el `lr` (`lrdecay_patience`) y para aplicar `early stopping` (`early_stop_patience`)\n",
        "- Arquitectura del modelo: n√∫mero de filtros por capa en `hidden_dims` y tama√±o del kernel\n",
        "\n",
        "Estos valores controlan el comportamiento del optimizador y la estructura de la red ConvLSTM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "314af641",
      "metadata": {
        "id": "314af641"
      },
      "outputs": [],
      "source": [
        "# ‚öôÔ∏è Hiperpar√°metros de entrenamiento\n",
        "epochs = 500\n",
        "lr = 1e-2\n",
        "lrdecay = 0.1\n",
        "lrdecay_patience = 10\n",
        "early_stop_patience = 50\n",
        "\n",
        "# üß† Arquitectura ConvLSTM\n",
        "hidden_dims = [64, 64]                     # N√∫mero de filtros por capa\n",
        "num_layers = len(hidden_dims)\n",
        "kernel_size = [(5, 5)] * num_layers        # Kernel de cada capa (igual para todas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e990ae",
      "metadata": {
        "id": "f2e990ae"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9aa29d9",
      "metadata": {
        "id": "b9aa29d9"
      },
      "source": [
        "Define la clase `PCB_ConvLSTM`, una red neuronal basada en ConvLSTM para predecir la evoluci√≥n t√©rmica en un PCB.\n",
        "\n",
        "- Usa `ConvLSTM` como n√∫cleo para modelar la secuencia temporal.\n",
        "- Incluye una capa `Conv2d` de 1x1 al final para proyectar la salida oculta a un canal de temperatura.\n",
        "- El m√©todo `forward` procesa secuencias completas (`seq_len > 1`), mientras que `forward_step` permite avanzar un paso en modo autoregresivo.\n",
        "\n",
        "Esta arquitectura es adecuada para secuencias espacio-temporales de mapas t√©rmicos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c431cd69",
      "metadata": {
        "id": "c431cd69"
      },
      "outputs": [],
      "source": [
        "class PCB_ConvLSTM(nn.Module):\n",
        "    def __init__(self, input_channels=6, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13):\n",
        "        super().__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.num_layers = len(hidden_dims)\n",
        "\n",
        "        self.convlstm = ConvLSTM(\n",
        "            input_dim=input_channels,\n",
        "            hidden_dim=hidden_dims,\n",
        "            kernel_size=kernel_size,\n",
        "            num_layers=self.num_layers,\n",
        "            batch_first=True,\n",
        "            bias=True,\n",
        "            return_all_layers=False\n",
        "        )\n",
        "        self.decoder = nn.Conv2d(hidden_dims[-1], 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        \"\"\"\n",
        "        x      : (B, T, 6, H, W)\n",
        "        hidden : lista de (h,c) por capa, o None\n",
        "        returns: preds (B, T, 1, H, W), hidden\n",
        "        \"\"\"\n",
        "        layer_output_list, hidden = self.convlstm(x, hidden)\n",
        "        h_seq = layer_output_list[0]                # (B, T, hidden_dim, H, W)\n",
        "        B, T, C_h, H, W = h_seq.shape\n",
        "\n",
        "        h_flat = h_seq.contiguous().view(B*T, C_h, H, W)\n",
        "        dec_flat = self.decoder(h_flat)\n",
        "        preds = dec_flat.view(B, T, 1, H, W)\n",
        "        return preds, hidden\n",
        "\n",
        "    def forward_step(self, x_t, hidden=None):\n",
        "        \"\"\"\n",
        "        Un paso de secuencia (seq_len=1).\n",
        "        x_t    : (B, 1, 6, H, W)\n",
        "        hidden : estado previo\n",
        "        returns: pred (B, 1, 1, H, W), hidden\n",
        "        \"\"\"\n",
        "        pred, hidden = self.forward(x_t, hidden)\n",
        "        return pred, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9537991",
      "metadata": {
        "id": "b9537991"
      },
      "source": [
        "Instancia el modelo `PCB_ConvLSTM` y lo env√≠a al dispositivo adecuado (`cpu` o `cuda`).\n",
        "\n",
        "Se define:\n",
        "\n",
        "- `criterion`: funci√≥n de p√©rdida MSE.\n",
        "- `optimizer`: Adam con la tasa de aprendizaje definida previamente.\n",
        "- `scheduler`: ReduceLROnPlateau para ajustar el `lr` si la p√©rdida se estanca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5de463c4",
      "metadata": {
        "id": "5de463c4",
        "outputId": "61feeb5a-f7ad-40a4-f839-ae2ba41aec5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo en dispositivo: cuda\n",
            "Par√°metros totales: 1,267,777\n"
          ]
        }
      ],
      "source": [
        "# Inicializar el modelo\n",
        "model = PCB_ConvLSTM(\n",
        "    input_channels=6,\n",
        "    hidden_dims=hidden_dims,\n",
        "    kernel_size=kernel_size\n",
        ").to(device)\n",
        "\n",
        "# P√©rdida y optimizador\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=lrdecay, patience=lrdecay_patience)\n",
        "\n",
        "# Mostrar informaci√≥n b√°sica del modelo\n",
        "print(f\"Modelo en dispositivo: {device}\")\n",
        "print(f\"Par√°metros totales: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea582d8",
      "metadata": {
        "id": "2ea582d8"
      },
      "source": [
        "### üß™ Entrenamiento del modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174c2b2f",
      "metadata": {
        "id": "174c2b2f"
      },
      "source": [
        "Define los hiperpar√°metros para el *scheduled sampling*, una t√©cnica para entrenamiento autoregresivo:\n",
        "\n",
        "- `p0`: probabilidad inicial de usar el valor real (ground truth).\n",
        "- `p_min`: probabilidad m√≠nima de usar GT al final del entrenamiento.\n",
        "- `decay_epochs`: n√∫mero de √©pocas en las que se reducir√° `p0` hasta `p_min`.\n",
        "\n",
        "Esta t√©cnica ayuda a la red a adaptarse gradualmente a predecir sin necesidad del ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d1b10ed6",
      "metadata": {
        "id": "d1b10ed6"
      },
      "outputs": [],
      "source": [
        "# Hiper-par√°metros de scheduled sampling\n",
        "p0              = 1.0            # probabilidad inicial de usar GT\n",
        "p_min           = 0.0            # probabilidad final de usar GT\n",
        "decay_epochs    = epochs // 5    # en cu√°ntas √©pocas bajar de p0 a p_min"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b089971",
      "metadata": {
        "id": "3b089971"
      },
      "source": [
        "Inicializa las variables de entrenamiento y prepara el sistema para **reanudar una sesi√≥n previa** si existe:\n",
        "\n",
        "- Crea la carpeta de salida.\n",
        "- Construye el nombre del fichero de modelo seg√∫n los hiperpar√°metros.\n",
        "- Si encuentra un modelo `.pth` guardado, lo carga junto con su configuraci√≥n `.json`.\n",
        "- Si no hay modelo previo, inicia un nuevo entrenamiento desde cero.\n",
        "\n",
        "Esta l√≥gica permite continuar el entrenamiento sin perder el progreso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1aed16b6",
      "metadata": {
        "id": "1aed16b6",
        "outputId": "d97280ef-52b0-45d8-bc0b-6640b11f6bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "‚ú® Nuevo entrenamiento: `PCB_ConvLSTM_6ch_nt1500_500s_bs512_h64-64_k5x5.pth`"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Los resultados se guardar√°n en: /content/drive/MyDrive/ia_thermal_colab/models/ConvLSTM_6ch/stateful_O2O/PCB_ConvLSTM_6ch_nt1500_500s_bs512_h64-64_k5x5.json\n"
          ]
        }
      ],
      "source": [
        "# Puedes cambiar esta ruta a mano si quieres usar una carpeta concreta\n",
        "# Si dejas None, guardar√° en MODELS_PATH/ConvLSTM_6ch/stateful_O2O\n",
        "custom_model_dir = None  # por ejemplo: Path(\"~/experimentos/cheops_v3\").expanduser()\n",
        "\n",
        "# ----------- Configurar ruta de guardado -----------\n",
        "kernel_string = f\"{kernel_size[0][0]}x{kernel_size[0][1]}\"\n",
        "layer_string = \"-\".join(str(d) for d in hidden_dims)\n",
        "\n",
        "if custom_model_dir is None:\n",
        "    model_dir = MODELS_PATH / \"ConvLSTM_6ch\" / \"stateful_O2O\"\n",
        "else:\n",
        "    model_dir = Path(custom_model_dir).resolve()\n",
        "\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "filename = f\"PCB_ConvLSTM_6ch_nt{n_train}_{time_sim}s_bs{batch_size}_h{layer_string}_k{kernel_string}.pth\"\n",
        "model_path = model_dir / filename\n",
        "json_path = model_path.with_suffix(\".json\")\n",
        "\n",
        "# ----------- Inicializaci√≥n de estado -----------\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "best_val_loss = np.inf\n",
        "elapsed_previous = 0.0\n",
        "start_epoch = 0\n",
        "start_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "# ----------- L√≥gica de reanudaci√≥n -----------\n",
        "if model_path.exists():\n",
        "    display(Markdown(f\"üîÅ Cargando modelo existente `{filename}` y reanudando entrenamiento.\"))\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "    if json_path.exists():\n",
        "        with open(json_path, 'r') as f:\n",
        "            prev = json.load(f)\n",
        "        best_val_loss = prev.get('best_val_loss', best_val_loss)\n",
        "        train_loss = prev.get('train_loss', [])\n",
        "        val_loss = prev.get('val_loss', [])\n",
        "        elapsed_previous = prev.get('training_duration_minutes', 0.0)\n",
        "        start_datetime = prev.get('start_datetime', start_datetime)\n",
        "        start_epoch = prev.get('epochs_trained', 0)\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        display(Markdown(\"‚ö†Ô∏è No se encontr√≥ JSON de hiperpar√°metros; se reinicia contadores.\"))\n",
        "else:\n",
        "    display(Markdown(f\"‚ú® Nuevo entrenamiento: `{filename}`\"))\n",
        "\n",
        "print(\"üìÅ Los resultados se guardar√°n en:\", json_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3bc3aa5",
      "metadata": {
        "id": "d3bc3aa5"
      },
      "source": [
        "Define el **bucle de entrenamiento completo** para la red `PCB_ConvLSTM`, incluyendo:\n",
        "\n",
        "- Entrenamiento paso a paso con *scheduled sampling* autoregresivo.\n",
        "- Validaci√≥n del modelo tras cada √©poca.\n",
        "- Ajuste autom√°tico de la tasa de aprendizaje con `ReduceLROnPlateau`.\n",
        "- Early stopping si no hay mejora tras cierto n√∫mero de √©pocas.\n",
        "- Guardado del mejor modelo y de los resultados en un archivo `.json`.\n",
        "\n",
        "El entrenamiento es completamente reproducible y robusto frente a interrupciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "db47a35d",
      "metadata": {
        "id": "db47a35d"
      },
      "outputs": [],
      "source": [
        "# def entrenar_modelo(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
        "#                     model_path, json_path, epochs, early_stop_patience,\n",
        "#                     p0=1.0, p_min=0.0, decay_epochs=50,\n",
        "#                     device='cpu', start_epoch=0, train_loss=None, val_loss=None,\n",
        "#                     best_val_loss=float('inf'), elapsed_previous=0.0,\n",
        "#                     start_datetime=None, system_specs=None):\n",
        "#     \"\"\"\n",
        "#     Entrena el modelo ConvLSTM con scheduled sampling, validaci√≥n, scheduler y early stopping.\n",
        "#     Guarda el mejor modelo y los par√°metros en disco.\n",
        "#     \"\"\"\n",
        "\n",
        "#     if train_loss is None:\n",
        "#         train_loss = []\n",
        "#     if val_loss is None:\n",
        "#         val_loss = []\n",
        "#     if start_datetime is None:\n",
        "#         start_datetime = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "#     elapsed_minutes = elapsed_previous\n",
        "#     start_time_training = time.time() - (elapsed_previous * 60)\n",
        "#     epochs_without_improvement = 0\n",
        "\n",
        "#     for epoch in range(start_epoch, epochs):\n",
        "#         model.train()\n",
        "#         total_loss = 0.0\n",
        "#         p_gt = max(p_min, p0 - (epoch * (p0 - p_min) / decay_epochs))\n",
        "\n",
        "#         for x_batch, y_batch in tqdm(train_loader,\n",
        "#                                      desc=f\"Epoch {epoch+1}/{epochs} - Training\",\n",
        "#                                      leave=False):\n",
        "#             x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "#             B, T, _, H, W = x_batch.shape\n",
        "\n",
        "#             bc_seq = x_batch[:, :, :5]        # (B, T, 5, H, W)\n",
        "#             t_prev = x_batch[:, 0, 5:6]       # (B, 1, H, W)\n",
        "#             hidden = None\n",
        "#             loss_accum = 0.0\n",
        "\n",
        "#             for t in range(T):\n",
        "#                 if t == 0:\n",
        "#                     t_in = t_prev\n",
        "#                 else:\n",
        "#                     mask = (torch.rand(B,1,1,1,device=device) < p_gt).float()\n",
        "#                     t_in  = mask * y_batch[:, t-1] + (1-mask) * t_prev.detach()\n",
        "\n",
        "#                 x_t = torch.cat([bc_seq[:, t], t_in], dim=1).unsqueeze(1)  # (B,1,6,H,W)\n",
        "#                 pred_seq, hidden = model(x_t, hidden)\n",
        "#                 t_prev = pred_seq[:, 0]\n",
        "#                 loss_accum += criterion(t_prev, y_batch[:, t])\n",
        "\n",
        "#             loss_batch = loss_accum / T\n",
        "#             optimizer.zero_grad()\n",
        "#             loss_batch.backward()\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss_batch.item()\n",
        "\n",
        "#         epoch_train_loss = total_loss / len(train_loader)\n",
        "#         train_loss.append(epoch_train_loss)\n",
        "\n",
        "#         # Validaci√≥n\n",
        "#         model.eval()\n",
        "#         total_val_loss = 0.0\n",
        "#         with torch.no_grad():\n",
        "#             for x_val, y_val in val_loader:\n",
        "#                 x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "#                 Bv, Tv, _, Hv, Wv = x_val.shape\n",
        "\n",
        "#                 bc_v     = x_val[:, :, :5]\n",
        "#                 t_prev_v = x_val[:, 0, 5:6]\n",
        "#                 hidden_v = None\n",
        "#                 val_acc  = 0.0\n",
        "\n",
        "#                 for t in range(Tv):\n",
        "#                     x_tv = torch.cat([bc_v[:, t], t_prev_v], dim=1).unsqueeze(1)\n",
        "#                     pred_v, hidden_v = model(x_tv, hidden_v)\n",
        "#                     t_prev_v = pred_v[:, 0]\n",
        "#                     val_acc += criterion(t_prev_v, y_val[:, t])\n",
        "\n",
        "#                 val_loss_batch = val_acc / Tv\n",
        "#                 total_val_loss += val_loss_batch.item()\n",
        "\n",
        "#         epoch_val_loss = total_val_loss / len(val_loader)\n",
        "#         val_loss.append(epoch_val_loss)\n",
        "\n",
        "#         # Scheduler\n",
        "#         scheduler.step(epoch_val_loss)\n",
        "\n",
        "#         # Early stopping & Guardado\n",
        "#         elapsed_training = time.time() - start_time_training\n",
        "#         elapsed_minutes = elapsed_training / 60\n",
        "#         current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "#         if epoch_val_loss < best_val_loss:\n",
        "#             best_val_loss = epoch_val_loss\n",
        "#             torch.save(model.state_dict(), model_path)\n",
        "#             epochs_without_improvement = 0\n",
        "#         else:\n",
        "#             epochs_without_improvement += 1\n",
        "#             if epochs_without_improvement >= early_stop_patience:\n",
        "#                 print(f\"‚ö†Ô∏è Early stopping en epoch {epoch+1}\")\n",
        "#                 break\n",
        "\n",
        "#         # Guardado JSON\n",
        "#         params = {\n",
        "#             'start_datetime': start_datetime,\n",
        "#             'training_duration_minutes': elapsed_minutes,\n",
        "#             'system_specs': system_specs,\n",
        "#             'hidden_dims': list(model.convlstm.hidden_dim),\n",
        "#             'kernel_size': model.convlstm.kernel_size[0],\n",
        "#             'batch_size': train_loader.batch_size,\n",
        "#             'lr': optimizer.param_groups[0]['lr'],\n",
        "#             'scheduler': {\n",
        "#                 'type': 'ReduceLROnPlateau',\n",
        "#                 'factor': scheduler.factor,\n",
        "#                 'patience': scheduler.patience,\n",
        "#                 'final_lr': current_lr\n",
        "#             },\n",
        "#             'early_stop_patience': early_stop_patience,\n",
        "#             'epochs_trained': epoch + 1,\n",
        "#             'best_val_loss': best_val_loss,\n",
        "#             'train_loss': train_loss,\n",
        "#             'val_loss': val_loss,\n",
        "#         }\n",
        "#         with open(json_path, 'w') as f:\n",
        "#             json.dump(params, f, indent=4)\n",
        "\n",
        "#     print(f\"Entrenamiento finalizado en {elapsed_minutes:.2f} minutos.\")\n",
        "#     return train_loss, val_loss, best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "36c72c78",
      "metadata": {
        "id": "36c72c78"
      },
      "outputs": [],
      "source": [
        "# 1) Desactivar CUDAGraphs globalmente (antes de importar torch._inductor)\n",
        "import os\n",
        "os.environ[\"TORCHINDUCTOR_DISABLE_CUDAGRAPHS\"] = \"1\"\n",
        "\n",
        "# 2) Imports y configuraci√≥n\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import torch._dynamo\n",
        "from torch import amp\n",
        "from tqdm import tqdm\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# Si torch.compile lanza errores, cae a modo eager\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "def entrenar_modelo_cuda(\n",
        "        model, train_loader, val_loader,\n",
        "        criterion, optimizer, scheduler,\n",
        "        model_path, json_path,\n",
        "        epochs, early_stop_patience,\n",
        "        p0=1.0, p_min=0.0, decay_epochs=50,\n",
        "        device=None, start_epoch=0,\n",
        "        train_loss=None, val_loss=None,\n",
        "        best_val_loss=float('inf'),\n",
        "        elapsed_previous=0.0,\n",
        "        start_datetime=None,\n",
        "        system_specs=None,\n",
        "        amp_enabled=True,   # mixtura de precisi√≥n\n",
        "        clip_grad=None,\n",
        "        use_compile=True):  # activar torch.compile\n",
        "\n",
        "    # Preparaci√≥n\n",
        "    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model  = model.to(device)\n",
        "\n",
        "    # torch.compile con mode reduce-overhead (CUDAGraphs ya desactivado via env var)\n",
        "    if use_compile and torch.__version__ >= '2' and device.type == 'cuda':\n",
        "        props = torch.cuda.get_device_properties(device)\n",
        "        if props.major >= 7:\n",
        "            model = torch.compile(model, mode=\"reduce-overhead\")\n",
        "            print(\"Modelo compilado (CUDAGraphs desactivado).\")\n",
        "        else:\n",
        "            print(f\"torch.compile desactivado: CC {props.major}.{props.minor} < 7.0\")\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # AMP: GradScaler y autocast (API torch.amp)\n",
        "    scaler = amp.GradScaler(enabled=amp_enabled)\n",
        "    autocast_ctx = (lambda: amp.autocast(device_type='cuda',\n",
        "                                         dtype=torch.float16,\n",
        "                                         enabled=True)) if amp_enabled else nullcontext\n",
        "\n",
        "    # Inicializar listas y tiempos\n",
        "    train_loss = [] if train_loss is None else train_loss\n",
        "    val_loss   = [] if val_loss   is None else val_loss\n",
        "    start_datetime = start_datetime or time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    start_time_training = time.time() - elapsed_previous*60\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    # Bucle de epochs\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        p_gt = max(p_min, p0 - epoch*(p0-p_min)/decay_epochs)\n",
        "\n",
        "        for x_batch, y_batch in tqdm(train_loader,\n",
        "                                     desc=f\"Epoch {epoch+1}/{epochs}\",\n",
        "                                     leave=False):\n",
        "            x_batch = x_batch.to(device, non_blocking=True)\n",
        "            y_batch = y_batch.to(device, non_blocking=True)\n",
        "            _, T, _, _, _ = x_batch.shape\n",
        "\n",
        "            bc_seq, t_prev = x_batch[:, :, :5], x_batch[:, 0, 5:6]\n",
        "            hidden, loss_accum = None, 0.0\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast_ctx():\n",
        "                for t in range(T):\n",
        "                    if t == 0:\n",
        "                        t_in = t_prev\n",
        "                    else:\n",
        "                        mask = (torch.rand_like(t_prev) < p_gt).float()\n",
        "                        t_in = mask * y_batch[:, t-1] + (1-mask) * t_prev.detach()\n",
        "\n",
        "                    x_t = torch.cat([bc_seq[:, t], t_in], dim=1).unsqueeze(1)\n",
        "                    pred_seq, hidden = model(x_t, hidden)\n",
        "                    t_prev = pred_seq[:, 0]\n",
        "                    loss_accum += criterion(t_prev, y_batch[:, t])\n",
        "\n",
        "                loss_batch = loss_accum / T\n",
        "\n",
        "            scaler.scale(loss_batch).backward()\n",
        "            if clip_grad:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss_batch.item()\n",
        "\n",
        "        train_loss.append(total_loss/len(train_loader))\n",
        "\n",
        "        # Validaci√≥n\n",
        "        epoch_val_loss = _validacion(model, val_loader, criterion, device)\n",
        "        val_loss.append(epoch_val_loss)\n",
        "\n",
        "        # Scheduler & Early stopping\n",
        "        scheduler.step(epoch_val_loss)\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stop_patience:\n",
        "                print(f\"‚ö†Ô∏è Early stopping en epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Guardar parametros en JSON\n",
        "        _guardar_json(json_path, {\n",
        "            'start_datetime': start_datetime,\n",
        "            'training_duration_minutes': (time.time()-start_time_training)/60,\n",
        "            'system_specs': system_specs,\n",
        "            'hidden_dims': list(model.convlstm.hidden_dim),\n",
        "            'kernel_size': model.convlstm.kernel_size[0],\n",
        "            'batch_size': train_loader.batch_size,\n",
        "            'lr': lr,\n",
        "            'scheduler': {\n",
        "                'type':'ReduceLROnPlateau',\n",
        "                'factor':scheduler.factor,\n",
        "                'patience':scheduler.patience,\n",
        "                'final_lr':lr\n",
        "            },\n",
        "            'early_stop_patience':early_stop_patience,\n",
        "            'epochs_trained':epoch+1,\n",
        "            'best_val_loss':best_val_loss,\n",
        "            'train_loss':train_loss,\n",
        "            'val_loss':val_loss\n",
        "        })\n",
        "\n",
        "    print(f\"Entrenamiento finalizado en {(time.time()-start_time_training)/60:.2f} min\")\n",
        "    return train_loss, val_loss, best_val_loss\n",
        "\n",
        "# Funciones auxiliares\n",
        "def _validacion(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val = x_val.to(device, non_blocking=True)\n",
        "            y_val = y_val.to(device, non_blocking=True)\n",
        "            _, T, _, _, _ = x_val.shape\n",
        "            bc_seq, t_prev = x_val[:, :, :5], x_val[:, 0, 5:6]\n",
        "            hidden, loss_accum = None, 0.0\n",
        "            for t in range(T):\n",
        "                x_t = torch.cat([bc_seq[:, t], t_prev], dim=1).unsqueeze(1)\n",
        "                pred_seq, hidden = model(x_t, hidden)\n",
        "                t_prev = pred_seq[:, 0]\n",
        "                loss_accum += criterion(t_prev, y_val[:, t])\n",
        "            total += (loss_accum/T).item()\n",
        "    return total/len(val_loader)\n",
        "\n",
        "def _guardar_json(ruta, params):\n",
        "    with open(ruta, 'w') as f:\n",
        "        json.dump(params, f, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "# Auxiliares\n",
        "\n",
        "def _validacion(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val = x_val.to(device, non_blocking=True)\n",
        "            y_val = y_val.to(device, non_blocking=True)\n",
        "            _, T, _, _, _ = x_val.shape\n",
        "\n",
        "            bc_seq, t_prev = x_val[:, :, :5], x_val[:, 0, 5:6]\n",
        "            hidden, loss_accum = None, 0.0\n",
        "\n",
        "            for t in range(T):\n",
        "                x_t = torch.cat([bc_seq[:, t], t_prev], dim=1).unsqueeze(1)\n",
        "                pred_seq, hidden = model(x_t, hidden)\n",
        "                t_prev = pred_seq[:, 0]\n",
        "                loss_accum += criterion(t_prev, y_val[:, t])\n",
        "\n",
        "            total += (loss_accum / T).item()\n",
        "    return total / len(val_loader)\n",
        "\n",
        "def _guardar_json(ruta, params):\n",
        "    with open(ruta, 'w') as f:\n",
        "        json.dump(params, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7bf4d008",
      "metadata": {
        "id": "7bf4d008",
        "outputId": "9d81f077-c305-43c4-f9a2-08157325e1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-260d56fd3070>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loss, val_loss, best_val = entrenar_modelo_cuda(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# tu modelo ConvLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# DataLoader con pin_memory=True, num_workers>0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-898efa088646>\u001b[0m in \u001b[0;36mentrenar_modelo_cuda\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, model_path, json_path, epochs, early_stop_patience, p0, p_min, decay_epochs, device, start_epoch, train_loss, val_loss, best_val_loss, elapsed_previous, start_datetime, system_specs, amp_enabled, clip_grad, use_compile)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_loss, val_loss, best_val = entrenar_modelo_cuda(\n",
        "    model,                 # tu modelo ConvLSTM\n",
        "    train_loader,          # DataLoader con pin_memory=True, num_workers>0\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    model_path,\n",
        "    json_path,\n",
        "    epochs,\n",
        "    early_stop_patience,\n",
        "    # Par√°metros de scheduled sampling (igual que antes)\n",
        "    p0=1.0,\n",
        "    p_min=0.0,\n",
        "    decay_epochs=50,\n",
        "    # Omite \"device\" si quieres auto-detecci√≥n de GPU\n",
        "    # Omite start_epoch, train_loss, etc. si usas valores por defecto\n",
        "    # Par√°metros nuevos:\n",
        "    amp_enabled=True,      # FP16 con la API torch.amp\n",
        "    clip_grad=None,        # clipping opcional\n",
        "    use_compile=False       # Desactiva torch.compile para probar\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "719ca60d",
      "metadata": {
        "id": "719ca60d"
      },
      "source": [
        "Grafica la evoluci√≥n de las p√©rdidas (`train_loss` y `val_loss`) a lo largo del entrenamiento.\n",
        "\n",
        "Esto permite analizar visualmente el comportamiento del modelo, detectar sobreajuste o problemas de convergencia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ebce970",
      "metadata": {
        "id": "2ebce970"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(train_loss, val_loss):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_loss, label='P√©rdida Entrenamiento', color='tab:blue')\n",
        "    plt.plot(val_loss, label='P√©rdida Validaci√≥n', color='tab:orange')\n",
        "    plt.xlabel('√âpocas')\n",
        "    plt.ylabel('Loss (MSE)')\n",
        "    plt.yscale('log')\n",
        "    plt.title('Curvas de p√©rdida durante el entrenamiento')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Uso\n",
        "plot_loss_curves(train_loss, val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8017cb82",
      "metadata": {
        "id": "8017cb82"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f55a05",
      "metadata": {
        "id": "e4f55a05"
      },
      "source": [
        "Carga el mejor modelo entrenado y eval√∫a su rendimiento en el conjunto de test mediante una funci√≥n `rollout` autoregresiva.\n",
        "\n",
        "- La funci√≥n `rollout` genera toda la secuencia de salida autoregresiva usando como entrada las condiciones de contorno (`bc_seq`) y la temperatura inicial (`T0`).\n",
        "- Se eval√∫a la p√©rdida total del modelo sobre todas las muestras y tambi√©n se calcula la p√©rdida por paso de tiempo.\n",
        "\n",
        "Incluye impresi√≥n opcional de errores en pasos espec√≠ficos para analizar c√≥mo evoluciona el error en el tiempo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa23a12",
      "metadata": {
        "id": "0fa23a12"
      },
      "outputs": [],
      "source": [
        "# --- 1. Carga del mejor modelo ---\n",
        "model = PCB_ConvLSTM(input_channels=6,\n",
        "                     hidden_dims=hidden_dims,\n",
        "                     kernel_size=kernel_size,\n",
        "                     height=13,\n",
        "                     width=13).to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# --- 2. Funci√≥n de rollout autoregresivo puro ---\n",
        "@torch.no_grad()\n",
        "def rollout(model, bc_seq, T0):\n",
        "    \"\"\"\n",
        "    Predicci√≥n autoregresiva completa.\n",
        "\n",
        "    Args:\n",
        "        model   : modelo PyTorch\n",
        "        bc_seq  : tensor (B, T, 5, H, W) con canales de contorno ya en device\n",
        "        T0      : tensor (B, 1, H, W) condici√≥n inicial ya en device\n",
        "\n",
        "    Returns:\n",
        "        preds   : tensor (B, T, 1, H, W) con predicciones autoregresivas\n",
        "    \"\"\"\n",
        "    B, T, _, H, W = bc_seq.shape\n",
        "    preds = []\n",
        "    t_prev = T0\n",
        "    hidden = None\n",
        "\n",
        "    for t in range(T):\n",
        "        x_t = torch.cat([bc_seq[:, t], t_prev], dim=1).unsqueeze(1)  # (B,1,6,H,W)\n",
        "        pred_seq, hidden = model(x_t, hidden)\n",
        "        t_prev = pred_seq[:, 0]\n",
        "        preds.append(t_prev)\n",
        "\n",
        "    return torch.stack(preds, dim=1)\n",
        "\n",
        "# --- Test completo ---\n",
        "test_losses = []\n",
        "step_losses = torch.zeros(sequence_length, device=device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        bc_seq = x_batch[:, :, :5]\n",
        "        T0 = x_batch[:, 0, 5:6]\n",
        "\n",
        "        y_pred = rollout(model, bc_seq, T0)\n",
        "\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        test_losses.append(loss.item())\n",
        "\n",
        "        for t in range(y_pred.shape[1]):\n",
        "            step_losses[t] += criterion(y_pred[:, t], y_batch[:, t]).item() * y_pred.size(0)\n",
        "\n",
        "mean_test_loss = sum(test_losses) / len(test_losses)\n",
        "step_losses = (step_losses / len(test_loader.dataset)).cpu().numpy()\n",
        "\n",
        "print(f\"‚ñ∂Ô∏é Test Loss (secuencia completa): {mean_test_loss:.6f}\")\n",
        "\n",
        "for t_idx in [0, 4, y_pred.shape[1]-1]:\n",
        "    print(f\"  Paso {t_idx+1:2d} Loss: {step_losses[t_idx]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8be719",
      "metadata": {
        "id": "de8be719"
      },
      "source": [
        "### Analyzing results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a4943e",
      "metadata": {
        "id": "c0a4943e"
      },
      "source": [
        "Define una funci√≥n `predict_from_conditions(...)` que genera una predicci√≥n completa de temperatura dada una condici√≥n inicial y par√°metros f√≠sicos del sistema (como temperaturas de interfaces y potencia de calentadores).\n",
        "\n",
        "- Usa el m√©todo `create_input_from_values` del dataset para construir la entrada a partir de arrays.\n",
        "- Realiza el `rollout` paso a paso utilizando el m√©todo `forward_step` del modelo.\n",
        "- Devuelve una secuencia completa desnormalizada en formato `np.ndarray`.\n",
        "\n",
        "Esta funci√≥n es clave para usar el modelo en modo inferencia realista, fuera del flujo de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df60ca3",
      "metadata": {
        "id": "1df60ca3"
      },
      "outputs": [],
      "source": [
        "def predict_from_conditions(Q_heaters: np.ndarray,\n",
        "                            T_interfaces: np.ndarray,\n",
        "                            T_env: float,\n",
        "                            T_seq_initial: np.ndarray,\n",
        "                            sequence_length: int,\n",
        "                            model: PCB_ConvLSTM,\n",
        "                            dataset: PCBDataset_convlstm,\n",
        "                            device: torch.device = None) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Genera una predicci√≥n completa de long. sequence_length a partir de:\n",
        "      - Q_heaters:        (4,)             np.ndarray\n",
        "      - T_interfaces:     (4,)             np.ndarray\n",
        "      - T_env:            scalar           float\n",
        "      - T_seq_initial:    (13,13)          np.ndarray (el mapa inicial)\n",
        "      - sequence_length:  n√∫mero de pasos a predecir\n",
        "      - model:            tu PCB_ConvLSTM cargado y en .eval()\n",
        "      - dataset:          instancia de PCBDataset_convlstm con create_input_from_values\n",
        "      - device:           opcional, torch.device\n",
        "\n",
        "    Devuelve:\n",
        "      np.ndarray de forma (sequence_length, 13, 13) con la serie desnormalizada.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    # 1) Primer input (1,1,6,13,13)\n",
        "    input0 = dataset.create_input_from_values(\n",
        "        Q_heaters, T_interfaces, T_env,\n",
        "        T_seq=np.expand_dims(T_seq_initial, 0),\n",
        "        sequence_length=sequence_length,\n",
        "        autorregress=True\n",
        "    ).to(device)\n",
        "\n",
        "    # 2) Prepara contornos y t_prev\n",
        "    # bc_static: (1, seq_len, 5, 13,13)\n",
        "    bc_static = input0[:, :1, :5, :, :].repeat(1, sequence_length, 1, 1, 1)\n",
        "    # t_prev: (1,1,1,13,13)\n",
        "    t_prev = input0[:, :1, 5:6, :, :]\n",
        "\n",
        "    # 3) Roll-out autoregresivo\n",
        "    preds_norm = []\n",
        "    hidden = None\n",
        "    with torch.no_grad():\n",
        "        for t in range(sequence_length):\n",
        "            # concatenar por canal (dim=2)\n",
        "            x_t = torch.cat([bc_static[:, t:t+1], t_prev], dim=2)  # ‚Üí (1,1,6,13,13)\n",
        "            pred_t, hidden = model.forward_step(x_t, hidden)       # ‚Üí (1,1,1,13,13)\n",
        "            t_prev = pred_t                                        # mantener shape\n",
        "            preds_norm.append(t_prev)\n",
        "\n",
        "    preds_norm = torch.cat(preds_norm, dim=1)  # (1, T, 1, 13,13)\n",
        "\n",
        "    # 4) Desnormalizar y to numpy\n",
        "    mean = dataset.T_outputs_mean.to(device)\n",
        "    std  = dataset.T_outputs_std.to(device)\n",
        "    preds_denorm = preds_norm * std + mean      # (1, T, 1, H, W)\n",
        "    preds_denorm = preds_denorm.squeeze(0).squeeze(1)  # (T, 13,13)\n",
        "    return preds_denorm.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62fc08d3",
      "metadata": {
        "id": "62fc08d3"
      },
      "source": [
        "Carga de nuevo el modelo desde el disco y lo pone en modo evaluaci√≥n (`eval()`), para realizar predicciones sin modificar sus par√°metros.\n",
        "\n",
        "Esto es √∫til para preparar el modelo antes de realizar inferencias como las de la funci√≥n anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f4f818",
      "metadata": {
        "id": "14f4f818"
      },
      "outputs": [],
      "source": [
        "model = PCB_ConvLSTM(input_channels=6,\n",
        "                     hidden_dims=hidden_dims,\n",
        "                     kernel_size=kernel_size,\n",
        "                     height=13,\n",
        "                     width=13).to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63c0c125",
      "metadata": {
        "id": "63c0c125"
      },
      "source": [
        "Define las posiciones de los nodos que se quieran estudiar, en el caso por defecto los heaters (`id_heaters`), como tuplas de coordenadas dentro de la malla 13x13."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f151a8d5",
      "metadata": {
        "id": "f151a8d5"
      },
      "outputs": [],
      "source": [
        "id_heaters = [(6,3), (3,6), (9,3), (9,9)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3b1ca2",
      "metadata": {
        "id": "7c3b1ca2"
      },
      "source": [
        "Define las condiciones f√≠sicas para el caso de prueba:\n",
        "\n",
        "- `Q_heaters`: potencia aplicada por cada calentador.\n",
        "- `T_interfaces`: temperaturas fijas en las interfaces t√©rmicas.\n",
        "- `T_env`: temperatura ambiente.\n",
        "- `T_initial_map`: mapa de temperatura inicial uniforme, basado en `T_init`.\n",
        "\n",
        "Estas variables se usar√°n como entrada en la simulaci√≥n o para el modelo entrenado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1e18ab",
      "metadata": {
        "id": "cf1e18ab"
      },
      "outputs": [],
      "source": [
        "Q_heaters = np.array([1.0, 1.0, 1.0, 1.0])\n",
        "T_interfaces = np.array([290, 290, 290, 290])\n",
        "T_env = 250\n",
        "T_initial_map = np.full((13, 13), T_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e45ebb8",
      "metadata": {
        "id": "0e45ebb8"
      },
      "source": [
        "Ejecuta el caso de simulaci√≥n real `PCB_case_2` con los par√°metros definidos (en modo transitorio) para obtener la soluci√≥n de referencia.\n",
        "\n",
        "- `T`: contiene toda la evoluci√≥n temporal.\n",
        "- Se reestructura la salida en forma de malla `(T, 13, 13)`.\n",
        "- Se convierte a `tensor` y se sube al dispositivo (`cpu` o `cuda`) para usarla en comparaci√≥n o inferencia.\n",
        "\n",
        "Esto proporciona la verdad de terreno contra la cual se comparar√° la predicci√≥n del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6e322e",
      "metadata": {
        "id": "ca6e322e"
      },
      "outputs": [],
      "source": [
        "T, _, _, _ = PCB_case_2(solver = 'transient', display=False, time = time_sim, dt = dt, T_init = T_init, Q_heaters = Q_heaters, T_interfaces = T_interfaces, Tenv = T_env) # heaters in default position\n",
        "T_true = T.reshape(T.shape[0], nodes_side, nodes_side) # reshaping the data grid-shape\n",
        "T_true_tensor = torch.tensor(T_true, dtype=torch.float32).to(device)  # (T, H, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ad14d8",
      "metadata": {
        "id": "31ad14d8"
      },
      "source": [
        "Llama a la funci√≥n `predict_from_conditions(...)` usando las condiciones definidas (`Q_heaters`, `T_interfaces`, `T_env`, `T_initial_map`) y genera la predicci√≥n de temperatura a lo largo del tiempo.\n",
        "\n",
        "- Devuelve un array `(T, 13, 13)` con la evoluci√≥n t√©rmica.\n",
        "- Se convierte a tensor y se env√≠a al dispositivo para facilitar c√°lculos posteriores.\n",
        "\n",
        "Este bloque representa el uso final del modelo entrenado para hacer una predicci√≥n completa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab8f886",
      "metadata": {
        "id": "fab8f886"
      },
      "outputs": [],
      "source": [
        "T_pred = predict_from_conditions(\n",
        "    Q_heaters, T_interfaces, T_env,\n",
        "    T_initial_map, sequence_length,\n",
        "    model, dataset, device\n",
        ")\n",
        "T_pred_tensor = torch.tensor(T_pred, dtype=torch.float32).to(device)  # (T, H, W)\n",
        "\n",
        "print(T_pred.shape)  # (T, 13, 13)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e04388",
      "metadata": {
        "id": "31e04388"
      },
      "source": [
        "Dibuja la evoluci√≥n t√©rmica en nodos seleccionados a lo largo del tiempo, comparando la **predicci√≥n del modelo (`T_pred`)** con la **soluci√≥n de referencia (`T_true`)**.\n",
        "\n",
        "El par√°metro `together=True` indica que ambas curvas se mostrar√°n en la misma figura para facilitar la comparaci√≥n.\n",
        "\n",
        "Este paso permite evaluar visualmente la precisi√≥n del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b65f91",
      "metadata": {
        "id": "c6b65f91"
      },
      "outputs": [],
      "source": [
        "plot_nodes_evolution(T_pred, T_true, id_heaters, together=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634695f4",
      "metadata": {
        "id": "634695f4"
      },
      "source": [
        "Eval√∫a la precisi√≥n del modelo usando m√©tricas basadas en un **umbral de error absoluto** (en Kelvin):\n",
        "\n",
        "- `porcentaje_error_bajo_umbral`: calcula el porcentaje de valores predichos cuyo error es menor que el umbral especificado.\n",
        "- `nodos_siempre_dentro_umbral`: determina el porcentaje de nodos que est√°n por debajo del umbral en **todos los pasos de tiempo**.\n",
        "\n",
        "Estas m√©tricas permiten cuantificar de forma robusta la calidad de la predicci√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8623101",
      "metadata": {
        "id": "c8623101"
      },
      "outputs": [],
      "source": [
        "umbral = 5\n",
        "\n",
        "acierto = porcentaje_error_bajo_umbral(T_true, T_pred, umbral=umbral)\n",
        "print(f\"Porcentaje de predicciones con error < {umbral:.1f} K: {acierto:.2f}%\")\n",
        "\n",
        "porcentaje, _, _ = nodos_siempre_dentro_umbral(T_true, T_pred, umbral=umbral)\n",
        "print(f\"Porcentaje de nodos buenos: {porcentaje:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7739f5b2",
      "metadata": {
        "id": "7739f5b2"
      },
      "source": [
        "Calcula y visualiza una **curva de precisi√≥n acumulada** en funci√≥n del umbral de error:\n",
        "\n",
        "- Eval√∫a qu√© porcentaje de nodos cumplen con el criterio de error para cada valor de umbral entre 0 y 25 K.\n",
        "- Muestra una gr√°fica que permite analizar la sensibilidad del modelo al nivel de tolerancia de error.\n",
        "\n",
        "Esta representaci√≥n es √∫til para comparar distintos modelos o configuraciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea92acbc",
      "metadata": {
        "id": "ea92acbc"
      },
      "outputs": [],
      "source": [
        "umbrales = np.linspace(0, 25, 26)\n",
        "porcentajes = porcentaje_nodos_siempre_dentro_por_umbral(T_true, T_pred, umbrales)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(umbrales, porcentajes, label=\"Porcentaje de nodos\", linewidth=2)\n",
        "plt.xlabel(\"Umbral de error (K)\")\n",
        "plt.ylabel(\"Porcentaje de nodos con error < umbral durante toda la secuencia\")\n",
        "plt.title(\"Curva de acierto acumulado por umbral de error\")\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 100)\n",
        "plt.xlim(0, umbrales[-1])\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a64d538c",
      "metadata": {
        "id": "a64d538c"
      },
      "source": [
        "Grafica el **error absoluto medio (MAE)** por fotograma (paso temporal), comparando la predicci√≥n del modelo y la soluci√≥n de referencia.\n",
        "\n",
        "Esto permite observar c√≥mo evoluciona el error del modelo a lo largo de la secuencia y detectar posibles derivas o acumulaciones de error en el tiempo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53536617",
      "metadata": {
        "id": "53536617"
      },
      "outputs": [],
      "source": [
        "plot_mae_per_frame(T_pred_tensor.detach().cpu(), T_true_tensor.detach().cpu(), dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b36a3a2",
      "metadata": {
        "id": "3b36a3a2"
      },
      "source": [
        "Genera una figura con el **MAE por p√≠xel** (nodo de la malla), calculado sobre toda la secuencia temporal.\n",
        "\n",
        "Esto permite identificar qu√© zonas del PCB tienen mayor o menor error sistem√°tico, y si existen patrones espaciales en el comportamiento del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f4edf90",
      "metadata": {
        "id": "6f4edf90"
      },
      "outputs": [],
      "source": [
        "plot_mae_per_pixel(T_pred_tensor.detach().cpu(), T_true_tensor.detach().cpu(), dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7d01551",
      "metadata": {
        "id": "b7d01551"
      },
      "source": [
        "Crea una animaci√≥n en forma de **GIF comparativo** entre la predicci√≥n (`T_pred`) y la soluci√≥n real (`T_true`) a lo largo del tiempo.\n",
        "\n",
        "- Guarda el GIF en la carpeta `figures`.\n",
        "- Lo muestra directamente en el notebook usando HTML.\n",
        "\n",
        "Esta animaci√≥n es muy √∫til para validar visualmente el desempe√±o din√°mico del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81dd8e55",
      "metadata": {
        "id": "81dd8e55"
      },
      "outputs": [],
      "source": [
        "ani = generar_gif_pcb_comparacion(T_pred, T_true, guardar_en_figures=False, nombre_archivo='prueba_6ch_comparacion')\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml()) # Mostrar el GIF en Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00974efb",
      "metadata": {
        "id": "00974efb"
      },
      "source": [
        "Genera un **GIF que visualiza la evoluci√≥n del error absoluto** entre la predicci√≥n y la realidad en cada paso temporal.\n",
        "\n",
        "- Muestra c√≥mo cambia el error con el tiempo.\n",
        "- √ötil para detectar acumulaci√≥n de error, deriva o zonas problem√°ticas.\n",
        "\n",
        "La animaci√≥n se guarda y se muestra directamente en el notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150e061a",
      "metadata": {
        "id": "150e061a"
      },
      "outputs": [],
      "source": [
        "ani = generar_gif_error_evolucion(T_pred, T_true, guardar_en_figures=False, nombre_archivo='prueba_6ch_error')\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml()) # Mostrar el GIF en Jupyter Notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}