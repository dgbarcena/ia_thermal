{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d47121a7",
      "metadata": {
        "id": "d47121a7"
      },
      "source": [
        "# Pruebas con Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ae1c4f",
      "metadata": {
        "id": "27ae1c4f"
      },
      "source": [
        "### Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7569b95a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7569b95a",
        "outputId": "6fe90719-9f38-41b8-cadf-0f3373413fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Modo: Colab\n",
            "Ruta datasets: /content/drive/MyDrive/ia_thermal_colab/datasets\n",
            "Ruta modelos: /content/drive/MyDrive/ia_thermal_colab/models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import IPython\n",
        "\n",
        "# Detectar si estamos en Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Ruta base\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/ia_thermal_colab\"\n",
        "else:\n",
        "    BASE_PATH = os.path.expanduser(\"~/ia_thermal_colab\")\n",
        "\n",
        "DATASETS_PATH = os.path.join(BASE_PATH, \"datasets\")\n",
        "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "\n",
        "os.makedirs(DATASETS_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Modo:\", \"Colab\" if IN_COLAB else \"Local\")\n",
        "print(\"Ruta datasets:\", DATASETS_PATH)\n",
        "print(\"Ruta modelos:\", MODELS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "de808483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "de808483",
        "outputId": "84bd6e0e-14d6-457c-ad42-86fd16662a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repositorio ya clonado en: /content/drive/MyDrive/ia_thermal_colab/ia_thermal\n",
            "Collecting torch==2.5.1 (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.20.1 (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 3))\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio==2.5.1 (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 4))\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 11)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (7.7.1)\n",
            "Collecting jupyterlab (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading jupyterlab-4.4.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (6.5.7)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (7.16.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 25)) (1.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 26)) (6.0.2)\n",
            "Collecting optuna (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 27))\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2))\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 25)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 9)) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (3.2.3)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (3.0.14)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (75.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (2.19.1)\n",
            "Collecting alembic>=1.5.0 (from optuna->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 27))\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 27))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 27)) (2.0.40)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 27)) (1.1.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.16.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.3.7)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18))\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (2.21.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 27)) (3.2.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (2.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, triton, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, colorlog, async-lru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, alembic, optuna, nvidia-cusolver-cu12, isoduration, torch, torchvision, torchaudio, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed alembic-1.15.2 arrow-1.3.0 async-lru-2.0.5 colorlog-6.9.0 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.1 jupyterlab-server-2.27.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.3.0 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 triton-3.1.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n",
            "🔄 Reinicia el entorno para aplicar los cambios...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.restartRuntime()"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 🔄 Parámetros del repo\n",
        "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # 👈 Cambia esto\n",
        "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "CLONE_PATH = os.path.join(BASE_PATH, REPO_NAME)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # 🧬 Clonar el repositorio si no existe ya\n",
        "    if not os.path.exists(CLONE_PATH):\n",
        "        !git clone {GIT_REPO_URL} {CLONE_PATH}\n",
        "    else:\n",
        "        print(f\"Repositorio ya clonado en: {CLONE_PATH}\")\n",
        "\n",
        "    # 📦 Instalar requirements.txt\n",
        "    req_path = os.path.join(CLONE_PATH, \"requirements.txt\")\n",
        "    if os.path.exists(req_path):\n",
        "        !pip install -r {req_path}\n",
        "    else:\n",
        "        print(\"No se encontró requirements.txt en el repositorio.\")\n",
        "\n",
        "    print(\"🔄 Reinicia el entorno para aplicar los cambios...\")\n",
        "    IPython.display.display(IPython.display.Javascript('''google.colab.restartRuntime()'''))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7da63d97",
      "metadata": {
        "id": "7da63d97"
      },
      "source": [
        "## Inicializar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4160dabe",
      "metadata": {
        "id": "4160dabe"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get the directory path of the file\n",
        "dir_path = os.getcwd()\n",
        "\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal\")\n",
        "\n",
        "from plot_functions import *\n",
        "from Physics_Loss import *\n",
        "from utils import *\n",
        "sys.path.append('../Convolutional_NN')\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN\")\n",
        "\n",
        "from Dataset_Class import *\n",
        "\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo\")\n",
        "\n",
        "from architectures.convlstm import *\n",
        "from architectures.generic_spatiotemporal_decoder import *\n",
        "from architectures.generic_spatiotemporal_regressor import *\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Path within your Google Drive\n",
        "    study_path = os.path.join(BASE_PATH, \"optuna_studies\")\n",
        "    os.makedirs(study_path, exist_ok=True)  # Create if not exists\n",
        "    storage_url = f\"sqlite:///{study_path}/study_decoder.db\"\n",
        "else:\n",
        "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
        "    storage_url = \"sqlite:///optuna_studies/study_decoder.db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a69e9ffd",
      "metadata": {
        "id": "a69e9ffd"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "n_train = 1000\n",
        "n_val = 200\n",
        "sequence_length = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e679264a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e679264a",
        "outputId": "b6c4fad7-040f-4174-842b-8e61a2ee1553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cargando dataset train desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_transient_dataset_train.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN/Dataset_Class.py:299: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  base_dataset = torch.load(full_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cargando dataset val desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_transient_dataset_val.pth\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  dir_path = BASE_PATH\n",
        "\n",
        "# ⬅️ Esto se ejecuta una vez\n",
        "dataset_train = load_trimmed_dataset(\n",
        "    base_path=dir_path,\n",
        "    dataset_type='train',\n",
        "    max_samples=n_train,\n",
        "    time_steps_output=sequence_length\n",
        ")\n",
        "dataset_val = load_trimmed_dataset(\n",
        "    base_path=dir_path,\n",
        "    dataset_type='val',\n",
        "    max_samples=n_val,\n",
        "    time_steps_output=sequence_length\n",
        ")\n",
        "\n",
        "# Convertir a tensores de entrada y salida\n",
        "input_train, output_train = prepare_data_for_convlstm(dataset_train, device='cpu')\n",
        "input_val, output_val = prepare_data_for_convlstm(dataset_val, device='cpu')\n",
        "\n",
        "\n",
        "def get_data_loaders_from_tensors(batch_size):\n",
        "    train_loader = DataLoader(TensorDataset(input_train, output_train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(TensorDataset(input_val, output_val), batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd475b6c",
      "metadata": {
        "id": "dd475b6c"
      },
      "source": [
        "## ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5c25d49d",
      "metadata": {
        "id": "5c25d49d"
      },
      "outputs": [],
      "source": [
        "class ConvLSTMWrapper(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.convlstm = ConvLSTM(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            kernel_size=kernel_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bias=True,\n",
        "            return_all_layers=False\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.convlstm(x)  # output es lista [layer_output]\n",
        "        return output[0]              # devolvemos directamente el tensor (B, T, C, H, W)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6764169f",
      "metadata": {
        "id": "6764169f"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperparámetros\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
        "    hidden_dim_val = trial.suggest_categorical(\"hidden_dim\", [16, 32, 64, 128])\n",
        "    kernel_size_val = trial.suggest_categorical(\"kernel_size\", [1, 3, 5, 7])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "\n",
        "    # Adaptar al formato requerido por ConvLSTM\n",
        "    hidden_dim = [hidden_dim_val] * num_layers\n",
        "    kernel_size = [(kernel_size_val, kernel_size_val)] * num_layers\n",
        "\n",
        "    # Crear modelo ConvLSTM\n",
        "    model = ConvLSTMWrapper(\n",
        "        input_dim=3,  # o el número de canales reales\n",
        "        hidden_dim=hidden_dim,\n",
        "        kernel_size=kernel_size,\n",
        "        num_layers=num_layers\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Obtener dataloaders (train y val)\n",
        "    train_loader, val_loader = get_data_loaders_from_tensors(batch_size=batch_size)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5a861fab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5a861fab",
        "outputId": "a6793451-1287-4ac9-cf65-21afbcbccb9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:34:02,490] A new study created in memory with name: no-name-194fc0af-b824-4817-9543-9d005052578a\n",
            "Epoch 1/500 - Training:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 20, 1, 13, 13])) that is different to the input size (torch.Size([32, 20, 32, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch 1/500 - Training:  94%|█████████▍| 30/32 [00:01<00:00, 21.68it/s, loss=0.0753]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([8, 20, 1, 13, 13])) that is different to the input size (torch.Size([8, 20, 32, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2025-05-06 06:47:08,705] Trial 0 finished with value: 0.04850052297115326 and parameters: {'lr': 0.009865275123955214, 'batch_size': 32, 'hidden_dim': 32, 'kernel_size': 3, 'num_layers': 2}. Best is trial 0 with value: 0.04850052297115326.\n",
            "Epoch 1/500 - Training:   0%|          | 0/16 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([64, 20, 1, 13, 13])) that is different to the input size (torch.Size([64, 20, 64, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch 1/500 - Training:  94%|█████████▍| 15/16 [00:03<00:00,  4.00it/s, loss=0.138]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([40, 20, 1, 13, 13])) that is different to the input size (torch.Size([40, 20, 64, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([8, 20, 1, 13, 13])) that is different to the input size (torch.Size([8, 20, 64, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2025-05-06 07:21:59,230] Trial 1 finished with value: 0.06607997044920921 and parameters: {'lr': 0.0006398364783436623, 'batch_size': 64, 'hidden_dim': 64, 'kernel_size': 7, 'num_layers': 1}. Best is trial 0 with value: 0.04850052297115326.\n",
            "[W 2025-05-06 07:32:49,289] Trial 2 failed with parameters: {'lr': 0.0010149248981900577, 'batch_size': 8, 'hidden_dim': 32, 'kernel_size': 5, 'num_layers': 2} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-7-4b5b92a39073>\", line 30, in objective\n",
            "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/utils.py\", line 146, in train_one_epoch\n",
            "    y_pred = model(x)\n",
            "             ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-6-74c6f4ee030a>\", line 15, in forward\n",
            "    output, _ = self.convlstm(x)  # output es lista [layer_output]\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo/architectures/convlstm.py\", line 170, in forward\n",
            "    h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-05-06 07:32:49,857] Trial 2 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a4bd1889e7ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4b5b92a39073>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ia_thermal_colab/ia_thermal/utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, total_epochs)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-74c6f4ee030a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# output es lista [layer_output]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m              \u001b[0;31m# devolvemos directamente el tensor (B, T, C, H, W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo/architectures/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutput_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n\u001b[0m\u001b[1;32m    171\u001b[0m                                                  cur_state=[h, c])\n\u001b[1;32m    172\u001b[0m                 \u001b[0moutput_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"nombre_del_estudio\",  # puedes elegirlo tú\n",
        "    storage=\"sqlite:///optuna_studies/study_convlstm.db\",  # 🧠 crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, continúa donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358d1f45",
      "metadata": {
        "id": "358d1f45"
      },
      "outputs": [],
      "source": [
        "print(\"Best trial:\")\n",
        "for key, val in study.best_trial.params.items():\n",
        "    print(f\"{key}: {val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e950fcd",
      "metadata": {
        "id": "0e950fcd"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study).show()\n",
        "optuna.visualization.plot_param_importances(study).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79656890",
      "metadata": {
        "id": "79656890"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5ac41ec4",
      "metadata": {
        "id": "5ac41ec4"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperparámetros estructurales\n",
        "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256, 512])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 6)\n",
        "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4, 8])\n",
        "    dim_feedforward_factor = trial.suggest_int(\"dim_ff_factor\", 2, 6)\n",
        "    use_temporal_channel = trial.suggest_categorical(\"use_temporal_channel\", [False, True])\n",
        "\n",
        "    # Hiperparámetros de entrenamiento\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
        "\n",
        "    # Elegir optimizador\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"])\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader, val_loader = get_data_loaders_from_tensors(batch_size)\n",
        "\n",
        "    # Modelo\n",
        "    class CustomTransformerDecoder(TransformerDecoder):\n",
        "        def __init__(self, embedding_dim, num_layers, nhead, dim_ff, dropout):\n",
        "            super().__init__(embedding_dim, num_layers, nhead)\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_ff,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    model = GenericSpatioTemporalDecoder(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        in_channels=3,\n",
        "        use_temporal_channel=use_temporal_channel\n",
        "    ).to(device)\n",
        "\n",
        "    # Reemplazar el decoder por uno con dropout y tamaño FF ajustado\n",
        "    model.temporal_decoder = CustomTransformerDecoder(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        dim_ff=embedding_dim * dim_feedforward_factor,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer_cls = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"RMSprop\": torch.optim.RMSprop}[optimizer_name]\n",
        "    optimizer = optimizer_cls(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Entrenamiento\n",
        "    best_val_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93468e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e93468e3",
        "outputId": "093405cd-3df5-4d78-ec68-694e617fe982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 07:36:38,948] A new study created in RDB with name: decoder1\n",
            "[I 2025-05-06 07:54:32,385] Trial 0 finished with value: 0.021076383498998787 and parameters: {'embedding_dim': 512, 'num_layers': 1, 'nhead': 4, 'dim_ff_factor': 5, 'use_temporal_channel': True, 'batch_size': 16, 'lr': 0.002594618385880667, 'weight_decay': 2.0078385486443473e-05, 'dropout': 0.1745864308897127, 'optimizer': 'AdamW'}. Best is trial 0 with value: 0.021076383498998787.\n",
            "[I 2025-05-06 08:10:17,864] Trial 1 finished with value: 0.0008704521460458636 and parameters: {'embedding_dim': 128, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 4, 'use_temporal_channel': True, 'batch_size': 32, 'lr': 0.0009351820145979584, 'weight_decay': 0.0003243004235869649, 'dropout': 0.21133949920051645, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.0008704521460458636.\n",
            "[I 2025-05-06 08:28:27,288] Trial 2 finished with value: 5.3424865784888554e-05 and parameters: {'embedding_dim': 512, 'num_layers': 1, 'nhead': 4, 'dim_ff_factor': 5, 'use_temporal_channel': True, 'batch_size': 32, 'lr': 0.000736840111006186, 'weight_decay': 9.67242667133501e-06, 'dropout': 0.02457454602075949, 'optimizer': 'Adam'}. Best is trial 2 with value: 5.3424865784888554e-05.\n",
            "[I 2025-05-06 08:46:02,958] Trial 3 finished with value: 4.182429620414041e-05 and parameters: {'embedding_dim': 256, 'num_layers': 4, 'nhead': 8, 'dim_ff_factor': 4, 'use_temporal_channel': True, 'batch_size': 32, 'lr': 0.0008682756077780104, 'weight_decay': 1.0441632683667664e-06, 'dropout': 0.10337393313366496, 'optimizer': 'AdamW'}. Best is trial 3 with value: 4.182429620414041e-05.\n",
            "[I 2025-05-06 09:04:25,760] Trial 4 finished with value: 0.0012000039818563632 and parameters: {'embedding_dim': 256, 'num_layers': 4, 'nhead': 8, 'dim_ff_factor': 5, 'use_temporal_channel': False, 'batch_size': 32, 'lr': 0.00017957356424700688, 'weight_decay': 0.0004907590260859938, 'dropout': 0.2276073413102599, 'optimizer': 'Adam'}. Best is trial 3 with value: 4.182429620414041e-05.\n",
            "[I 2025-05-06 09:04:34,090] Trial 5 pruned. \n",
            "[I 2025-05-06 09:04:36,376] Trial 6 pruned. \n",
            "[I 2025-05-06 09:04:38,990] Trial 7 pruned. \n",
            "Epoch 69/500 - Training:  34%|███▎      | 42/125 [00:00<00:01, 63.55it/s, loss=0.000154]"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"decoder1\",  # puedes elegirlo tú\n",
        "    storage=storage_url,  # 🧠 crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, continúa donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Mostrar el mejor resultado\n",
        "print(\"🔍 Best trial:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d69a161",
      "metadata": {
        "id": "3d69a161"
      },
      "outputs": [],
      "source": [
        "import optuna.visualization as vis\n",
        "\n",
        "vis.plot_optimization_history(study).show()\n",
        "vis.plot_param_importances(study).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71120961",
      "metadata": {
        "id": "71120961"
      },
      "source": [
        "## Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc94e0b3",
      "metadata": {
        "id": "fc94e0b3"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos una sola vez\n",
        "dataset_train = load_trimmed_dataset(\n",
        "    base_path=dir_path, dataset_type='train',\n",
        "    max_samples=n_train, time_steps_output=sequence_length\n",
        ")\n",
        "dataset_val = load_trimmed_dataset(\n",
        "    base_path=dir_path, dataset_type='val',\n",
        "    max_samples=n_val, time_steps_output=sequence_length\n",
        ")\n",
        "\n",
        "x_train, y_train = prepare_data_for_convlstm(dataset_train, device='cpu')\n",
        "x_val, y_val = prepare_data_for_convlstm(dataset_val, device='cpu')\n",
        "\n",
        "train_dataset = TemporalRegressionDataset(x_train, y_train)\n",
        "val_dataset = TemporalRegressionDataset(x_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66140c54",
      "metadata": {
        "id": "66140c54"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperparámetros\n",
        "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4])\n",
        "    dim_ff_factor = trial.suggest_int(\"dim_ff_factor\", 2, 6)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"])\n",
        "\n",
        "    # DataLoaders desde datasets pre-cargados\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Modelo\n",
        "    model = GenericSpatioTemporalRegressor(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        in_channels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Reemplazo del decoder por uno personalizado con dropout y FF dimensionado\n",
        "    class CustomTransformerDecoder(TransformerDecoder):\n",
        "        def __init__(self, embedding_dim, num_layers, nhead, dim_ff, dropout):\n",
        "            super().__init__(embedding_dim, num_layers, nhead)\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_ff,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    model.temporal_decoder = CustomTransformerDecoder(\n",
        "        embedding_dim=embedding_dim * 2,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        dim_ff=embedding_dim * dim_ff_factor,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer_cls = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"RMSprop\": torch.optim.RMSprop}[optimizer_name]\n",
        "    optimizer = optimizer_cls(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caabb460",
      "metadata": {
        "id": "caabb460"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"nombre_del_estudio\",  # puedes elegirlo tú\n",
        "    storage=\"sqlite:///optuna_studies/study_regressor.db\",  # 🧠 crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, continúa donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Mostrar el mejor resultado\n",
        "print(\"🔍 Best trial:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}