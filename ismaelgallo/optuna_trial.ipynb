{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d47121a7",
      "metadata": {
        "id": "d47121a7"
      },
      "source": [
        "# Pruebas con Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ae1c4f",
      "metadata": {
        "id": "27ae1c4f"
      },
      "source": [
        "### Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7569b95a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7569b95a",
        "outputId": "6fe90719-9f38-41b8-cadf-0f3373413fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modo: Local\n",
            "Ruta datasets: C:\\Users\\ismael.gallo/ia_thermal_colab\\datasets\n",
            "Ruta modelos: C:\\Users\\ismael.gallo/ia_thermal_colab\\models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import IPython\n",
        "\n",
        "# Detectar si estamos en Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Ruta base\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/ia_thermal_colab\"\n",
        "else:\n",
        "    BASE_PATH = os.path.expanduser(\"~/ia_thermal_colab\")\n",
        "\n",
        "DATASETS_PATH = os.path.join(BASE_PATH, \"datasets\")\n",
        "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "\n",
        "os.makedirs(DATASETS_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Modo:\", \"Colab\" if IN_COLAB else \"Local\")\n",
        "print(\"Ruta datasets:\", DATASETS_PATH)\n",
        "print(\"Ruta modelos:\", MODELS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "de808483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "de808483",
        "outputId": "84bd6e0e-14d6-457c-ad42-86fd16662a21"
      },
      "outputs": [],
      "source": [
        "# üîÑ Par√°metros del repo\n",
        "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia esto\n",
        "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "CLONE_PATH = os.path.join(BASE_PATH, REPO_NAME)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # üß¨ Clonar el repositorio si no existe ya\n",
        "    if not os.path.exists(CLONE_PATH):\n",
        "        !git clone {GIT_REPO_URL} {CLONE_PATH}\n",
        "    else:\n",
        "        print(f\"Repositorio ya clonado en: {CLONE_PATH}\")\n",
        "\n",
        "    # üì¶ Instalar requirements.txt\n",
        "    req_path = os.path.join(CLONE_PATH, \"requirements.txt\")\n",
        "    if os.path.exists(req_path):\n",
        "        !pip install -r {req_path}\n",
        "    else:\n",
        "        print(\"No se encontr√≥ requirements.txt en el repositorio.\")\n",
        "\n",
        "    print(\"üîÑ Reinicia el entorno para aplicar los cambios...\")\n",
        "    IPython.display.display(IPython.display.Javascript('''google.colab.restartRuntime()'''))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7da63d97",
      "metadata": {
        "id": "7da63d97"
      },
      "source": [
        "## Inicializar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4160dabe",
      "metadata": {
        "id": "4160dabe"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get the directory path of the file\n",
        "dir_path = os.getcwd()\n",
        "\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal\")\n",
        "\n",
        "from plot_functions import *\n",
        "from Physics_Loss import *\n",
        "from utils import *\n",
        "sys.path.append('../Convolutional_NN')\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN\")\n",
        "\n",
        "from Dataset_Class import *\n",
        "\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo\")\n",
        "\n",
        "from architectures.convlstm import *\n",
        "from architectures.generic_spatiotemporal_decoder import *\n",
        "from architectures.generic_spatiotemporal_regressor import *\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Path within your Google Drive\n",
        "    study_path = os.path.join(BASE_PATH, \"optuna_studies\")\n",
        "    os.makedirs(study_path, exist_ok=True)  # Create if not exists\n",
        "    storage_url = f\"sqlite:///{study_path}/study_decoder.db\"\n",
        "else:\n",
        "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
        "    storage_url = \"sqlite:///optuna_studies/study_decoder.db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a69e9ffd",
      "metadata": {
        "id": "a69e9ffd"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "n_train = 1000\n",
        "n_val = 200\n",
        "\n",
        "sequence_length = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e679264a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e679264a",
        "outputId": "b6c4fad7-040f-4174-842b-8e61a2ee1553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cargando dataset train desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_transient_dataset_train.pth\n",
            "‚úÖ Cargando dataset val desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_transient_dataset_val.pth\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  dir_path = BASE_PATH\n",
        "\n",
        "# ‚¨ÖÔ∏è Esto se ejecuta una vez\n",
        "dataset_train = load_trimmed_dataset(\n",
        "    base_path=dir_path,\n",
        "    dataset_type='train',\n",
        "    max_samples=n_train,\n",
        "    time_steps_output=sequence_length\n",
        ")\n",
        "dataset_val = load_trimmed_dataset(\n",
        "    base_path=dir_path,\n",
        "    dataset_type='val',\n",
        "    max_samples=n_val,\n",
        "    time_steps_output=sequence_length\n",
        ")\n",
        "\n",
        "# Convertir a tensores de entrada y salida\n",
        "input_train, output_train = prepare_data_for_convlstm(dataset_train, device='cpu')\n",
        "input_val, output_val = prepare_data_for_convlstm(dataset_val, device='cpu')\n",
        "\n",
        "\n",
        "def get_data_loaders_from_tensors(batch_size):\n",
        "    train_loader = DataLoader(TensorDataset(input_train, output_train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(TensorDataset(input_val, output_val), batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd475b6c",
      "metadata": {
        "id": "dd475b6c"
      },
      "source": [
        "## ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5c25d49d",
      "metadata": {
        "id": "5c25d49d"
      },
      "outputs": [],
      "source": [
        "class ConvLSTMWrapper(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.model = ConvLSTM(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            kernel_size=kernel_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # x: [B, T, C, H, W]\n",
        "        output, _ = self.model(x)  # output is list of length T: each [B, C, H, W]\n",
        "        y_pred = torch.stack(output, dim=1)  # [B, T, C, H, W]\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "6764169f",
      "metadata": {
        "id": "6764169f"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperpar√°metros\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
        "    hidden_dim_val = trial.suggest_categorical(\"hidden_dim\", [16, 32, 64, 128])\n",
        "    kernel_size_val = trial.suggest_categorical(\"kernel_size\", [1, 3, 5, 7])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "\n",
        "    # Adaptar al formato requerido por ConvLSTM\n",
        "    hidden_dim = [hidden_dim_val] * num_layers\n",
        "    kernel_size = [(kernel_size_val, kernel_size_val)] * num_layers\n",
        "\n",
        "    # Crear modelo ConvLSTM\n",
        "    model = ConvLSTMWrapper(\n",
        "        input_dim=3,  # o el n√∫mero de canales reales\n",
        "        hidden_dim=hidden_dim,\n",
        "        kernel_size=kernel_size,\n",
        "        num_layers=num_layers\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Obtener dataloaders (train y val)\n",
        "    train_loader, val_loader = get_data_loaders_from_tensors(batch_size=batch_size)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5a861fab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5a861fab",
        "outputId": "a6793451-1287-4ac9-cf65-21afbcbccb9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 11:32:20,852] Using an existing study with name 'nombre_del_estudio' instead of creating a new one.\n",
            "Epoch 1/10 - Training:   0%|          | 0/32 [00:00<?, ?it/s]c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([32, 1, 20, 13, 13])) that is different to the input size (torch.Size([32, 1, 1, 128, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[W 2025-05-06 11:32:21,034] Trial 5 failed with parameters: {'lr': 0.00017156717056421555, 'batch_size': 32, 'hidden_dim': 128, 'kernel_size': 3, 'num_layers': 1} because of the following error: RuntimeError('The size of tensor a (128) must match the size of tensor b (20) at non-singleton dimension 3').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\ismael.gallo\\AppData\\Local\\Temp\\ipykernel_2892\\503547808.py\", line 30, in objective\n",
            "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
            "  File \"c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\utils.py\", line 148, in train_one_epoch\n",
            "    loss = criterion(y_pred, y)\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py\", line 608, in forward\n",
            "    return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\functional.py\", line 3791, in mse_loss\n",
            "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\functional.py\", line 76, in broadcast_tensors\n",
            "    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n",
            "RuntimeError: The size of tensor a (128) must match the size of tensor b (20) at non-singleton dimension 3\n",
            "[W 2025-05-06 11:32:21,034] Trial 5 failed with value None.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (128) must match the size of tensor b (20) at non-singleton dimension 3",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnombre_del_estudio\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# puedes elegirlo t√∫\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///optuna_studies/study_convlstm.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# üß† crea archivo .db en tu carpeta\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# por si ya existe, contin√∫a donde lo dejaste\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[40], line 30\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 30\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[0;32m     32\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\utils.py:148\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, criterion, optimizer, device, epoch, total_epochs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    146\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m--> 148\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    150\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\functional.py:3791\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[0;32m   3793\u001b[0m     expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3794\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (20) at non-singleton dimension 3"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"nombre_del_estudio\",  # puedes elegirlo t√∫\n",
        "    storage=\"sqlite:///optuna_studies/study_convlstm.db\",  # üß† crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, contin√∫a donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358d1f45",
      "metadata": {
        "id": "358d1f45"
      },
      "outputs": [],
      "source": [
        "print(\"Best trial:\")\n",
        "for key, val in study.best_trial.params.items():\n",
        "    print(f\"{key}: {val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e950fcd",
      "metadata": {
        "id": "0e950fcd"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study).show()\n",
        "optuna.visualization.plot_param_importances(study).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79656890",
      "metadata": {
        "id": "79656890"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac41ec4",
      "metadata": {
        "id": "5ac41ec4"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperpar√°metros estructurales\n",
        "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256, 512])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 6)\n",
        "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4, 8])\n",
        "    dim_feedforward_factor = trial.suggest_int(\"dim_ff_factor\", 2, 6)\n",
        "    use_temporal_channel = trial.suggest_categorical(\"use_temporal_channel\", [False, True])\n",
        "\n",
        "    # Hiperpar√°metros de entrenamiento\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
        "\n",
        "    # Elegir optimizador\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"])\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader, val_loader = get_data_loaders_from_tensors(batch_size)\n",
        "\n",
        "    # Modelo\n",
        "    class CustomTransformerDecoder(TransformerDecoder):\n",
        "        def __init__(self, embedding_dim, num_layers, nhead, dim_ff, dropout):\n",
        "            super().__init__(embedding_dim, num_layers, nhead)\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_ff,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    model = GenericSpatioTemporalDecoder(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        in_channels=3,\n",
        "        use_temporal_channel=use_temporal_channel\n",
        "    ).to(device)\n",
        "\n",
        "    # Reemplazar el decoder por uno con dropout y tama√±o FF ajustado\n",
        "    model.temporal_decoder = CustomTransformerDecoder(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        dim_ff=embedding_dim * dim_feedforward_factor,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer_cls = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"RMSprop\": torch.optim.RMSprop}[optimizer_name]\n",
        "    optimizer = optimizer_cls(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Entrenamiento\n",
        "    best_val_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93468e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e93468e3",
        "outputId": "093405cd-3df5-4d78-ec68-694e617fe982"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 11:25:13,744] A new study created in RDB with name: decoder1\n",
            "c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "  warnings.warn(\n",
            "Epoch 1/10 - Training:   0%|          | 0/32 [00:00<?, ?it/s]c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([32, 1, 20, 13, 13])) that is different to the input size (torch.Size([32, 1, 1, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch 1/10 - Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 29/32 [00:01<00:00, 38.92it/s, loss=0.0487]c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([8, 1, 20, 13, 13])) that is different to the input size (torch.Size([8, 1, 1, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2025-05-06 11:25:19,907] Trial 0 finished with value: 0.04487396510584014 and parameters: {'embedding_dim': 128, 'num_layers': 2, 'nhead': 1, 'dim_ff_factor': 2, 'use_temporal_channel': False, 'batch_size': 32, 'lr': 0.00019970441706714957, 'weight_decay': 2.273120800568371e-06, 'dropout': 0.16863953565403722, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.04487396510584014.\n",
            "Epoch 1/10 - Training:   0%|          | 0/63 [00:00<?, ?it/s]c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([16, 1, 20, 13, 13])) that is different to the input size (torch.Size([16, 1, 1, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2025-05-06 11:25:41,360] Trial 1 finished with value: 0.0473155347773662 and parameters: {'embedding_dim': 512, 'num_layers': 5, 'nhead': 8, 'dim_ff_factor': 5, 'use_temporal_channel': False, 'batch_size': 16, 'lr': 0.001209064349330731, 'weight_decay': 1.4705877462938071e-05, 'dropout': 0.2598781724052648, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.04487396510584014.\n",
            "[I 2025-05-06 11:25:46,783] Trial 2 finished with value: 0.04400619651590075 and parameters: {'embedding_dim': 64, 'num_layers': 2, 'nhead': 8, 'dim_ff_factor': 3, 'use_temporal_channel': False, 'batch_size': 32, 'lr': 0.004770127308932659, 'weight_decay': 1.947229078167483e-06, 'dropout': 0.03958452195478179, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.04400619651590075.\n",
            "[I 2025-05-06 11:25:59,231] Trial 3 finished with value: 0.04570222789278397 and parameters: {'embedding_dim': 64, 'num_layers': 6, 'nhead': 8, 'dim_ff_factor': 2, 'use_temporal_channel': True, 'batch_size': 16, 'lr': 0.0018899354793789616, 'weight_decay': 3.838328048615317e-06, 'dropout': 0.11313399154990553, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.04400619651590075.\n",
            "[I 2025-05-06 11:26:16,500] Trial 4 finished with value: 0.04225574567914009 and parameters: {'embedding_dim': 256, 'num_layers': 2, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.0006205495149215425, 'weight_decay': 5.448371936569403e-06, 'dropout': 0.029478485029753896, 'optimizer': 'AdamW'}. Best is trial 4 with value: 0.04225574567914009.\n",
            "[I 2025-05-06 11:26:18,694] Trial 5 pruned.                                        \n",
            "[I 2025-05-06 11:26:21,445] Trial 6 pruned.                                           \n",
            "[I 2025-05-06 11:26:24,141] Trial 7 pruned.                                          \n",
            "[I 2025-05-06 11:26:24,874] Trial 8 pruned.                                        \n",
            "[I 2025-05-06 11:26:41,460] Trial 9 finished with value: 0.04337637707591057 and parameters: {'embedding_dim': 128, 'num_layers': 3, 'nhead': 2, 'dim_ff_factor': 2, 'use_temporal_channel': False, 'batch_size': 8, 'lr': 0.00015614410241718334, 'weight_decay': 2.358569956358099e-06, 'dropout': 0.21746823172650617, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.04225574567914009.\n",
            "[I 2025-05-06 11:26:55,623] Trial 10 finished with value: 0.03166840195655823 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00038455328702488513, 'weight_decay': 0.003991391265013607, 'dropout': 0.0010486873855304543, 'optimizer': 'AdamW'}. Best is trial 10 with value: 0.03166840195655823.\n",
            "[I 2025-05-06 11:27:09,957] Trial 11 finished with value: 0.02679059997200966 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00044705557551759806, 'weight_decay': 0.006653138311259327, 'dropout': 0.006116567588937374, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:27:24,209] Trial 12 finished with value: 0.030958633944392203 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00031965721830277, 'weight_decay': 0.006327576311638901, 'dropout': 0.016411487989501435, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:27:37,965] Trial 13 finished with value: 0.04177577555179596 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 5, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00028481487678627833, 'weight_decay': 0.008453107497106597, 'dropout': 0.0006011177102152737, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:27:42,947] Trial 14 pruned.                                         \n",
            "c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\pruners\\_percentile.py:21: RuntimeWarning: All-NaN slice encountered\n",
            "  return np.nanmin(values)\n",
            "[I 2025-05-06 11:27:44,573] Trial 15 pruned. \n",
            "[I 2025-05-06 11:28:01,264] Trial 16 finished with value: 0.04227642461657524 and parameters: {'embedding_dim': 256, 'num_layers': 2, 'nhead': 2, 'dim_ff_factor': 5, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00010783212741517716, 'weight_decay': 7.823235853021282e-05, 'dropout': 0.13300131823560493, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:28:09,642] Trial 17 pruned.                                         \n",
            "[I 2025-05-06 11:28:10,928] Trial 18 pruned.                                       \n",
            "[I 2025-05-06 11:28:11,692] Trial 19 pruned.                                       \n",
            "[I 2025-05-06 11:28:41,904] Trial 20 pruned.                                          \n",
            "[I 2025-05-06 11:28:47,483] Trial 21 pruned.                                          \n",
            "[I 2025-05-06 11:28:53,263] Trial 22 pruned.                                          \n",
            "[I 2025-05-06 11:28:56,778] Trial 23 pruned.                                         \n",
            "[I 2025-05-06 11:29:10,676] Trial 24 finished with value: 0.04150837540626526 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00016734418457986419, 'weight_decay': 0.0007746916383294535, 'dropout': 0.01872206351981416, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:29:12,185] Trial 25 pruned.                                          \n",
            "[I 2025-05-06 11:29:13,679] Trial 26 pruned.                                         \n",
            "[I 2025-05-06 11:29:18,226] Trial 27 pruned.                                         \n",
            "[I 2025-05-06 11:29:18,843] Trial 28 pruned.                                      \n",
            "[I 2025-05-06 11:29:19,879] Trial 29 pruned.                                       \n",
            "[I 2025-05-06 11:29:21,103] Trial 30 pruned.                                       \n",
            "[I 2025-05-06 11:29:34,980] Trial 31 finished with value: 0.036447759866714474 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.00017373395755339546, 'weight_decay': 0.0007279986465451004, 'dropout': 0.015664959378440535, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:29:49,068] Trial 32 finished with value: 0.04121098831295967 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.0001516844713860682, 'weight_decay': 0.0016995923792997832, 'dropout': 0.014919203218851087, 'optimizer': 'AdamW'}. Best is trial 11 with value: 0.02679059997200966.\n",
            "[I 2025-05-06 11:29:52,686] Trial 33 pruned.                                         \n",
            "[I 2025-05-06 11:29:54,580] Trial 34 pruned.                                         \n",
            "[I 2025-05-06 11:29:55,426] Trial 35 pruned.                                        \n",
            "[I 2025-05-06 11:29:58,228] Trial 36 pruned.                                         \n",
            "[I 2025-05-06 11:30:06,512] Trial 37 pruned.                                          \n",
            "[I 2025-05-06 11:30:07,546] Trial 38 pruned.                                       \n",
            "[I 2025-05-06 11:30:08,625] Trial 39 pruned.                                       \n",
            "[I 2025-05-06 11:30:10,333] Trial 40 pruned.                                        \n",
            "[I 2025-05-06 11:30:11,903] Trial 41 pruned.                                         \n",
            "[I 2025-05-06 11:30:24,118] Trial 42 pruned.                                          \n",
            "[I 2025-05-06 11:30:32,135] Trial 43 pruned.                                          \n",
            "[I 2025-05-06 11:30:40,636] Trial 44 pruned.                                          \n",
            "[I 2025-05-06 11:30:52,696] Trial 45 pruned.                                          \n",
            "[I 2025-05-06 11:30:56,432] Trial 46 pruned.                                         \n",
            "[I 2025-05-06 11:31:05,914] Trial 47 pruned.                                         \n",
            "[I 2025-05-06 11:31:20,194] Trial 48 finished with value: 0.02450983926653862 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.0003414932288993386, 'weight_decay': 0.00624608421877893, 'dropout': 0.06447200840935602, 'optimizer': 'AdamW'}. Best is trial 48 with value: 0.02450983926653862.\n",
            "[I 2025-05-06 11:31:21,315] Trial 49 pruned.                                       \n",
            "[I 2025-05-06 11:31:22,056] Trial 50 pruned.                                      \n",
            "[I 2025-05-06 11:31:35,780] Trial 51 finished with value: 0.031241235435009004 and parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.0003624737246213666, 'weight_decay': 0.00713132362917297, 'dropout': 0.0024040779106329594, 'optimizer': 'AdamW'}. Best is trial 48 with value: 0.02450983926653862.\n",
            "[I 2025-05-06 11:31:44,081] Trial 52 pruned.                                          \n",
            "[W 2025-05-06 11:31:56,682] Trial 53 failed with parameters: {'embedding_dim': 256, 'num_layers': 1, 'nhead': 2, 'dim_ff_factor': 6, 'use_temporal_channel': True, 'batch_size': 8, 'lr': 0.0003245208593473029, 'weight_decay': 0.0033253908681085266, 'dropout': 0.04879670458460052, 'optimizer': 'AdamW'} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\ismael.gallo\\AppData\\Local\\Temp\\ipykernel_2892\\1241698156.py\", line 61, in objective\n",
            "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
            "  File \"c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\utils.py\", line 153, in train_one_epoch\n",
            "    total_loss += loss.item()\n",
            "KeyboardInterrupt\n",
            "[W 2025-05-06 11:31:56,682] Trial 53 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder1\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# puedes elegirlo t√∫\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     storage\u001b[38;5;241m=\u001b[39mstorage_url,  \u001b[38;5;66;03m# üß† crea archivo .db en tu carpeta\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# por si ya existe, contin√∫a donde lo dejaste\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Mostrar el mejor resultado\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç Best trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[29], line 61\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     59\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 61\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[0;32m     63\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\utils.py:153\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, criterion, optimizer, device, epoch, total_epochs)\u001b[0m\n\u001b[0;32m    150\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    151\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 153\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"decoder1\",  # puedes elegirlo t√∫\n",
        "    storage=storage_url,  # üß† crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, contin√∫a donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Mostrar el mejor resultado\n",
        "print(\"üîç Best trial:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d69a161",
      "metadata": {
        "id": "3d69a161"
      },
      "outputs": [],
      "source": [
        "import optuna.visualization as vis\n",
        "\n",
        "vis.plot_optimization_history(study).show()\n",
        "vis.plot_param_importances(study).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71120961",
      "metadata": {
        "id": "71120961"
      },
      "source": [
        "## Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc94e0b3",
      "metadata": {
        "id": "fc94e0b3"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos una sola vez\n",
        "dataset_train = load_trimmed_dataset(\n",
        "    base_path=dir_path, dataset_type='train',\n",
        "    max_samples=n_train, time_steps_output=sequence_length\n",
        ")\n",
        "dataset_val = load_trimmed_dataset(\n",
        "    base_path=dir_path, dataset_type='val',\n",
        "    max_samples=n_val, time_steps_output=sequence_length\n",
        ")\n",
        "\n",
        "x_train, y_train = prepare_data_for_convlstm(dataset_train, device='cpu')\n",
        "x_val, y_val = prepare_data_for_convlstm(dataset_val, device='cpu')\n",
        "\n",
        "train_dataset = TemporalRegressionDataset(x_train, y_train)\n",
        "val_dataset = TemporalRegressionDataset(x_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66140c54",
      "metadata": {
        "id": "66140c54"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperpar√°metros\n",
        "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4])\n",
        "    dim_ff_factor = trial.suggest_int(\"dim_ff_factor\", 2, 6)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"])\n",
        "\n",
        "    # DataLoaders desde datasets pre-cargados\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Modelo\n",
        "    model = GenericSpatioTemporalRegressor(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        in_channels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Reemplazo del decoder por uno personalizado con dropout y FF dimensionado\n",
        "    class CustomTransformerDecoder(TransformerDecoder):\n",
        "        def __init__(self, embedding_dim, num_layers, nhead, dim_ff, dropout):\n",
        "            super().__init__(embedding_dim, num_layers, nhead)\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_ff,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    model.temporal_decoder = CustomTransformerDecoder(\n",
        "        embedding_dim=embedding_dim * 2,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        dim_ff=embedding_dim * dim_ff_factor,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer_cls = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"RMSprop\": torch.optim.RMSprop}[optimizer_name]\n",
        "    optimizer = optimizer_cls(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caabb460",
      "metadata": {
        "id": "caabb460"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"nombre_del_estudio\",  # puedes elegirlo t√∫\n",
        "    storage=\"sqlite:///optuna_studies/study_regressor.db\",  # üß† crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, contin√∫a donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Mostrar el mejor resultado\n",
        "print(\"üîç Best trial:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ismael_minimal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
