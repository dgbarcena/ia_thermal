{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d47121a7",
      "metadata": {
        "id": "d47121a7"
      },
      "source": [
        "# Pruebas con Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ae1c4f",
      "metadata": {
        "id": "27ae1c4f"
      },
      "source": [
        "### Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7569b95a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7569b95a",
        "outputId": "1a8b397c-3d98-456b-fa91-698833755edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modo: Local\n",
            "Ruta datasets: C:\\Users\\ismael.gallo/ia_thermal_colab\\datasets\n",
            "Ruta modelos: C:\\Users\\ismael.gallo/ia_thermal_colab\\models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import IPython\n",
        "\n",
        "# Detectar si estamos en Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Ruta base\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/ia_thermal_colab\"\n",
        "else:\n",
        "    BASE_PATH = os.path.expanduser(\"~/ia_thermal_colab\")\n",
        "\n",
        "DATASETS_PATH = os.path.join(BASE_PATH, \"datasets\")\n",
        "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "\n",
        "os.makedirs(DATASETS_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Modo:\", \"Colab\" if IN_COLAB else \"Local\")\n",
        "print(\"Ruta datasets:\", DATASETS_PATH)\n",
        "print(\"Ruta modelos:\", MODELS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "de808483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "de808483",
        "outputId": "c2582acf-227b-4b27-f20a-7f0b33a22541"
      },
      "outputs": [],
      "source": [
        "# üîÑ Par√°metros del repo\n",
        "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia esto\n",
        "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "CLONE_PATH = os.path.join(BASE_PATH, REPO_NAME)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # üß¨ Clonar el repositorio si no existe ya\n",
        "    if not os.path.exists(CLONE_PATH):\n",
        "        !git clone {GIT_REPO_URL} {CLONE_PATH}\n",
        "    else:\n",
        "        print(f\"Repositorio ya clonado en: {CLONE_PATH}\")\n",
        "\n",
        "    # üì¶ Instalar requirements.txt\n",
        "    req_path = os.path.join(CLONE_PATH, \"requirements.txt\")\n",
        "    if os.path.exists(req_path):\n",
        "        !pip install -r {req_path}\n",
        "    else:\n",
        "        print(\"No se encontr√≥ requirements.txt en el repositorio.\")\n",
        "\n",
        "    print(\"üîÑ Reinicia el entorno para aplicar los cambios...\")\n",
        "    IPython.display.display(IPython.display.Javascript('''google.colab.restartRuntime()'''))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7da63d97",
      "metadata": {
        "id": "7da63d97"
      },
      "source": [
        "## Inicializar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "4160dabe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4160dabe",
        "outputId": "e7d1f6f7-cabd-48b5-d020-ecc4ea38b561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ruta que usar√° SQLite: sqlite:///\\content\\drive\\MyDrive\\ia_thermal_colab\\optuna_studies\\test_study.db\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get the directory path of the file\n",
        "dir_path = os.getcwd()\n",
        "\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal\")\n",
        "\n",
        "from plot_functions import *\n",
        "from Physics_Loss import *\n",
        "from utils import *\n",
        "sys.path.append('../Convolutional_NN')\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN\")\n",
        "\n",
        "from Dataset_Class import *\n",
        "\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo\")\n",
        "\n",
        "from architectures.convlstm import *\n",
        "from architectures.generic_spatiotemporal_decoder import *\n",
        "from architectures.generic_spatiotemporal_regressor import *\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Ruta absoluta y segura dentro de Drive\n",
        "study_path = Path(\"/content/drive/MyDrive/ia_thermal_colab/optuna_studies\")\n",
        "study_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "db_path = study_path / \"test_study.db\"\n",
        "storage_url = f\"sqlite:///{db_path}\"\n",
        "\n",
        "print(\"Ruta que usar√° SQLite:\", storage_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "HIICVI3PGJV5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIICVI3PGJV5",
        "outputId": "ba16dc3b-88ed-4bb4-ec52-d5a65055ab7b"
      },
      "outputs": [],
      "source": [
        "# def objective(trial):\n",
        "#     x = trial.suggest_float(\"x\", -10, 10)\n",
        "#     return x ** 2\n",
        "\n",
        "# study = optuna.create_study(\n",
        "#     direction=\"minimize\",\n",
        "#     storage=storage_url,\n",
        "#     study_name=\"test_study\",\n",
        "#     load_if_exists=True\n",
        "# )\n",
        "\n",
        "# study.optimize(objective, n_trials=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "kbsWVc7LGMU5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbsWVc7LGMU5",
        "outputId": "bb560d97-f48a-4fc6-bee8-fdd3f766e4f3"
      },
      "outputs": [],
      "source": [
        "# print(\"‚úÖ ¬øExiste el archivo?\", db_path.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69e9ffd",
      "metadata": {
        "id": "a69e9ffd"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "n_train = 1000\n",
        "n_val = 200\n",
        "\n",
        "sequence_length = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e679264a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e679264a",
        "outputId": "5a2dc75f-7978-44fa-a803-caf3e63500b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cargando dataset train desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_transient_dataset_train.pth\n",
            "‚úÖ Cargando dataset val desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_transient_dataset_val.pth\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  dir_path = BASE_PATH\n",
        "\n",
        "# ‚¨ÖÔ∏è Esto se ejecuta una vez\n",
        "dataset_train = load_trimmed_dataset(\n",
        "    base_path=dir_path,\n",
        "    dataset_type='train',\n",
        "    max_samples=n_train,\n",
        "    time_steps_output=sequence_length\n",
        ")\n",
        "dataset_val = load_trimmed_dataset(\n",
        "    base_path=dir_path,\n",
        "    dataset_type='val',\n",
        "    max_samples=n_val,\n",
        "    time_steps_output=sequence_length\n",
        ")\n",
        "\n",
        "# Convertir a tensores de entrada y salida\n",
        "input_train, output_train = prepare_data_for_convlstm(dataset_train, device='cpu')\n",
        "input_val, output_val = prepare_data_for_convlstm(dataset_val, device='cpu')\n",
        "\n",
        "\n",
        "def get_data_loaders_from_tensors(batch_size):\n",
        "    train_loader = DataLoader(TensorDataset(input_train, output_train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(TensorDataset(input_val, output_val), batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd475b6c",
      "metadata": {
        "id": "dd475b6c"
      },
      "source": [
        "## ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "cE5MyqliEwkB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE5MyqliEwkB",
        "outputId": "a94b76c7-eee9-459a-cc2a-d33b1f2de039"
      },
      "outputs": [],
      "source": [
        "# print(\"Ruta completa del .db:\", storage_url.replace(\"sqlite:///\", \"\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "bz1cW5TfE1p5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz1cW5TfE1p5",
        "outputId": "dddfb21b-e2b3-4c33-8da1-bab43ffa8529"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# print(\"¬øExiste el archivo?:\", os.path.exists(storage_url.replace(\"sqlite:///\", \"\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "RSn6cDyuFJ75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSn6cDyuFJ75",
        "outputId": "3dec4060-472a-4fd0-f8ae-7e6a34ef31d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 12:36:43,959] A new study created in RDB with name: test_study\n",
            "[I 2025-05-06 12:36:45,626] Trial 0 finished with value: 4.7560397290313965 and parameters: {'x': -2.180834640460252}. Best is trial 0 with value: 4.7560397290313965.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    return trial.suggest_float(\"x\", -10, 10) ** 2\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    storage=\"sqlite:////content/drive/MyDrive/ia_thermal_colab/optuna_studies/test_dummy.db\",\n",
        "    study_name=\"test_study\",\n",
        "    load_if_exists=True\n",
        ")\n",
        "study.optimize(objective, n_trials=1)\n",
        "\n",
        "import os\n",
        "print(os.path.exists(\"/content/drive/MyDrive/ia_thermal_colab/optuna_studies/test_dummy.db\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "5c25d49d",
      "metadata": {
        "id": "5c25d49d"
      },
      "outputs": [],
      "source": [
        "class ConvLSTMWrapper(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convlstm = ConvLSTM(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            kernel_size=kernel_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bias=True,\n",
        "            return_all_layers=False\n",
        "        )\n",
        "\n",
        "        self.output_conv = nn.Conv2d(\n",
        "            in_channels=hidden_dim[-1],\n",
        "            out_channels=1,\n",
        "            kernel_size=1  # ‚úÖ produce salida de 1 canal sin cambiar tama√±o\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # x: [B, T, C, 13, 13]\n",
        "        lstm_output, _ = self.convlstm(x)  # lstm_output is [layer_output_list]\n",
        "        y = lstm_output[0]  # [B, T, hidden_dim[-1], 13, 13]\n",
        "\n",
        "        # Aplicar conv final a cada paso temporal\n",
        "        B, T, C, H, W = y.shape\n",
        "        y = y.view(B * T, C, H, W)\n",
        "        y = self.output_conv(y)             # [B*T, 1, 13, 13]\n",
        "        y = y.view(B, T, 1, H, W)           # [B, T, 1, 13, 13]\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "6764169f",
      "metadata": {
        "id": "6764169f"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperpar√°metros\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
        "    hidden_dim_val = trial.suggest_categorical(\"hidden_dim\", [16, 32, 64, 128])\n",
        "    kernel_size_val = trial.suggest_categorical(\"kernel_size\", [1, 3, 5, 7])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "\n",
        "    # Adaptar al formato requerido por ConvLSTM\n",
        "    hidden_dim = [hidden_dim_val] * num_layers\n",
        "    kernel_size = [(kernel_size_val, kernel_size_val)] * num_layers\n",
        "\n",
        "    # Crear modelo ConvLSTM\n",
        "    model = ConvLSTMWrapper(\n",
        "        input_dim=3,  # o el n√∫mero de canales reales\n",
        "        hidden_dim=hidden_dim,\n",
        "        kernel_size=kernel_size,\n",
        "        num_layers=num_layers\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Obtener dataloaders (train y val)\n",
        "    train_loader, val_loader = get_data_loaders_from_tensors(batch_size=batch_size)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "5a861fab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a861fab",
        "outputId": "582ac60b-47e1-4eba-abd3-63b1749faa14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 12:37:07,487] Using an existing study with name 'convlstm' instead of creating a new one.\n",
            "Epoch 1/10 - Training:   0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning:\n",
            "\n",
            "Using a target size (torch.Size([64, 1, 20, 13, 13])) that is different to the input size (torch.Size([64, 1, 1, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\n",
            "Epoch 1/10 - Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:00<00:00, 44.95it/s, loss=0.395]c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning:\n",
            "\n",
            "Using a target size (torch.Size([40, 1, 20, 13, 13])) that is different to the input size (torch.Size([40, 1, 1, 13, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\n",
            "[I 2025-05-06 12:37:10,710] Trial 1 finished with value: 0.05529384035617113 and parameters: {'lr': 0.00837817254286601, 'batch_size': 64, 'hidden_dim': 64, 'kernel_size': 1, 'num_layers': 3}. Best is trial 1 with value: 0.05529384035617113.\n",
            "[I 2025-05-06 12:37:12,042] Trial 2 finished with value: 0.8635045737028122 and parameters: {'lr': 0.00029795286210330935, 'batch_size': 64, 'hidden_dim': 32, 'kernel_size': 3, 'num_layers': 1}. Best is trial 1 with value: 0.05529384035617113.\n",
            "[I 2025-05-06 12:37:14,761] Trial 3 finished with value: 0.05267427010195596 and parameters: {'lr': 0.0011975923071317865, 'batch_size': 32, 'hidden_dim': 16, 'kernel_size': 3, 'num_layers': 3}. Best is trial 3 with value: 0.05267427010195596.\n",
            "[I 2025-05-06 12:37:25,204] Trial 4 finished with value: 0.0755251981317997 and parameters: {'lr': 0.0011814609936976368, 'batch_size': 64, 'hidden_dim': 64, 'kernel_size': 5, 'num_layers': 4}. Best is trial 3 with value: 0.05267427010195596.\n",
            "[W 2025-05-06 12:38:44,977] Trial 5 failed with parameters: {'lr': 0.0022345783894975506, 'batch_size': 64, 'hidden_dim': 128, 'kernel_size': 7, 'num_layers': 3} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\ismael.gallo\\AppData\\Local\\Temp\\ipykernel_2892\\503547808.py\", line 30, in objective\n",
            "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
            "  File \"c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\utils.py\", line 153, in train_one_epoch\n",
            "    total_loss += loss.item()\n",
            "KeyboardInterrupt\n",
            "[W 2025-05-06 12:38:44,977] Trial 5 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[68], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# puedes elegirlo t√∫\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(study_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy_convlstm.db\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# üß† crea archivo .db en tu carpeta\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# por si ya existe, contin√∫a donde lo dejaste\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[67], line 30\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 30\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[0;32m     32\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
            "File \u001b[1;32mc:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\utils.py:153\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, criterion, optimizer, device, epoch, total_epochs)\u001b[0m\n\u001b[0;32m    150\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    151\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 153\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"convlstm\",  # puedes elegirlo t√∫\n",
        "    storage=\"sqlite:///\" + os.path.join(study_path, \"study_convlstm.db\"),  # üß† crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, contin√∫a donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358d1f45",
      "metadata": {
        "id": "358d1f45"
      },
      "outputs": [],
      "source": [
        "print(\"Best trial:\")\n",
        "for key, val in study.best_trial.params.items():\n",
        "    print(f\"{key}: {val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e950fcd",
      "metadata": {
        "id": "0e950fcd"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study).show()\n",
        "optuna.visualization.plot_param_importances(study).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79656890",
      "metadata": {
        "id": "79656890"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac41ec4",
      "metadata": {
        "id": "5ac41ec4"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperpar√°metros estructurales\n",
        "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256, 512])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 6)\n",
        "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4, 8])\n",
        "    dim_feedforward_factor = trial.suggest_int(\"dim_ff_factor\", 2, 6)\n",
        "    use_temporal_channel = trial.suggest_categorical(\"use_temporal_channel\", [False, True])\n",
        "\n",
        "    # Hiperpar√°metros de entrenamiento\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
        "\n",
        "    # Elegir optimizador\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"])\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader, val_loader = get_data_loaders_from_tensors(batch_size)\n",
        "\n",
        "    # Modelo\n",
        "    class CustomTransformerDecoder(TransformerDecoder):\n",
        "        def __init__(self, embedding_dim, num_layers, nhead, dim_ff, dropout):\n",
        "            super().__init__(embedding_dim, num_layers, nhead)\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_ff,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    model = GenericSpatioTemporalDecoder(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        in_channels=3,\n",
        "        use_temporal_channel=use_temporal_channel\n",
        "    ).to(device)\n",
        "\n",
        "    # Reemplazar el decoder por uno con dropout y tama√±o FF ajustado\n",
        "    model.temporal_decoder = CustomTransformerDecoder(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        dim_ff=embedding_dim * dim_feedforward_factor,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer_cls = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"RMSprop\": torch.optim.RMSprop}[optimizer_name]\n",
        "    optimizer = optimizer_cls(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Entrenamiento\n",
        "    best_val_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93468e3",
      "metadata": {
        "id": "e93468e3"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"decoder1\",  # puedes elegirlo t√∫\n",
        "    storage=storage_url,  # üß† crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, contin√∫a donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Mostrar el mejor resultado\n",
        "print(\"üîç Best trial:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d69a161",
      "metadata": {
        "id": "3d69a161"
      },
      "outputs": [],
      "source": [
        "import optuna.visualization as vis\n",
        "\n",
        "vis.plot_optimization_history(study).show()\n",
        "vis.plot_param_importances(study).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71120961",
      "metadata": {
        "id": "71120961"
      },
      "source": [
        "## Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc94e0b3",
      "metadata": {
        "id": "fc94e0b3"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos una sola vez\n",
        "dataset_train = load_trimmed_dataset(\n",
        "    base_path=dir_path, dataset_type='train',\n",
        "    max_samples=n_train, time_steps_output=sequence_length\n",
        ")\n",
        "dataset_val = load_trimmed_dataset(\n",
        "    base_path=dir_path, dataset_type='val',\n",
        "    max_samples=n_val, time_steps_output=sequence_length\n",
        ")\n",
        "\n",
        "x_train, y_train = prepare_data_for_convlstm(dataset_train, device='cpu')\n",
        "x_val, y_val = prepare_data_for_convlstm(dataset_val, device='cpu')\n",
        "\n",
        "train_dataset = TemporalRegressionDataset(x_train, y_train)\n",
        "val_dataset = TemporalRegressionDataset(x_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66140c54",
      "metadata": {
        "id": "66140c54"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hiperpar√°metros\n",
        "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4])\n",
        "    dim_ff_factor = trial.suggest_int(\"dim_ff_factor\", 2, 6)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"])\n",
        "\n",
        "    # DataLoaders desde datasets pre-cargados\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Modelo\n",
        "    model = GenericSpatioTemporalRegressor(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        in_channels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Reemplazo del decoder por uno personalizado con dropout y FF dimensionado\n",
        "    class CustomTransformerDecoder(TransformerDecoder):\n",
        "        def __init__(self, embedding_dim, num_layers, nhead, dim_ff, dropout):\n",
        "            super().__init__(embedding_dim, num_layers, nhead)\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim,\n",
        "                nhead=nhead,\n",
        "                dim_feedforward=dim_ff,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    model.temporal_decoder = CustomTransformerDecoder(\n",
        "        embedding_dim=embedding_dim * 2,\n",
        "        num_layers=num_layers,\n",
        "        nhead=nhead,\n",
        "        dim_ff=embedding_dim * dim_ff_factor,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer_cls = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"RMSprop\": torch.optim.RMSprop}[optimizer_name]\n",
        "    optimizer = optimizer_cls(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, epochs)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "        trial.report(val_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caabb460",
      "metadata": {
        "id": "caabb460"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"nombre_del_estudio\",  # puedes elegirlo t√∫\n",
        "    storage=\"sqlite:///optuna_studies/study_regressor.db\",  # üß† crea archivo .db en tu carpeta\n",
        "    load_if_exists=True  # por si ya existe, contin√∫a donde lo dejaste\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Mostrar el mejor resultado\n",
        "print(\"üîç Best trial:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
