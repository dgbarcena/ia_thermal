{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phV4LvGoyQP7"
      },
      "source": [
        "# PINN RNN POD reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXmvXNYXyQP-"
      },
      "source": [
        "Celda para que funcione en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3SyPL8tRyQP_",
        "outputId": "76e48e76-1440-446a-cdbe-3d5c5b8ad060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Modo: Colab\n",
            "Ruta datasets: /content/drive/MyDrive/ia_thermal_colab/datasets\n",
            "Ruta modelos: /content/drive/MyDrive/ia_thermal_colab/models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import IPython\n",
        "\n",
        "# Detectar si estamos en Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Ruta base\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/ia_thermal_colab\"\n",
        "else:\n",
        "    BASE_PATH = os.path.expanduser(\"~/ia_thermal_colab\")\n",
        "\n",
        "DATASETS_PATH = os.path.join(BASE_PATH, \"datasets\")\n",
        "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "\n",
        "os.makedirs(DATASETS_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Modo:\", \"Colab\" if IN_COLAB else \"Local\")\n",
        "print(\"Ruta datasets:\", DATASETS_PATH)\n",
        "print(\"Ruta modelos:\", MODELS_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÑ Par√°metros del repo\n",
        "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia esto\n",
        "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "CLONE_PATH = os.path.join(BASE_PATH, REPO_NAME)\n",
        "\n",
        "# üß¨ Clonar el repositorio si no existe ya\n",
        "if not os.path.exists(CLONE_PATH):\n",
        "    !git clone {GIT_REPO_URL} {CLONE_PATH}\n",
        "else:\n",
        "    print(f\"Repositorio ya clonado en: {CLONE_PATH}\")\n",
        "\n",
        "# üì¶ Instalar requirements.txt\n",
        "req_path = os.path.join(CLONE_PATH, \"requirements.txt\")\n",
        "if os.path.exists(req_path):\n",
        "    !pip install -r {req_path}\n",
        "else:\n",
        "    print(\"No se encontr√≥ requirements.txt en el repositorio.\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üîÑ Reinicia el entorno para aplicar los cambios...\")\n",
        "    IPython.display.display(IPython.display.Javascript('''google.colab.restartRuntime()'''))\n"
      ],
      "metadata": {
        "id": "Oy7TgJKN0afm",
        "outputId": "9f004a1f-41d8-420f-d948-dab3cc4b2b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repositorio ya clonado en: /content/drive/MyDrive/ia_thermal_colab/ia_thermal\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (2.5.1)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 3)) (0.20.1)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 4)) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 11)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.4.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (6.5.7)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (7.16.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 25)) (1.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 26)) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 25)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 10)) (3.2.3)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 19)) (3.0.13)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.0.5)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (75.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (1.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (2.18.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.14.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.3.7)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (21.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (2.21.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 22)) (2.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.24.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (0.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 18)) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 21)) (2.22)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (24.11.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/ia_thermal_colab/ia_thermal/requirements.txt (line 20)) (2.9.0.20241206)\n",
            "üîÑ Reinicia el entorno para aplicar los cambios...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.restartRuntime()"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-tBD9O_0yQQB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "from IPython.display import display, Markdown\n",
        "import platform\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import seaborn as sns\n",
        "\n",
        "# import sklearn\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "# from torch import nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "# get the directory path of the file\n",
        "dir_path = os.getcwd()\n",
        "\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal\")\n",
        "\n",
        "from plot_functions import *\n",
        "from Physics_Loss import *\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo\")\n",
        "\n",
        "from convlstm import *\n",
        "\n",
        "sys.path.append('../Convolutional_NN')\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN\")\n",
        "\n",
        "from Dataset_Class import *\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "# torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5zrx7mpyQQB"
      },
      "source": [
        "Configuraci√≥n global de Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jFYTB9YayQQC"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({\n",
        "    # 'text.usetex': True,  # Usar LaTeX para el texto (Local)\n",
        "    'text.usetex': False,  # NO Usar LaTeX para el texto (Colab)\n",
        "    'font.family': 'serif',  # Fuente serif\n",
        "    # 'figure.figsize': (10, 6),  # Tama√±o de la figura\n",
        "    'axes.labelsize': 12,  # Tama√±o de las etiquetas de los ejes\n",
        "    'axes.titlesize': 14,  # Tama√±o del t√≠tulo\n",
        "    'legend.fontsize': 12,  # Tama√±o de la leyenda\n",
        "    'xtick.labelsize': 10,  # Tama√±o de las etiquetas del eje x\n",
        "    'ytick.labelsize': 10,  # Tama√±o de las etiquetas del eje y\n",
        "    'axes.grid': True,  # Habilitar la cuadr√≠cula\n",
        "    'grid.alpha': 0.75,  # Transparencia de la cuadr√≠cula\n",
        "    'grid.linestyle': '--'  # Estilo de la l√≠nea de la cuadr√≠cula\n",
        "})\n",
        "\n",
        "# Configuraci√≥n de Seaborn\n",
        "sns.set_context('paper')\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UYPDpkHpyQQC",
        "outputId": "24b50511-0dda-4a60-ebf4-fb2f857d0a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G70jUJ0oyQQD"
      },
      "outputs": [],
      "source": [
        "system_specs = {\n",
        "    \"os\": platform.system(),  # e.g. \"Linux\", \"Windows\", \"Darwin\"\n",
        "    \"os_version\": platform.version(),\n",
        "    \"machine\": platform.machine(),  # e.g. \"x86_64\"\n",
        "    \"processor\": platform.processor(),  # e.g. \"Intel64 Family 6 Model 158\"\n",
        "    \"python_version\": platform.python_version(),\n",
        "    \"device\": str(device)\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    system_specs[\"gpu_name\"] = torch.cuda.get_device_name(0)\n",
        "    system_specs[\"gpu_memory_total_GB\"] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
        "    system_specs[\"cuda_version\"] = torch.version.cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1sqDH_7yQQD"
      },
      "source": [
        "<a id='section_1'></a>\n",
        "# PCB solver trasient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xcquCb43yQQD"
      },
      "outputs": [],
      "source": [
        "sys.path.append('../scripts')\n",
        "\n",
        "if IN_COLAB:\n",
        "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/scripts\")\n",
        "\n",
        "from PCB_solver_tr import PCB_solver_main, PCB_case_1, PCB_case_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOl_GmFJyQQE"
      },
      "source": [
        "# Dataset import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhPbX2IOyQQE"
      },
      "source": [
        "Dataset hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d7BzeJVIyQQE"
      },
      "outputs": [],
      "source": [
        "n_train = 1000\n",
        "n_test = 200\n",
        "n_val = 50\n",
        "time_sim = 100 # seconds\n",
        "\n",
        "batch_size = 30\n",
        "\n",
        "sequence_length = time_sim+1 # seconds\n",
        "dt = 1 # seconds\n",
        "T_init = 298.0 # Kelvin\n",
        "nodes_side = 13 # number of nodes in one side of the PCB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4HJovEdyQQE"
      },
      "source": [
        "Dataset extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TwSrSBkryQQE",
        "outputId": "0b79f85a-0376-40ba-92a7-e85683742303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cargando dataset base desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_transient_dataset.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN/Dataset_Class.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(full_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cargando dataset train desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_transient_dataset_train.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ia_thermal_colab/ia_thermal/Convolutional_NN/Dataset_Class.py:266: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  base_dataset = torch.load(full_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cargando dataset test desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_transient_dataset_test.pth\n",
            "‚úÖ Cargando dataset val desde: /content/drive/MyDrive/ia_thermal_colab/datasets/PCB_transient_dataset_val.pth\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  dir_path = BASE_PATH\n",
        "\n",
        "dataset = load_dataset(base_path=dir_path)  # ‚Üê carga el dataset base completo (PCB_transient_dataset.pth)\n",
        "dataset_train = load_trimmed_dataset(base_path=dir_path, dataset_type='train', max_samples=n_train, time_steps_output=sequence_length)\n",
        "dataset_test = load_trimmed_dataset(base_path=dir_path, dataset_type='test', max_samples=n_test, time_steps_output=sequence_length)\n",
        "dataset_val = load_trimmed_dataset(base_path=dir_path, dataset_type='val', max_samples=n_val, time_steps_output=sequence_length)\n",
        "\n",
        "input_train, output_train = prepare_data_for_convlstm(dataset_train, device=device)\n",
        "input_test, output_test = prepare_data_for_convlstm(dataset_test, device=device)\n",
        "input_val, output_val = prepare_data_for_convlstm(dataset_val, device=device)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(input_train, output_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(input_test, output_test), batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(TensorDataset(input_val, output_val), batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_uUAaVOyQQE"
      },
      "source": [
        "# Convolutional LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jC-5B0oyQQF"
      },
      "source": [
        "## Common to all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D-PcVmzyQQF"
      },
      "source": [
        "### Hyperparameters of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fdqiRli_yQQF"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "lr = 1e-2\n",
        "lrdecay = 0.1\n",
        "lrdecay_patience = 10\n",
        "early_stop_patience = 50\n",
        "\n",
        "hidden_dims = [32] # [64, 32, 16, 8, 16, 32, 64]\n",
        "num_layers = len(hidden_dims)\n",
        "kernel_size = [(3,3) for i in range(num_layers)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDn7Tc1LyQQF"
      },
      "source": [
        "## No-physics Convolutional LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6gae-iQyQQF"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fTZqbVe7yQQF"
      },
      "outputs": [],
      "source": [
        "# from convlstm import *\n",
        "\n",
        "class PCB_ConvLSTM(nn.Module):\n",
        "    def __init__(self, input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13):\n",
        "        super().__init__()\n",
        "        self.convlstm = ConvLSTM(input_dim=input_channels,\n",
        "                                 hidden_dim=hidden_dims,\n",
        "                                 kernel_size=kernel_size,\n",
        "                                 num_layers=len(hidden_dims),\n",
        "                                 batch_first=True,\n",
        "                                 bias=True,\n",
        "                                 return_all_layers=False)\n",
        "\n",
        "        self.decoder = nn.Conv2d(hidden_dims[-1], 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, C, H, W)\n",
        "        lstm_out, _ = self.convlstm(x)  # lstm_out[0]: (B, T, hidden_dim, H, W)\n",
        "\n",
        "        # Apply decoder to each time step\n",
        "        decoded = [self.decoder(lstm_out[0][:, t]) for t in range(x.size(1))]\n",
        "        output = torch.stack(decoded, dim=1)  # (B, T, 1, H, W)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGVYirqQyQQF"
      },
      "source": [
        "Definici√≥n del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eja9iPLeyQQF",
        "outputId": "92b1574c-b9b9-4441-f149-166a311f7165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x est√° en: cpu\n",
            "y est√° en: cpu\n",
            "model est√° en: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = PCB_ConvLSTM(input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=lrdecay, patience=lrdecay_patience, verbose=True)\n",
        "\n",
        "# DEBUGGING\n",
        "# Ensure data is moved to the appropriate device\n",
        "batch = next(iter(train_loader))\n",
        "x, y = batch\n",
        "\n",
        "print(f\"x est√° en: {x.device}\")\n",
        "print(f\"y est√° en: {y.device}\")\n",
        "print(f\"model est√° en: {next(model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPkmf7ZbyQQG"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVAiXob-yQQG"
      },
      "source": [
        "Training and saving best model with best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgbix8pwyQQG",
        "outputId": "47289b82-bd06-4cf6-d161-e46d46d7ff38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**‚ùå El modelo `PCB_ConvLSTM_nt1000_100s_lr0.01_bs30_h1_k3x3.pth` ya existe. Se omite esta celda para evitar sobreescritura.**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/500 - Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 15/34 [03:54<04:51, 15.35s/it]"
          ]
        }
      ],
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "best_test_loss = np.inf\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "kernel_string = f\"{kernel_size[0][0]}x{kernel_size[0][1]}\"\n",
        "model_dir = os.path.join(dir_path, 'models', 'ConvLSTM')\n",
        "\n",
        "if IN_COLAB:\n",
        "  model_dir = os.path.join(MODELS_PATH, 'ConvLSTM')\n",
        "\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Nombre del archivo con hiperpar√°metros\n",
        "filename = f\"PCB_ConvLSTM_nt{n_train}_{time_sim}s_lr{lr}_bs{batch_size}_h{num_layers}_k{kernel_string}.pth\"\n",
        "\n",
        "# Ruta completa del modelo\n",
        "model_path = os.path.join(model_dir, filename)\n",
        "\n",
        "# Comprobar si el modelo ya existe\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    display(Markdown(f\"**‚ùå El modelo `{filename}` ya existe. Se omite esta celda para evitar sobreescritura.**\"))\n",
        "    # Detiene la ejecuci√≥n de esta celda sin interrumpir el notebook\n",
        "    # raise SystemExit\n",
        "\n",
        "# ruta para el JSON\n",
        "json_path = model_path.replace('.pth', '.json')\n",
        "\n",
        "start_time_training = time.time()\n",
        "start_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time_epoch = time.time()\n",
        "\n",
        "    # Entrenamiento\n",
        "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\", leave=False):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.detach().item()\n",
        "\n",
        "    epoch_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validaci√≥n\n",
        "    model.eval()\n",
        "    total_test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            y_pred = model(x_test)\n",
        "            test = criterion(y_pred, y_test)\n",
        "            total_test_loss += test.item()\n",
        "\n",
        "    epoch_test_loss = total_test_loss / len(test_loader)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "\n",
        "    # Scheduler update\n",
        "    scheduler.step(epoch_test_loss)\n",
        "\n",
        "    # Early stopping check\n",
        "    if epoch_test_loss < best_test_loss:\n",
        "        best_test_loss = epoch_test_loss\n",
        "\n",
        "        # Guardar el modelo\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        elapsed_training = time.time() - start_time_training\n",
        "        elapsed_minutes = elapsed_training / 60\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "        # Guardar hiperpar√°metros en JSON\n",
        "        params = {\n",
        "            'start_datetime': start_datetime,\n",
        "            'training_duration_minutes': elapsed_minutes,\n",
        "            \"system_specs\": system_specs,\n",
        "            'hidden_dims': hidden_dims,\n",
        "            'kernel_size': kernel_string,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': lr,\n",
        "            \"scheduler\":{\n",
        "                \"type\": \"ReduceLROnPlateau\",\n",
        "                \"factor\": lrdecay,\n",
        "                \"patience\": lrdecay_patience,\n",
        "                \"final_lr\": current_lr\n",
        "            },\n",
        "            'early_stop_patience': early_stop_patience,\n",
        "            'epochs_trained': epoch + 1,\n",
        "            'best_test_loss': best_test_loss,\n",
        "            \"train_loss\": list(map(float, train_loss)),\n",
        "            \"test_loss\": list(map(float, test_loss)),\n",
        "        }\n",
        "\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(params, f, indent=4)\n",
        "\n",
        "        # print(f\"‚úì Saving model (epoch {epoch+1}) | test_loss improved to {best_test_loss:.6f}\")\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        # print(f\"No improvement for {epochs_without_improvement} epoch(s)\")\n",
        "\n",
        "    if epochs_without_improvement >= early_stop_patience:\n",
        "        print(f\"‚ö†Ô∏è Early stopping at epoch {epoch+1} ‚Äî no improvement for {early_stop_patience} epochs.\")\n",
        "        break\n",
        "\n",
        "    # Estad√≠sticas finales de la √©poca\n",
        "    elapsed_epoch = time.time() - start_time_epoch\n",
        "    # print(f\"Epoch {epoch+1:3d} | Train Loss: {epoch_train_loss:.6f} | Test Loss: {epoch_test_loss:.6f} | Time: {elapsed_epoch:.2f}s\")\n",
        "\n",
        "print(f\"Entrenamiento finalizado en {elapsed_minutes:.2f} minutos.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìÅ El modelo se est√° guardando en:\", model_path)\n"
      ],
      "metadata": {
        "id": "U-UCxIIl9jxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMAi2gEhyQQG"
      },
      "source": [
        "Plotting validation loss and train loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATV1kOdQyQQG"
      },
      "outputs": [],
      "source": [
        "plot_loss_evolution(train_loss, test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VOTdM70yQQG"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU_dLGBeyQQG"
      },
      "outputs": [],
      "source": [
        "# load the best model\n",
        "model = PCB_ConvLSTM(input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13).to(device)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(input_val)  # (B, T, 1, H, W)\n",
        "    val_loss = criterion(y_pred, output_val)\n",
        "    print(f\"Test Loss: {val_loss.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzhssyS3yQQH"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYatBJLqyQQH"
      },
      "source": [
        "We are going to plot the temperature evolution in the four nodes corresponding with the heaters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpXz9WrByQQH"
      },
      "outputs": [],
      "source": [
        "id_heaters = [(6,3), (3,6), (9,3), (9,9)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c25-r2gGyQQH"
      },
      "source": [
        "Boundary conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6IyIWymyQQH"
      },
      "outputs": [],
      "source": [
        "Q_heaters = np.array([1.0, 1.0, 1.0, 1.0])\n",
        "T_interfaces = np.array([250, 250, 250, 250])\n",
        "T_env = 250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFBbajaGyQQH"
      },
      "source": [
        "Actual values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNuPsS5CyQQH"
      },
      "outputs": [],
      "source": [
        "T, _, _, _ = PCB_case_2(solver = 'transient', display=False, time = time_sim, dt = dt, T_init = T_init, Q_heaters = Q_heaters, T_interfaces = T_interfaces, Tenv = T_env) # heaters in default position\n",
        "T = T.reshape(T.shape[0], nodes_side, nodes_side) # reshaping the data grid-shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4D7SIpyQQL"
      },
      "source": [
        "Predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmd1fwE6yQQL"
      },
      "outputs": [],
      "source": [
        "input_tensor = dataset.create_input_from_values(Q_heaters, T_interfaces, T_env, sequence_length=101)\n",
        "\n",
        "output = model(input_tensor)\n",
        "output_denorm = dataset.denormalize_output(output)\n",
        "T_pred = output_denorm[0,:,0,:,:].cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lM62xcmyQQL"
      },
      "outputs": [],
      "source": [
        "plot_nodes_evolution(T_pred, T, id_heaters, together=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK2MYrOWyQQM"
      },
      "source": [
        "## Physics informed Convolutional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnfGBcmPyQQM"
      },
      "outputs": [],
      "source": [
        "# from Physics_Loss import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "PdmId4gCyQQM"
      },
      "source": [
        "### New loss function validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0WDNmjsyQQM"
      },
      "source": [
        "Validation of the Physics loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV2klzyIyQQM"
      },
      "outputs": [],
      "source": [
        "# Crear instancia de la clase de p√©rdida\n",
        "physics_loss = PhysicsLossTransient().to(device)\n",
        "\n",
        "# Par√°metros\n",
        "B = 1        # batch size\n",
        "H = W = 13    # dimensiones espaciales\n",
        "\n",
        "# Obtener datos reales del solver\n",
        "T2, _, interfaces2, heaters2 = PCB_case_2(solver='transient', display=False, time=100, dt=1, T_init=298.0)\n",
        "T = T2.shape[0]      # n√∫mero de pasos temporales\n",
        "\n",
        "# Temperatura: [B, T, 1, 13, 13]\n",
        "T_tensor = torch.tensor(T2, dtype=torch.float32).view(T, 1, H, W).unsqueeze(0).repeat(B, 1, 1, 1, 1).to(device)\n",
        "\n",
        "interfaces_input = torch.tensor([list(interfaces2.values())], dtype=torch.float32).repeat(B, 1).to(device) # [B, 4]\n",
        "heaters_input = torch.tensor([list(heaters2.values())], dtype=torch.float32).repeat(B, 1).to(device) # [B, 4]\n",
        "Tenv = torch.full((B, 1), 250.0).to(device) # [B, 1]\n",
        "\n",
        "# Calcular la p√©rdida\n",
        "loss = physics_loss(\n",
        "    T_pred=T_tensor,\n",
        "    T_true=T_tensor,\n",
        "    heaters_input=heaters_input,\n",
        "    interfaces_input=interfaces_input,\n",
        "    Tenv=Tenv\n",
        ")\n",
        "\n",
        "# # Mostrar resultado\n",
        "print(f\"Physics loss (esperada ‚âà 0): {loss.item():.6e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "degRji3syQQM"
      },
      "source": [
        "Validation of the boundary loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCYgsLlayQQM"
      },
      "outputs": [],
      "source": [
        "# Crear una instancia de BoundaryLoss con valores predeterminados\n",
        "boundary_loss = BoundaryLoss()\n",
        "\n",
        "# Ejemplo de tensores\n",
        "interfaces_example = torch.tensor(list(interfaces2.values()), dtype=torch.float32).unsqueeze(0)\n",
        "T2_reshaped = torch.tensor(T2).view(1, 101, 1, 13, 13).to(device)  # [B, T, 1, H, W]\n",
        "\n",
        "# Calcular la p√©rdida\n",
        "loss = boundary_loss(T2_reshaped, interfaces_example)\n",
        "print(\"P√©rdida en las interfaces:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYSB6VhyQQN"
      },
      "source": [
        "Funci√≥n para extraer las condiciones de contorno de los tensores de los 3 canales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuGXDosyyQQN"
      },
      "outputs": [],
      "source": [
        "def extract_boundary_conditions_from_dataset(input_tensor, dataset: PCBDataset, nodes_side=13):\n",
        "    \"\"\"\n",
        "    Extrae las condiciones de contorno originales (desnormalizadas) a partir de un input_tensor y el dataset asociado.\n",
        "    input_tensor: tensor de forma [batch, sequence_length, 3, nodes_side, nodes_side]\n",
        "    \"\"\"\n",
        "    input_0 = input_tensor[0, 0]  # [3, 13, 13]\n",
        "\n",
        "    T_interfaces1 = input_0[0]\n",
        "    Q_heaters1 = input_0[1]\n",
        "    T_env1 = input_0[2]\n",
        "\n",
        "    # Extraer los valores originales usando los m√©todos de desnormalizaci√≥n del dataset\n",
        "    T_interfaces_raw = torch.tensor([\n",
        "        T_interfaces1[0, 0],\n",
        "        T_interfaces1[0, nodes_side - 1],\n",
        "        T_interfaces1[nodes_side - 1, nodes_side - 1],\n",
        "        T_interfaces1[nodes_side - 1, 0]\n",
        "    ], device=input_tensor.device)\n",
        "    T_interfaces_in = dataset.denormalize_T_interfaces(T_interfaces_raw)\n",
        "\n",
        "    Q_heaters_raw = torch.tensor([\n",
        "        Q_heaters1[6, 3],\n",
        "        Q_heaters1[3, 6],\n",
        "        Q_heaters1[9, 3],\n",
        "        Q_heaters1[9, 9]\n",
        "    ], device=input_tensor.device)\n",
        "    Q_heaters_in = dataset.denormalize_Q_heaters(Q_heaters_raw)\n",
        "\n",
        "    T_env_in = dataset.denormalize_T_env(T_env1[0, 0])\n",
        "\n",
        "    return Q_heaters_in, T_interfaces_in, T_env_in\n",
        "\n",
        "\n",
        "def extract_all_boundary_conditions(input_tensor, dataset: PCBDataset, nodes_side=13):\n",
        "    \"\"\"\n",
        "    Extrae las condiciones de contorno desnormalizadas de todos los ejemplos del batch.\n",
        "    Retorna tres listas: Q_heaters_all, T_interfaces_all, T_env_all.\n",
        "    \"\"\"\n",
        "    batch_size = input_tensor.shape[0]\n",
        "    Q_heaters_all = []\n",
        "    T_interfaces_all = []\n",
        "    T_env_all = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        q, t_int, t_env = extract_boundary_conditions_from_dataset(input_tensor[i:i+1], dataset, nodes_side)\n",
        "        Q_heaters_all.append(q)\n",
        "        T_interfaces_all.append(t_int)\n",
        "        T_env_all.append(t_env)\n",
        "\n",
        "    Q_heaters_all = torch.stack(Q_heaters_all)       # [batch_size, 4]\n",
        "    T_interfaces_all = torch.stack(T_interfaces_all) # [batch_size, 4]\n",
        "    T_env_all = torch.stack(T_env_all)               # [batch_size]\n",
        "\n",
        "    return Q_heaters_all, T_interfaces_all, T_env_all\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lds-HzipyQQN"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-3S-KhryQQN"
      },
      "source": [
        "Hyperparameters of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7ua50RmyQQN"
      },
      "outputs": [],
      "source": [
        "mse_weight = 1.0\n",
        "phy_weight = 0.0000\n",
        "bnd_weight = 0.0000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QnyMk8qyQQN"
      },
      "outputs": [],
      "source": [
        "# from convlstm import *\n",
        "\n",
        "class PCB_ConvLSTM_physics(nn.Module):\n",
        "    def __init__(self, input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13):\n",
        "        super().__init__()\n",
        "        self.convlstm = ConvLSTM(input_dim=input_channels,\n",
        "                                 hidden_dim=hidden_dims,\n",
        "                                 kernel_size=kernel_size,\n",
        "                                 num_layers=len(hidden_dims),\n",
        "                                 batch_first=True,\n",
        "                                 bias=True,\n",
        "                                 return_all_layers=False)\n",
        "\n",
        "        self.decoder = nn.Conv2d(hidden_dims[-1], 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, C, H, W)\n",
        "        lstm_out, _ = self.convlstm(x)  # lstm_out[0]: (B, T, hidden_dim, H, W)\n",
        "\n",
        "        # Apply decoder to each time step\n",
        "        decoded = [self.decoder(lstm_out[0][:, t]) for t in range(x.size(1))]\n",
        "        output = torch.stack(decoded, dim=1)  # (B, T, 1, H, W)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzsWT8hAyQQN"
      },
      "source": [
        "Definici√≥n del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAv25zlxyQQO"
      },
      "outputs": [],
      "source": [
        "dataset_train.base_dataset.return_bc = True\n",
        "dataset_test.base_dataset.return_bc = True\n",
        "\n",
        "train_ds = prepare_data_with_bc(dataset_train, device=device)\n",
        "train_loader_phy = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_ds = prepare_data_with_bc(dataset_test, device=device)\n",
        "test_loader_phy = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = PCB_ConvLSTM_physics(input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13).to(device)\n",
        "\n",
        "total_loss_fn = TotalLoss(\n",
        "    mse_weight=mse_weight,\n",
        "    physics_weight=phy_weight,\n",
        "    boundary_weight=bnd_weight,\n",
        "    denormalize_output_fn=dataset.denormalize_output\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=lrdecay, patience=lrdecay_patience, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RACNs8zyQQO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNrse8iNyQQO"
      },
      "source": [
        "Training and saving best model with best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S79n__WyQQO"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "loss_mse = []\n",
        "loss_phy = []\n",
        "loss_bndry = []\n",
        "\n",
        "best_test_loss = np.inf\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "kernel_string = f\"{kernel_size[0][0]}x{kernel_size[0][1]}\"\n",
        "model_dir = os.path.join(dir_path, 'models', 'ConvLSTM')\n",
        "if IN_COLAB:\n",
        "  model_dir = os.path.join(MODELS_PATH, 'ConvLSTM')\n",
        "\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Nombre del archivo con hiperpar√°metros\n",
        "filename_phy = f\"PCB_ConvLSTM_nt{n_train}_{time_sim}s_lr{lr}_bs{batch_size}_h{len(hidden_dims)}_k{kernel_string}_phy_{phy_weight}_bnd{bnd_weight}.pth\"\n",
        "\n",
        "# Ruta completa del modelo\n",
        "model_path_phy = os.path.join(model_dir, filename_phy)\n",
        "\n",
        "# Comprobar si el modelo ya existe\n",
        "if os.path.exists(model_path_phy):\n",
        "    display(Markdown(f\"**‚ùå El modelo `{filename_phy}` ya existe. Se omite esta celda para evitar sobreescritura.**\"))\n",
        "    # Detiene la ejecuci√≥n de esta celda sin interrumpir el notebook\n",
        "    # raise SystemExit\n",
        "\n",
        "# ruta para el JSON\n",
        "json_path_phy = model_path_phy.replace('.pth', '.json')\n",
        "\n",
        "start_time_training = time.time()\n",
        "start_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_loss_mse = 0.0\n",
        "    total_loss_phy = 0.0\n",
        "    total_loss_bndry = 0.0\n",
        "    start_time_epoch = time.time()\n",
        "\n",
        "    # Entrenamiento\n",
        "    for x, y, bc_all in tqdm(train_loader_phy, desc=f\"Epoch {epoch+1}/{epochs} - Training\", leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        q = bc_all[:, 0:4] # sin normalizar\n",
        "        t_int = bc_all[:, 4:8] # sin normalizar\n",
        "        t_env = bc_all[:, 8].unsqueeze(1) # sin normalizar\n",
        "\n",
        "        q_denorm     = dataset.denormalize_Q_heaters(q)\n",
        "        t_int_denorm = dataset.denormalize_T_interfaces(t_int)\n",
        "        t_env_denorm = dataset.denormalize_T_env(t_env)\n",
        "        y_denorm     = dataset.denormalize_output(y)\n",
        "\n",
        "        y_hat = model(x) # model prediction\n",
        "        y_hat_denorm = dataset.denormalize_output(y_hat)\n",
        "\n",
        "        loss, loss_mse_batch, loss_phys_batch, loss_bdry_batch = total_loss_fn(y_hat, y, q_denorm, t_int_denorm, t_env_denorm)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.detach().item()\n",
        "        total_loss_mse += loss_mse_batch.item()\n",
        "        total_loss_phy += loss_phys_batch.item()\n",
        "        total_loss_bndry += loss_bdry_batch.item()\n",
        "\n",
        "    epoch_train_loss = total_loss / len(train_loader_phy)\n",
        "    epoch_loss_mse = total_loss_mse / len(train_loader_phy)\n",
        "    epoch_loss_phy = total_loss_phy / len(train_loader_phy)\n",
        "    epoch_loss_bndry = total_loss_bndry / len(train_loader_phy)\n",
        "\n",
        "    train_loss.append(epoch_train_loss)\n",
        "    loss_mse.append(epoch_loss_mse)\n",
        "    loss_phy.append(epoch_loss_phy)\n",
        "    loss_bndry.append(epoch_loss_bndry)\n",
        "\n",
        "    # Validaci√≥n\n",
        "    model.eval()\n",
        "    total_test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test, bc_test in test_loader_phy:\n",
        "\n",
        "            q = bc_test[:, 0:4]\n",
        "            t_int = bc_test[:, 4:8]\n",
        "            t_env = bc_test[:, 8].unsqueeze(1)\n",
        "\n",
        "            q_denorm     = dataset.denormalize_Q_heaters(q)\n",
        "            t_int_denorm = dataset.denormalize_T_interfaces(t_int)\n",
        "            t_env_denorm = dataset.denormalize_T_env(t_env)\n",
        "            y_denorm     = dataset.denormalize_output(y)\n",
        "            y_hat_denorm = dataset.denormalize_output(y_hat)\n",
        "\n",
        "            y_pred = model(x_test)\n",
        "\n",
        "            test_loss_comb, _, _, _ = total_loss_fn(y_pred, y_test, q_denorm, t_int_denorm, t_env_denorm)\n",
        "            total_test_loss += test_loss_comb.item()\n",
        "\n",
        "    epoch_test_loss = total_test_loss / len(test_loader_phy)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "\n",
        "    # Scheduler update\n",
        "    scheduler.step(epoch_test_loss)\n",
        "\n",
        "    elapsed_minutes = (time.time() - start_time_training) / 60\n",
        "\n",
        "    # Early stopping check\n",
        "    if epoch_test_loss < best_test_loss:\n",
        "        best_test_loss = epoch_test_loss\n",
        "\n",
        "        # Guardar el modelo\n",
        "        torch.save(model.state_dict(), model_path_phy)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Guardar hiperpar√°metros en JSON\n",
        "        params = {\n",
        "            'start_datetime': start_datetime,\n",
        "            'training_duration_minutes': elapsed_minutes,\n",
        "            \"system_specs\": system_specs,\n",
        "            'hidden_dims': hidden_dims,\n",
        "            'kernel_size': kernel_string,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': lr,\n",
        "            \"scheduler\":{\n",
        "                \"type\": \"ReduceLROnPlateau\",\n",
        "                \"factor\": lrdecay,\n",
        "                \"patience\": lrdecay_patience,\n",
        "                \"final_lr\": current_lr\n",
        "            },\n",
        "            'early_stop_patience': early_stop_patience,\n",
        "            'epochs_trained': epoch + 1,\n",
        "            'best_test_loss': best_test_loss,\n",
        "            \"train_loss\": list(map(float, train_loss)),\n",
        "            \"test_loss\": list(map(float, test_loss)),\n",
        "            \"physics\": {\n",
        "                \"phy_param\": phy_weight,\n",
        "                \"bnd_param\": bnd_weight,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(json_path_phy, 'w') as f:\n",
        "            json.dump(params, f, indent=4)\n",
        "\n",
        "        # print(f\"‚úì Saving model (epoch {epoch+1}) | test_loss improved to {best_test_loss:.6f}\")\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        # print(f\"No improvement for {epochs_without_improvement} epoch(s)\")\n",
        "\n",
        "    if epochs_without_improvement >= early_stop_patience:\n",
        "        print(f\"‚ö†Ô∏è Early stopping at epoch {epoch+1} ‚Äî no improvement for {early_stop_patience} epochs.\")\n",
        "        break\n",
        "\n",
        "    # Estad√≠sticas finales de la √©poca\n",
        "    elapsed_epoch = time.time() - start_time_epoch\n",
        "    # print(f\"Epoch {epoch+1:3d} | Train Loss: {epoch_train_loss:.6f} | Test Loss: {epoch_test_loss:.6f} | Time: {elapsed_epoch:.2f}s\")\n",
        "\n",
        "print(f\"Entrenamiento finalizado en {elapsed_minutes:.2f} minutos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3uS8GdgyQQO"
      },
      "source": [
        "Plotting validation loss and train loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6QT9Mm5yQQO"
      },
      "outputs": [],
      "source": [
        "plot_loss_evolution(train_loss, test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWTZ9mpXyQQP"
      },
      "outputs": [],
      "source": [
        "# Ensure loss_phy and loss_bndry are converted to NumPy arrays for element-wise multiplication\n",
        "loss_mse = np.array(loss_mse)\n",
        "loss_phy = np.array(loss_phy)\n",
        "loss_bndry = np.array(loss_bndry)\n",
        "\n",
        "plt.plot(loss_mse * mse_weight, label=f'MSE Loss*{mse_weight}', color='blue')\n",
        "plt.plot(loss_phy * phy_weight, label=f'Physics Loss*{phy_weight}', color='orange')\n",
        "plt.plot(loss_bndry * bnd_weight, label=f'Boundary Loss*{bnd_weight}', color='green')\n",
        "plt.plot(test_loss, label='Total Loss', color='red')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlim(0, len(train_loss)-1)\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.title('Loss Components')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-MEUfJsyQQP"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV-Oe_6IyQQP"
      },
      "outputs": [],
      "source": [
        "# load the best model\n",
        "model = PCB_ConvLSTM_physics(input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13).to(device)\n",
        "model.load_state_dict(torch.load(model_path_phy))\n",
        "model.eval()\n",
        "\n",
        "criterion = nn.MSELoss() # para comparar colo con la recostrucci√≥n\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(input_val)  # (B, T, 1, H, W)\n",
        "    val_loss = criterion(y_pred, output_val)\n",
        "    print(f\"Test Loss: {val_loss.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJRcdvB2yQQP"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdgAjDvdyQQP"
      },
      "source": [
        "We are going to plot the temperature evolution in the four nodes corresponding with the heaters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvaEkYzxyQQP"
      },
      "outputs": [],
      "source": [
        "id_heaters = [(6,3), (3,6), (9,3), (9,9)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv4Wemc7yQQP"
      },
      "source": [
        "Boundary conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIFx-VNiyQQQ"
      },
      "outputs": [],
      "source": [
        "Q_heaters = np.array([1.0, 1.0, 1.0, 1.0])\n",
        "T_interfaces = np.array([250, 250, 250, 250])\n",
        "T_env = 250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwOghOyuyQQQ"
      },
      "source": [
        "Actual values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0CMhpnHyQQQ"
      },
      "outputs": [],
      "source": [
        "T, _, _, _ = PCB_case_2(solver = 'transient', display=False, time = time_sim, dt = dt, T_init = T_init, Q_heaters = Q_heaters, T_interfaces = T_interfaces, Tenv = T_env) # heaters in default position\n",
        "T = T.reshape(T.shape[0], nodes_side, nodes_side) # reshaping the data grid-shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYnOw-mzyQQQ"
      },
      "source": [
        "Predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1TakCLZyQQQ"
      },
      "outputs": [],
      "source": [
        "input_tensor = dataset.create_input_from_values(Q_heaters, T_interfaces, T_env, sequence_length=sequence_length)\n",
        "\n",
        "output = model(input_tensor)\n",
        "output_denorm = dataset.denormalize_output(output)\n",
        "T_pred = output_denorm[0,:,0,:,:].cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPN6Cl-CyQQQ"
      },
      "outputs": [],
      "source": [
        "plot_nodes_evolution(T_pred, T, id_heaters, together=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB3xpTKFyQQQ"
      },
      "source": [
        "Error en la predicci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwckh7pDyQQQ"
      },
      "outputs": [],
      "source": [
        "plot_se_map(T_pred, T, time=100, show_pred=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CXst2CayQQR"
      },
      "source": [
        "Error en la predicci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHBLrRGByQQR"
      },
      "outputs": [],
      "source": [
        "plot_se_map(T_pred, T, time=100, show_pred=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLiq4JsiyQQR"
      },
      "source": [
        "## Comparison of models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyVx2fz9yQQR"
      },
      "source": [
        "Loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yolswH_myQQR"
      },
      "outputs": [],
      "source": [
        "model = PCB_ConvLSTM(input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13).to(device)\n",
        "model_phy = PCB_ConvLSTM_physics(input_channels=3, hidden_dims=hidden_dims, kernel_size=kernel_size, height=13, width=13).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device).eval()\n",
        "model_phy.load_state_dict(torch.load(model_path_phy))\n",
        "model_phy.to(device).eval()\n",
        "print(f\"Modelos cargados en dispositivo {device} y listos para evaluar.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPRL1uMhyQQR"
      },
      "source": [
        "Generating random data to evaluate the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gpg28KWyQQR"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "Q_random = np.random.uniform(0.1, 1.25, 4)\n",
        "T_interfaces_random = np.random.uniform(260, 310, 4)\n",
        "T_env_random = np.random.uniform(260, 310)\n",
        "\n",
        "input_tensor = dataset.create_input_from_values(Q_heaters, T_interfaces, T_env, sequence_length=sequence_length)\n",
        "\n",
        "T_true = PCB_case_2(solver='transient', display=False, time=100, dt=1, T_init=298.0, Q_heaters=Q_random, T_interfaces=T_interfaces_random, Tenv=T_env_random)[0]\n",
        "T_true = T_true.reshape(T_true.shape[0], nodes_side, nodes_side) # reshaping the data grid-shape\n",
        "\n",
        "pred = model(input_tensor).cpu().detach()[0,:,0,:,:]\n",
        "T_pred = dataset.denormalize_output(torch.tensor(pred)).numpy()\n",
        "\n",
        "pred_phy = model_phy(input_tensor).cpu().detach()[0,:,0,:,:]\n",
        "T_pred_phy = dataset.denormalize_output(torch.tensor(pred_phy)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib4prZeCyQQR"
      },
      "source": [
        "Error calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5B6YfRpyQQS"
      },
      "outputs": [],
      "source": [
        "error = T_true - T_pred\n",
        "error_phy = T_true - T_pred_phy\n",
        "\n",
        "error_last = error[-1]\n",
        "error_phy_last = error_phy[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvyIWXFbyQQS"
      },
      "source": [
        "Non-PINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nemetkm3yQQS"
      },
      "outputs": [],
      "source": [
        "plot_prediction_and_error(T_pred, T_true, t=100, cmap='hot', save_as_pdf=False, filename='prediction_and_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugyOzveRyQQS"
      },
      "source": [
        "PINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQXElnZUyQQS"
      },
      "outputs": [],
      "source": [
        "plot_prediction_and_error(T_pred_phy, T_true, t=-1, cmap='hot', save_as_pdf=False, filename='prediction_and_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfI8YVRGyQQS"
      },
      "source": [
        "Error plot comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q70j6wHPyQQS"
      },
      "outputs": [],
      "source": [
        "compare_error_maps_2d(error_last, error_phy_last, (\"Error sin f√≠sica\", \"Error con f√≠sica\"), save_as_pdf=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}