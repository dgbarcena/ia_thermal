{
    "start_datetime": "2025-06-17 13:07:26",
    "training_duration_minutes": 13.318534962336223,
    "model_parameters": 456769,
    "system_specs": {
        "platform": "Linux-6.1.123+-x86_64-with-glibc2.35",
        "python_version": "3.11.13",
        "torch_version": "2.5.1+cu124",
        "cuda_available": true,
        "cuda_version": "12.4",
        "gpu_count": 1,
        "primary_gpu_name": "NVIDIA L4",
        "gpu_details": {
            "gpu_0": {
                "name": "NVIDIA L4",
                "memory_total_gb": 22.16,
                "compute_capability": "8.9",
                "multi_processor_count": 58
            }
        },
        "cpu_count_logical": 12,
        "cpu_count_physical": 6,
        "memory_total_gb": 52.96
    },
    "simulation_time": 200,
    "dt": 2,
    "n_train": 1000,
    "n_val": 200,
    "n_test": 20,
    "input_channels": 6,
    "sequence_length": 101,
    "epochs": 1000,
    "hidden_dims": [
        64,
        64
    ],
    "kernel_size": [
        [
            3,
            3
        ],
        [
            3,
            3
        ]
    ],
    "scheduled_sampling": {
        "p0": 1.0,
        "p_min": 0.0,
        "decay_epochs": 200
    },
    "batch_size": 64,
    "lr": 1.0000000000000004e-08,
    "scheduler": {
        "type": "ReduceLROnPlateau",
        "factor": 0.1,
        "patience": 10,
        "final_lr": 1.0000000000000004e-08
    },
    "early_stop_patience": 100,
    "epochs_trained": 149,
    "best_val_loss": 0.03583703329786658,
    "train_loss": [
        0.9078786950558424,
        0.1932784435339272,
        0.06136081088334322,
        0.04060107539407909,
        0.07020335411652923,
        0.028798236162401736,
        0.013561337953433394,
        0.008982165600173175,
        0.006959418969927356,
        0.005859382450580597,
        0.004900855084997602,
        0.004723481310065836,
        0.004815367661649361,
        0.005045380050432868,
        0.004586813956848346,
        0.005002414662158117,
        0.004664836102165282,
        0.0032904246036196128,
        0.0025162072415696457,
        0.002235889660369139,
        0.0021495867986232042,
        0.0021303941393853165,
        0.002112679649144411,
        0.0021164058343856595,
        0.0020967122763977386,
        0.002109873639710713,
        0.002069228961772751,
        0.0020896813002764247,
        0.002062831015791744,
        0.002041861262114253,
        0.002037717575149145,
        0.0020471032403293066,
        0.002017865794186946,
        0.0020039773517055437,
        0.002040470571955666,
        0.001978718297323212,
        0.0019662417616927996,
        0.002046652210992761,
        0.0019882974374922924,
        0.001981228037038818,
        0.0019906619781977497,
        0.002009119649301283,
        0.001981167384656146,
        0.0019561586377676576,
        0.001937582295795437,
        0.001928795849380549,
        0.0019288758558104746,
        0.001960513967787847,
        0.0019192295876564458,
        0.0019219283494749106,
        0.0019660022808238864,
        0.0019637546574813314,
        0.001958269305760041,
        0.0019430423926678486,
        0.0019919845872209407,
        0.001998829175136052,
        0.0019554314567358233,
        0.0019824032351607457,
        0.00197518416098319,
        0.0019661975238705054,
        0.0019346417248016223,
        0.00192896906810347,
        0.0019337762569193728,
        0.001932319202751387,
        0.0019437070804997347,
        0.0019416318027651869,
        0.0019398990407353267,
        0.0019455406145425513,
        0.001950130084878765,
        0.0019532264486770146,
        0.0019480873379507102,
        0.0019618310980149545,
        0.001964093440619763,
        0.0019590886004152708,
        0.001967883108591195,
        0.0019707286992343143,
        0.0019954690360464156,
        0.0019675412695505656,
        0.001976680418010801,
        0.0019865549184032716,
        0.0019968011329183355,
        0.0020081707334611565,
        0.0020066856741323136,
        0.002014994344790466,
        0.0020168054179521278,
        0.0020173814045847394,
        0.0020240318044670857,
        0.0020358915207907557,
        0.0020405592294991948,
        0.002041009021922946,
        0.002052939140412491,
        0.0020568978870869614,
        0.002053232878097333,
        0.00207481919642305,
        0.002084237275994383,
        0.0020905000492348336,
        0.0021081863887957297,
        0.0021191827472648583,
        0.002117046926287003,
        0.0021197683745413087,
        0.0021239379784674384,
        0.0021305254122125916,
        0.0021347841611714102,
        0.0021631120034726337,
        0.002158591611078009,
        0.0021663411025656387,
        0.002176538051571697,
        0.0021893231823923998,
        0.002179990420700051,
        0.0022051184641895816,
        0.002226368189440109,
        0.002214053471107036,
        0.002247486285341438,
        0.002245753727038391,
        0.0022702549322275445,
        0.002255620544019621,
        0.002280366730701644,
        0.0022834758856333792,
        0.0023164736267062835,
        0.002298519015312195,
        0.0023299637250602245,
        0.002341359533602372,
        0.002349443318962585,
        0.002349051952478476,
        0.0023642804662813433,
        0.0023775503068463877,
        0.002418761985609308,
        0.002422052166366484,
        0.0024112806568155065,
        0.0024368111771764234,
        0.0024803840133245103,
        0.0024821360275382176,
        0.0024593698180979118,
        0.002509380632545799,
        0.0025409717636648566,
        0.002521825459552929,
        0.0025511720596114174,
        0.002597314611193724,
        0.002649096102686599,
        0.0026135706139029935,
        0.0026656870904844254,
        0.0026898392679868266,
        0.0027190070977667347,
        0.0027308533171890303,
        0.002724122110521421,
        0.002769836995867081,
        0.002812479477142915,
        0.002826270618243143,
        0.002885993686504662
    ],
    "val_loss": [
        0.6819945573806763,
        0.9087066352367401,
        1.0940061807632446,
        1.0122753828763962,
        0.5985048338770866,
        0.7918650358915329,
        0.4876822754740715,
        0.3334074765443802,
        0.36376016587018967,
        0.672920823097229,
        0.4395862966775894,
        0.8246640413999557,
        1.047978013753891,
        0.8304247111082077,
        0.4748377129435539,
        1.835867166519165,
        1.5117011368274689,
        0.6167571693658829,
        0.4406973123550415,
        0.2824479825794697,
        0.1573959942907095,
        0.17744679376482964,
        0.18398289941251278,
        0.1705427411943674,
        0.14756700489670038,
        0.13412219658493996,
        0.15637591108679771,
        0.17160387244075537,
        0.14157703891396523,
        0.14711328875273466,
        0.165457084774971,
        0.15860819164663553,
        0.16012986935675144,
        0.13451576605439186,
        0.13866660837084055,
        0.14926071744412184,
        0.13247875683009624,
        0.0820606634952128,
        0.04311088053509593,
        0.05229984549805522,
        0.05350204976275563,
        0.09474972868338227,
        0.07647816929966211,
        0.0766099807806313,
        0.0763045884668827,
        0.0829028645530343,
        0.06000878755003214,
        0.048241766169667244,
        0.045924017671495676,
        0.03583703329786658,
        0.048409244511276484,
        0.04998376406729221,
        0.052386267110705376,
        0.056218440644443035,
        0.05798793025314808,
        0.0657429383136332,
        0.09674183186143637,
        0.12129946425557137,
        0.131319809705019,
        0.1269586468115449,
        0.12046378897503018,
        0.12013160507194698,
        0.12094274396076798,
        0.12029443867504597,
        0.12024520756676793,
        0.11930158664472401,
        0.11983890645205975,
        0.11972407856956124,
        0.11917488323524594,
        0.1182098682038486,
        0.11874676821753383,
        0.11581780086271465,
        0.11682908772490919,
        0.11777354055084288,
        0.11776304733939469,
        0.11782243568450212,
        0.11762969079427421,
        0.11709283059462905,
        0.1175104072317481,
        0.11778270523063838,
        0.11765034683048725,
        0.11719081667251885,
        0.11722058732993901,
        0.11722293426282704,
        0.11727478844113648,
        0.11722854827530682,
        0.11726418370380998,
        0.11729199043475091,
        0.11735711432993412,
        0.11736777587793767,
        0.11737375659868121,
        0.11745348758995533,
        0.11740582180209458,
        0.11738161416724324,
        0.11737769423052669,
        0.11738128936849535,
        0.11738386820070446,
        0.11737764533609152,
        0.11739474604837596,
        0.11737704114057124,
        0.11736455140635371,
        0.11737749050371349,
        0.11736952024511993,
        0.1173712972085923,
        0.11735762981697917,
        0.11735798185691237,
        0.1173577590379864,
        0.11735606426373124,
        0.11735122906975448,
        0.11735539766959846,
        0.11735977791249752,
        0.11736122937873006,
        0.11736163427121937,
        0.11736008315347135,
        0.11735891248099506,
        0.11736922431737185,
        0.1173659551423043,
        0.11736600333824754,
        0.1173640894703567,
        0.11736112250946462,
        0.1173566859215498,
        0.11736434511840343,
        0.11736348900012672,
        0.11736651393584907,
        0.11736677261069417,
        0.11736691812984645,
        0.1173617229796946,
        0.11735443468205631,
        0.11736374674364924,
        0.11735620279796422,
        0.11735991481691599,
        0.11735622747801244,
        0.11735792690888047,
        0.11735371639952064,
        0.11735997814685106,
        0.11736210226081312,
        0.11736384639516473,
        0.11736291879788041,
        0.11736006662249565,
        0.1173590945545584,
        0.117355118971318,
        0.11735187377780676,
        0.11735374736599624,
        0.11734759481623769,
        0.11734714894555509,
        0.1173444704618305,
        0.11734449677169323,
        0.11733995843678713,
        0.11733481544069946
    ],
    "training_config": {
        "amp_enabled": true,
        "use_compile": false,
        "clip_grad": null,
        "device_type": "cuda",
        "cudnn_benchmark": true
    }
}