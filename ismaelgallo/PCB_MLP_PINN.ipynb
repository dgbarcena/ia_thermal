{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127321bf",
   "metadata": {},
   "source": [
    "# MLP transient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89305a8e",
   "metadata": {},
   "source": [
    "## Previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa7860",
   "metadata": {},
   "source": [
    "Para que funcione en Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802a673f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo: Local\n",
      "Ruta datasets: C:\\Users\\ismael.gallo/ia_thermal_colab\\datasets\n",
      "Ruta modelos: C:\\Users\\ismael.gallo/ia_thermal_colab\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import IPython\n",
    "\n",
    "# Detectar si estamos en Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Ruta base\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_PATH = \"/content/drive/MyDrive/ia_thermal_colab\"\n",
    "else:\n",
    "    BASE_PATH = os.path.expanduser(\"~/ia_thermal_colab\")\n",
    "\n",
    "DATASETS_PATH = os.path.join(BASE_PATH, \"datasets\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
    "\n",
    "os.makedirs(DATASETS_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"Modo:\", \"Colab\" if IN_COLAB else \"Local\")\n",
    "print(\"Ruta datasets:\", DATASETS_PATH)\n",
    "print(\"Ruta modelos:\", MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce43b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Par√°metros del repo\n",
    "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia esto\n",
    "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "CLONE_PATH = os.path.join(BASE_PATH, REPO_NAME)\n",
    "\n",
    "if IN_COLAB:\n",
    "    # üß¨ Clonar el repositorio si no existe ya\n",
    "    if not os.path.exists(CLONE_PATH):\n",
    "        !git clone {GIT_REPO_URL} {CLONE_PATH}\n",
    "    else:\n",
    "        print(f\"Repositorio ya clonado en: {CLONE_PATH}\")\n",
    "\n",
    "    # üì¶ Instalar requirements.txt\n",
    "    req_path = os.path.join(CLONE_PATH, \"requirements.txt\")\n",
    "    if os.path.exists(req_path):\n",
    "        !pip install -r {req_path}\n",
    "    else:\n",
    "        print(\"No se encontr√≥ requirements.txt en el repositorio.\")\n",
    "\n",
    "    print(\"üîÑ Reinicia el entorno para aplicar los cambios...\")\n",
    "    IPython.display.display(IPython.display.Javascript('''google.colab.restartRuntime()'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7dd21",
   "metadata": {},
   "source": [
    "Importaci√≥n de librer√≠as necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a1b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import optuna\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# get the directory path of the file\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "if IN_COLAB:\n",
    "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal\")\n",
    "\n",
    "from plot_functions import *\n",
    "from Physics_Loss import *\n",
    "from utils import *\n",
    "\n",
    "if IN_COLAB:\n",
    "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo\")\n",
    "\n",
    "from architectures.mlp_pcb import *\n",
    "\n",
    "from Dataset_Class_mlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85f2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be876f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_specs = {\n",
    "    \"os\": platform.system(),  # e.g. \"Linux\", \"Windows\", \"Darwin\"\n",
    "    \"os_version\": platform.version(),\n",
    "    \"machine\": platform.machine(),  # e.g. \"x86_64\"\n",
    "    \"processor\": platform.processor(),  # e.g. \"Intel64 Family 6 Model 158\"\n",
    "    \"python_version\": platform.python_version(),\n",
    "    \"device\": str(device)\n",
    "}\n",
    "if torch.cuda.is_available():\n",
    "    system_specs[\"gpu_name\"] = torch.cuda.get_device_name(0)\n",
    "    system_specs[\"gpu_memory_total_GB\"] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
    "    system_specs[\"cuda_version\"] = torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa2a2e",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fed6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_test = 200\n",
    "n_val = 20\n",
    "time_sim = 1000 # seconds\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "sequence_length = time_sim+1 # seconds\n",
    "dt = 1 # seconds\n",
    "T_init = 298.0 # Kelvin\n",
    "nodes_side = 13 # number of nodes in one side of the PCB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e01f5",
   "metadata": {},
   "source": [
    "Dataset extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c033746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cargando mlp transient dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\Dataset_Class_mlp.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(full_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset_train.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\Dataset_Class_mlp.py:277: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  base_dataset = torch.load(full_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset_val.pth\n",
      "Cargando dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset_test.pth\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "  dir_path = BASE_PATH\n",
    "\n",
    "base_dataset = load_dataset_mlp(base_path=dir_path)  # ‚Üê carga el dataset base completo (PCB_mlp_transient_dataset.pth)\n",
    "dataset_train = load_trimmed_dataset_mlp(base_path=dir_path, dataset_type='train', max_cases=n_train, to_device=True)\n",
    "dataset_val = load_trimmed_dataset_mlp(base_path=dir_path, dataset_type='val', max_cases=n_val, to_device=True)\n",
    "dataset_test = load_trimmed_dataset_mlp(base_path=dir_path, dataset_type='test', max_cases=n_test, to_device=True)\n",
    "\n",
    "loader = DataLoader(base_dataset, batch_size=batch_size, shuffle=False)  # DEBUGGING\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62770947",
   "metadata": {},
   "source": [
    "Debugging para comprobar que cumpla tama√±os que nos interesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3084bc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 10]), torch.Size([1000, 169]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade0c21",
   "metadata": {},
   "source": [
    "## Hyperparameters of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63d188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr = 1e-2\n",
    "lrdecay = 0.1\n",
    "lrdecay_patience = 10\n",
    "early_stop_patience = 100\n",
    "\n",
    "hidden_layers = [64, 128, 256]\n",
    "activation = nn.ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7f1ac",
   "metadata": {},
   "source": [
    "# Non-physics MLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663aab6",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87c0b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_PCB(nn.Module):\n",
    "    def __init__(self, input_dim:int=10, output_dim:int=169, hidden_layers=[128, 128], activation=nn.SiLU):\n",
    "        \"\"\"\n",
    "        Modelo MLP configurable para regresi√≥n.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): N√∫mero de caracter√≠sticas de entrada.\n",
    "            output_dim (int): N√∫mero de salidas (por ejemplo, nodos de temperatura).\n",
    "            hidden_layers (list): Lista con el n√∫mero de neuronas por capa oculta.\n",
    "            activation (callable): Clase de funci√≥n de activaci√≥n (por defecto nn.ReLU).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_dim, h))\n",
    "            layers.append(activation())\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff8073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_PCB(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=169, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MLP_PCB(hidden_layers=hidden_layers, activation=activation).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=lrdecay, patience=lrdecay_patience, verbose=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f4459",
   "metadata": {},
   "source": [
    "Ensure data is moved to the appropriate device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba349ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x est√° en: cuda:0\n",
      "y est√° en: cuda:0\n",
      "model est√° en: cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "\n",
    "print(f\"x est√° en: {x.device}\")\n",
    "print(f\"y est√° en: {y.device}\")\n",
    "print(f\"model est√° en: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c93ae",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae59c8",
   "metadata": {},
   "source": [
    "Training and saving best model with best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1acd8424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "üîÅ Cargando modelo existente `PCB_MLP_nt1000_e500_lr0.01_bs1000_h-64-128-256_ReLU.pth` y reanudando entrenamiento."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Los resultados se guardar√°n en: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\models\\MLP_PCB\\PCB_MLP_nt1000_e500_lr0.01_bs1000_h-64-128-256_ReLU.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ismael.gallo\\AppData\\Local\\Temp\\ipykernel_19300\\104693093.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss_hist = []\n",
    "best_val_loss = np.inf\n",
    "epochs_without_improvement = 0\n",
    "elapsed_previous = 0.0  # minutos ya entrenados en sesiones anteriores\n",
    "\n",
    "layer_string = \"\"\n",
    "for d in hidden_layers:\n",
    "    layer_string += f\"-{d}\"\n",
    "    \n",
    "activation_string = activation.__name__\n",
    "\n",
    "model_dir = os.path.join(dir_path, 'models', 'MLP_PCB')\n",
    "if IN_COLAB:\n",
    "    model_dir = os.path.join(MODELS_PATH, 'MLP_PCB')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "filename = f\"PCB_MLP_nt{n_train}_e{epochs}_lr{lr}_bs{batch_size}_h{layer_string}_{activation_string}.pth\"\n",
    "model_path = os.path.join(model_dir, filename)\n",
    "json_path  = model_path.replace('.pth', '.json')\n",
    "\n",
    "start_epoch = 0\n",
    "start_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# --- L√≥gica de reanudaci√≥n ---\n",
    "if os.path.exists(model_path):\n",
    "    display(Markdown(f\"üîÅ Cargando modelo existente `{filename}` y reanudando entrenamiento.\"))\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            prev = json.load(f)\n",
    "        best_test_loss        = prev.get('best_val_loss', best_val_loss)\n",
    "        train_loss            = prev.get('train_loss', [])\n",
    "        val_loss              = prev.get('val_loss', [])\n",
    "        elapsed_previous      = prev.get('training_duration_minutes', 0.0)\n",
    "        start_datetime        = prev.get('start_datetime', start_datetime)\n",
    "        start_epoch           = prev.get('epochs_trained', 0)\n",
    "        # Reiniciamos el contador de paciencia tras mejora\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        display(Markdown(\"‚ö†Ô∏è No se encontr√≥ JSON de hiperpar√°metros; se reinicia contadores.\"))\n",
    "else:\n",
    "    display(Markdown(f\"‚ú® Nuevo entrenamiento: `{filename}`\"))\n",
    "\n",
    "print(\"üìÅ Los resultados se guardar√°n en:\", json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3b8e4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x)\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "    for x, y in train_bar:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_loss.append(epoch_loss)\n",
    "    # print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "    # Validaci√≥n\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_bar:\n",
    "            y_pred_val = model(x_val)\n",
    "            loss_val = criterion(y_pred_val, y_val)\n",
    "            val_loss += loss_val.item() * x_val.size(0)\n",
    "            val_bar.set_postfix(val_loss=loss_val.item())\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    # If you want to keep a history, use a list like val_loss_hist and append here:\n",
    "    val_loss_hist.append(val_loss)\n",
    "    # print(f\"           Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Guardar mejor modelo\n",
    "    if val_loss < best_test_loss:\n",
    "        best_test_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # Guardar JSON con info de entrenamiento\n",
    "        training_info = {\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"epochs_trained\": epoch + 1,\n",
    "            \"training_duration_minutes\": elapsed_previous + ((datetime.datetime.now() - datetime.datetime.strptime(start_datetime, \"%Y-%m-%d %H:%M:%S\")).total_seconds() / 60.0),\n",
    "            \"start_datetime\": start_datetime,\n",
    "            \"hyperparameters\": {\n",
    "                \"epochs\": epochs,\n",
    "                \"lr0\": lr,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"hidden_layers\": hidden_layers,\n",
    "                \"activation\": activation_string,\n",
    "            },\n",
    "            \"final lr\": optimizer.param_groups[0]['lr'],\n",
    "            # \"train_loss\": train_loss,\n",
    "            # \"val_loss\": val_loss_hist\n",
    "        }\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(training_info, f, indent=2)\n",
    "        # print(f\"‚úÖ Modelo guardado: {model_path}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= early_stop_patience:\n",
    "        print(f\"‚èπÔ∏è Early stopping en la √©poca {epoch+1} tras {early_stop_patience} √©pocas sin mejora.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020559b",
   "metadata": {},
   "source": [
    "Plot training loss and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8efa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (271,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_loss_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\plot_functions.py:140\u001b[0m, in \u001b[0;36mplot_loss_evolution\u001b[1;34m(train_loss, test_loss)\u001b[0m\n\u001b[0;32m    136\u001b[0m epochs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_loss)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    139\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, train_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 140\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    142\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3796\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3797\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3798\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3800\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ismael.gallo\\anaconda3\\envs\\ismael_minimal\\lib\\site-packages\\matplotlib\\axes\\_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (271,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_evolution(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa79576",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83e49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ismael.gallo\\AppData\\Local\\Temp\\ipykernel_21388\\3240133991.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "# load the best model\n",
    "model = MLP_PCB(hidden_layers=hidden_layers, activation=activation).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Test\n",
    "test_loss = 0.0\n",
    "test_bar = tqdm(test_loader, desc=f\"Test\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_bar:\n",
    "        y_pred_test = model(x_test)\n",
    "        loss_test = criterion(y_pred_test, y_test)\n",
    "        test_loss += loss_test.item() * x_test.size(0)\n",
    "        test_bar.set_postfix(test_loss=loss_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeea70c",
   "metadata": {},
   "source": [
    "## Optuna study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ad1c1",
   "metadata": {},
   "source": [
    "Estudio para encontrar las mejores combinaciones de numero de capas con iteraciones en n√∫mero de neuronas ocultas, learning rate, numero de capas, funcion de activacion, lr decay factor y patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Sugerir hiperpar√°metros\n",
    "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256, 512])\n",
    "    activation_name = trial.suggest_categorical('activation', ['ReLU', 'SiLU', 'Tanh'])\n",
    "    activation = getattr(nn, activation_name)\n",
    "    lrdecay = trial.suggest_loguniform('lrdecay', 0.1, 0.5)\n",
    "    lrdecay_patience = trial.suggest_int('lrdecay_patience', 5, 50)\n",
    "\n",
    "    # Definir arquitectura\n",
    "    hidden_layers = [hidden_dim] * n_layers\n",
    "    model = MLP_PCB(hidden_layers=hidden_layers, activation=activation).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=lrdecay, patience=lrdecay_patience, verbose=False)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    epochs_optuna = epochs\n",
    "    train_loss = []\n",
    "    val_loss_hist = []\n",
    "    start_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    for epoch in range(epochs_optuna):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_loss.append(epoch_loss)\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                y_pred_val = model(x_val)\n",
    "                loss_val = criterion(y_pred_val, y_val)\n",
    "                val_loss += loss_val.item() * x_val.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_loss_hist.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # Guardar modelo y JSON en carpeta optuna_studies/models\n",
    "    os.makedirs(\"optuna_studies/mlp_models\", exist_ok=True)\n",
    "    model_path = f\"optuna_studies/mlp_models/model_trial_{trial.number}.pth\"\n",
    "    json_path = f\"optuna_studies/mlp_models/model_trial_{trial.number}.json\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Guardar tambi√©n con el mismo formato y ruta que el entrenamiento normal\n",
    "    layer_string = \"\"\n",
    "    for d in hidden_layers:\n",
    "        layer_string += f\"-{d}\"\n",
    "    activation_string = activation.__name__\n",
    "    # Abreviar el learning rate para el nombre del archivo\n",
    "    lr_str = f\"{lr:.0e}\" if lr < 1e-2 else f\"{lr:.2f}\"\n",
    "    model_dir = os.path.join(dir_path, 'models', 'MLP_PCB')\n",
    "    if IN_COLAB:\n",
    "        model_dir = os.path.join(MODELS_PATH, 'MLP_PCB')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    filename = f\"PCB_MLP_trial{trial.number}_nt{n_train}_e{epochs_optuna}_lr{lr_str}_bs{batch_size}_h{layer_string}_{activation_string}.pth\"\n",
    "    model_path_normal = os.path.join(model_dir, filename)\n",
    "    json_path_normal = model_path_normal.replace('.pth', '.json')\n",
    "    torch.save(model.state_dict(), model_path_normal)\n",
    "\n",
    "    training_info = {\n",
    "        \"trial_number\": trial.number,\n",
    "        \"final_val_loss\": val_loss_hist[-1] if val_loss_hist else None,\n",
    "        \"epochs_trained\": epochs_optuna,\n",
    "        \"training_duration_minutes\": None,  # Puedes calcularlo si quieres\n",
    "        \"start_datetime\": start_datetime,\n",
    "        \"hyperparameters\": {\n",
    "            \"lr\": lr,\n",
    "            \"n_layers\": n_layers,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"activation\": activation_name,\n",
    "            \"lrdecay\": lrdecay,\n",
    "            \"lrdecay_patience\": lrdecay_patience,\n",
    "        },\n",
    "        \"final_lr\": optimizer.param_groups[0]['lr'],\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss_hist\n",
    "    }\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(training_info, f, indent=2)\n",
    "    with open(json_path_normal, 'w') as f:\n",
    "        json.dump(training_info, f, indent=2)\n",
    "\n",
    "    return val_loss_hist[-1] if val_loss_hist else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7052c36",
   "metadata": {},
   "source": [
    "Crear y ejecutar el estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-19 08:35:08,082] Using an existing study with name 'mlp_pcb_study' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "# Crea el estudio y lo guarda en un archivo SQLite\n",
    "os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name=\"mlp_pcb_study\",\n",
    "    storage=\"sqlite:///optuna_studies/mlp_pcb_optuna_study.db\",\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d8dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de ensayo ganador : 41\n",
      "Valor objetivo (p√©rdida) : 1.0661789418519619e-07\n",
      "Hiperpar√°metros √≥ptimos  : {'lr': 0.007992966235711838, 'n_layers': 5, 'hidden_dim': 64, 'activation': 'SiLU', 'lrdecay': 0.3961551271796536, 'lrdecay_patience': 22}\n"
     ]
    }
   ],
   "source": [
    "best_trial   = study.best_trial\n",
    "best_params  = best_trial.params         # dict con los hiperpar√°metros ganadores\n",
    "print(\"N√∫mero de ensayo ganador :\", best_trial.number)\n",
    "print(\"Valor objetivo (p√©rdida) :\", best_trial.value)\n",
    "print(\"Hiperpar√°metros √≥ptimos  :\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b710783",
   "metadata": {},
   "source": [
    "### Loading best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c838a2",
   "metadata": {},
   "source": [
    "Cargar el estudio que mejores resultados obtuvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.load_study(\n",
    "    study_name=\"mlp_pcb_study\",\n",
    "    storage=\"sqlite:///optuna_studies/mlp_pcb_optuna_study.db\"\n",
    ")\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d979c",
   "metadata": {},
   "source": [
    "Reconstrucci√≥n de la ruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0317ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"optuna_studies/mlp_models/model_trial_{best_trial.number}.pth\"\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"No existe el fichero {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3068637",
   "metadata": {},
   "source": [
    "Asignando valors de los par√°metros del mejor modelo de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d343742",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [best_params[\"hidden_dim\"]] * best_params[\"n_layers\"]\n",
    "activation = getattr(torch.nn, best_params[\"activation\"])\n",
    "model = MLP_PCB(hidden_layers=hidden_layers, activation=activation).to(\"cpu\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=best_params[\"lr\"])\n",
    "\n",
    "# 4) Crea un nuevo scheduler id√©ntico al usado en el trial\n",
    "scheduler = ReduceLROnPlateau(optimizer,\n",
    "                              mode=\"min\",\n",
    "                              factor=best_params[\"lrdecay\"],\n",
    "                              patience=best_params[\"lrdecay_patience\"],\n",
    "                              verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a020d3",
   "metadata": {},
   "source": [
    "Cargar los pesos del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30d04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ismael.gallo\\AppData\\Local\\Temp\\ipykernel_21388\\2633090818.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP_PCB(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (9): SiLU()\n",
       "    (10): Linear(in_features=64, out_features=169, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49023b2",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Sequence, Union, Optional\n",
    "\n",
    "def predict_temperature_evolution_pcb(\n",
    "    model: torch.nn.Module,\n",
    "    dataset: PCBDataset_mlp,\n",
    "    Q_heaters: Sequence[float],\n",
    "    T_interfaces: Sequence[float],\n",
    "    T_env: float,\n",
    "    time_raw_seq: Optional[Union[np.ndarray, torch.Tensor]] = None,\n",
    "    n_steps: int = 1001,\n",
    "    device: Optional[torch.device] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inferencia completa de la evoluci√≥n t√©rmica de la PCB.\n",
    "\n",
    "    Si `time_raw_seq` es None, se crea autom√°ticamente el vector\n",
    "    de tiempo normalizado de longitud 1001 por defecto.\n",
    "\n",
    "    Devuelve un array (n_steps, 169) con los mapas de temperatura\n",
    "    desnormalizados.\n",
    "    \"\"\"\n",
    "    # 0) Device y modelo  \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # 1) Generar o convertir la secuencia de tiempo cruda\n",
    "    if time_raw_seq is None:\n",
    "        time_raw = torch.arange(0, n_steps, dtype=torch.float32)  # (n_steps,)\n",
    "    else:\n",
    "        if isinstance(time_raw_seq, np.ndarray):\n",
    "            time_raw = torch.from_numpy(time_raw_seq.astype(np.float32))\n",
    "        else:\n",
    "            time_raw = time_raw_seq.clone().float()\n",
    "    time_raw = time_raw.to(device)\n",
    "\n",
    "    # 2) Crear todos los inputs normalizados\n",
    "    inputs = []\n",
    "    for t in time_raw.cpu().numpy():\n",
    "        inp = dataset.create_input_from_values(\n",
    "            Q_heaters=Q_heaters,\n",
    "            T_interfaces=T_interfaces,\n",
    "            T_env=T_env,\n",
    "            time=t\n",
    "        )\n",
    "        inputs.append(inp.unsqueeze(0))\n",
    "    X = torch.cat(inputs, dim=0).to(device)  # (n_steps, 10)√ß\n",
    "    print('X[:,0].mean()',X[:,0].mean())\n",
    "    # print(X[0])\n",
    "\n",
    "    # 3) Inferir en batch\n",
    "    with torch.no_grad():\n",
    "        preds_norm = model(X)  # (n_steps, 169)\n",
    "\n",
    "    # 4) Desnormalizar la salida\n",
    "    temps_denorm = dataset.denormalize_output(preds_norm)  # (n_steps,169)\n",
    "    return temps_denorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[:,0].mean() tensor(1932.9221, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(229179.2969, device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temps = predict_temperature_evolution_pcb(\n",
    "    model=model,\n",
    "    dataset=base_dataset,\n",
    "    Q_heaters=[1, 1, 1, 1],\n",
    "    T_interfaces=[280, 280, 280, 280],\n",
    "    T_env=298.0,\n",
    ")\n",
    "# temps tendr√° forma (1001, 169)\n",
    "temps.shape\n",
    "temps.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismael_minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
