{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127321bf",
   "metadata": {},
   "source": [
    "# MLP transient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89305a8e",
   "metadata": {},
   "source": [
    "## Previo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa7860",
   "metadata": {},
   "source": [
    "Para que funcione en Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802a673f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo: Local\n",
      "Ruta datasets: C:\\Users\\ismael.gallo/ia_thermal_colab\\datasets\n",
      "Ruta modelos: C:\\Users\\ismael.gallo/ia_thermal_colab\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import IPython\n",
    "\n",
    "# Detectar si estamos en Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Ruta base\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_PATH = \"/content/drive/MyDrive/ia_thermal_colab\"\n",
    "else:\n",
    "    BASE_PATH = os.path.expanduser(\"~/ia_thermal_colab\")\n",
    "\n",
    "DATASETS_PATH = os.path.join(BASE_PATH, \"datasets\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
    "\n",
    "os.makedirs(DATASETS_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"Modo:\", \"Colab\" if IN_COLAB else \"Local\")\n",
    "print(\"Ruta datasets:\", DATASETS_PATH)\n",
    "print(\"Ruta modelos:\", MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce43b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Par√°metros del repo\n",
    "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia esto\n",
    "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "CLONE_PATH = os.path.join(BASE_PATH, REPO_NAME)\n",
    "\n",
    "if IN_COLAB:\n",
    "    # üß¨ Clonar el repositorio si no existe ya\n",
    "    if not os.path.exists(CLONE_PATH):\n",
    "        !git clone {GIT_REPO_URL} {CLONE_PATH}\n",
    "    else:\n",
    "        print(f\"Repositorio ya clonado en: {CLONE_PATH}\")\n",
    "\n",
    "    # üì¶ Instalar requirements.txt\n",
    "    req_path = os.path.join(CLONE_PATH, \"requirements.txt\")\n",
    "    if os.path.exists(req_path):\n",
    "        !pip install -r {req_path}\n",
    "    else:\n",
    "        print(\"No se encontr√≥ requirements.txt en el repositorio.\")\n",
    "\n",
    "    print(\"üîÑ Reinicia el entorno para aplicar los cambios...\")\n",
    "    IPython.display.display(IPython.display.Javascript('''google.colab.restartRuntime()'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7dd21",
   "metadata": {},
   "source": [
    "Importaci√≥n de librer√≠as necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a1b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from IPython.display import display, Markdown\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# get the directory path of the file\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "if IN_COLAB:\n",
    "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal\")\n",
    "\n",
    "from plot_functions import *\n",
    "from Physics_Loss import *\n",
    "from utils import *\n",
    "\n",
    "if IN_COLAB:\n",
    "  sys.path.append(\"/content/drive/MyDrive/ia_thermal_colab/ia_thermal/ismaelgallo\")\n",
    "\n",
    "from architectures.mlp_pcb import *\n",
    "\n",
    "from Dataset_Class_mlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85f2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be876f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_specs = {\n",
    "    \"os\": platform.system(),  # e.g. \"Linux\", \"Windows\", \"Darwin\"\n",
    "    \"os_version\": platform.version(),\n",
    "    \"machine\": platform.machine(),  # e.g. \"x86_64\"\n",
    "    \"processor\": platform.processor(),  # e.g. \"Intel64 Family 6 Model 158\"\n",
    "    \"python_version\": platform.python_version(),\n",
    "    \"device\": str(device)\n",
    "}\n",
    "if torch.cuda.is_available():\n",
    "    system_specs[\"gpu_name\"] = torch.cuda.get_device_name(0)\n",
    "    system_specs[\"gpu_memory_total_GB\"] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
    "    system_specs[\"cuda_version\"] = torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa2a2e",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fed6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 5\n",
    "n_test = 2\n",
    "n_val = 5\n",
    "time_sim = 50 # seconds\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "sequence_length = time_sim+1 # seconds\n",
    "dt = 1 # seconds\n",
    "T_init = 298.0 # Kelvin\n",
    "nodes_side = 13 # number of nodes in one side of the PCB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e01f5",
   "metadata": {},
   "source": [
    "Dataset extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c033746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cargando mlp transient dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset.pth\n",
      "Cargando dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset_train.pth\n",
      "Cargando dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset_val.pth\n",
      "Cargando dataset base desde: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\\PCB_mlp_transient_dataset_test.pth\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "  dir_path = BASE_PATH\n",
    "\n",
    "base_dataset = load_dataset_mlp(base_path=dir_path)  # ‚Üê carga el dataset base completo (PCB_mlp_transient_dataset.pth)\n",
    "dataset_train = load_trimmed_dataset_mlp(base_path=dir_path, dataset_type='train', max_cases=n_train)\n",
    "dataset_val = load_trimmed_dataset_mlp(base_path=dir_path, dataset_type='val', max_cases=n_val)\n",
    "dataset_test = load_trimmed_dataset_mlp(base_path=dir_path, dataset_type='test', max_cases=n_test)\n",
    "\n",
    "# loader = DataLoader(base_dataset, batch_size=batch_size, shuffle=False)  # DEBUGGING\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62770947",
   "metadata": {},
   "source": [
    "Debugging para comprobar que cumpla tama√±os que nos interesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084bc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5005, 10]), torch.Size([5005, 169]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7f1ac",
   "metadata": {},
   "source": [
    "# Non-physics MLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663aab6",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade0c21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismael_minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
