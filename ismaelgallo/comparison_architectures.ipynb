{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25ee6c9",
   "metadata": {},
   "source": [
    "# Statistical comparison for all models studied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73267f",
   "metadata": {},
   "source": [
    "## Previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6bcb7",
   "metadata": {},
   "source": [
    "\n",
    "Esta celda detecta si el c√≥digo se ejecuta en **Google Colab** o localmente, configura rutas base para guardar datasets y modelos, y crea los directorios necesarios si no existen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d72c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entorno detectado: Local\n",
      "üìÅ Ruta base: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\n",
      "üìÅ Ruta datasets: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\datasets\n",
      "üìÅ Ruta modelos: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\models\n",
      "üìÅ Ruta figures: c:\\Users\\ismael.gallo\\Desktop\\ia_thermal\\ismaelgallo\\figures\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import IPython\n",
    "\n",
    "def detectar_entorno_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def configurar_rutas(base_local=None, base_colab=\"/content/drive/MyDrive/ia_thermal_colab\", verbose=True):\n",
    "    IN_COLAB = detectar_entorno_colab()\n",
    "\n",
    "    if IN_COLAB:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        base_path = Path(base_colab)\n",
    "    else:\n",
    "        # ‚ö†Ô∏è Si no se pasa base_local, usar el directorio del notebook\n",
    "        if base_local is None:\n",
    "            base_path = Path.cwd()\n",
    "        else:\n",
    "            base_path = Path(base_local).expanduser().resolve()\n",
    "\n",
    "    datasets_path = base_path / \"datasets\"\n",
    "    models_path = base_path / \"models\"\n",
    "    figures_path = base_path / \"figures\"\n",
    "    datasets_path.mkdir(parents=True, exist_ok=True)\n",
    "    models_path.mkdir(parents=True, exist_ok=True)\n",
    "    figures_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"‚úÖ Entorno detectado:\", \"Colab\" if IN_COLAB else \"Local\")\n",
    "        print(\"üìÅ Ruta base:\", base_path)\n",
    "        print(\"üìÅ Ruta datasets:\", datasets_path)\n",
    "        print(\"üìÅ Ruta modelos:\", models_path)\n",
    "        print(\"üìÅ Ruta figures:\", figures_path)\n",
    "\n",
    "    return IN_COLAB, base_path, datasets_path, models_path, figures_path\n",
    "\n",
    "# üü¢ Llamada principal\n",
    "IN_COLAB, BASE_PATH, DATASETS_PATH, MODELS_PATH, FIGURES_PATH = configurar_rutas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba3be0",
   "metadata": {},
   "source": [
    "\n",
    "Esta celda clona el repositorio del proyecto en Colab, instala las dependencias desde `requirements.txt` y reinicia el entorno para aplicar los cambios.\n",
    "\n",
    "üîß *Sugerencia*: podr√≠as separar la clonaci√≥n del repositorio y la instalaci√≥n en funciones para mayor claridad y reutilizaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0aff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Par√°metros del repositorio\n",
    "GIT_REPO_URL = \"https://github.com/ismaelgallolopez/ia_thermal.git\"  # üëà Cambia si usas otro repo\n",
    "REPO_NAME = GIT_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "CLONE_PATH = BASE_PATH / REPO_NAME  # Usamos Path (de pathlib)\n",
    "\n",
    "def clonar_repo_si_no_existe(repo_url: str, clone_path: Path):\n",
    "    if not clone_path.exists():\n",
    "        print(f\"üì• Clonando repositorio en {clone_path}...\")\n",
    "        os.system(f\"git clone {repo_url} {clone_path}\")\n",
    "    else:\n",
    "        print(f\"üìÇ Repositorio ya clonado en: {clone_path}\")\n",
    "\n",
    "def instalar_requirements(clone_path: Path):\n",
    "    req_path = clone_path / \"requirements.txt\"\n",
    "    if req_path.exists():\n",
    "        print(\"üì¶ Instalando dependencias desde requirements.txt...\")\n",
    "        os.system(f\"pip install -r {req_path}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No se encontr√≥ requirements.txt en el repositorio.\")\n",
    "\n",
    "def reiniciar_entorno_colab():\n",
    "    print(\"üîÑ Reiniciando entorno para aplicar los cambios...\")\n",
    "    display(IPython.display.Javascript('''google.colab.restartRuntime()'''))\n",
    "\n",
    "# üß™ Ejecutar solo en Colab\n",
    "if IN_COLAB:\n",
    "    clonar_repo_si_no_existe(GIT_REPO_URL, CLONE_PATH)\n",
    "    instalar_requirements(CLONE_PATH)\n",
    "    reiniciar_entorno_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d12f5",
   "metadata": {},
   "source": [
    "\n",
    "Se importan todas las librer√≠as necesarias, tanto est√°ndar como personalizadas. Tambi√©n se configura el path para poder importar m√≥dulos espec√≠ficos seg√∫n el entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2245d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as est√°ndar\n",
    "import os, sys, time, json, platform\n",
    "from datetime import datetime\n",
    "from typing import Sequence, Union, Optional\n",
    "\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# NumPy y ciencia de datos\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch y entrenamiento\n",
    "import torch\n",
    "from torch import nn, amp\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch._dynamo\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# Optimizaci√≥n\n",
    "import optuna\n",
    "\n",
    "# A√±adir rutas del proyecto (de forma portable)\n",
    "sys.path.append(str(BASE_PATH))\n",
    "sys.path.append(str(BASE_PATH / \"ia_thermal\"))\n",
    "sys.path.append(str(BASE_PATH / \"ia_thermal\" / \"ismaelgallo\"))\n",
    "sys.path.append(str(BASE_PATH.parent))\n",
    "\n",
    "# M√≥dulos propios del proyecto\n",
    "from architectures.convlstm import *\n",
    "from Dataset_Class_convlstm import *\n",
    "from plot_functions import *\n",
    "from Physics_Loss import *\n",
    "from utils import *\n",
    "from scripts.PCB_solver_tr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65140d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== CONFIGURACI√ìN DE MATPLOTLIB ===============\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "#plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.family\"] = \"lmroman10-regular\"\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"axes.titlesize\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8057c",
   "metadata": {},
   "source": [
    "\n",
    "Esta celda detecta si hay una GPU disponible y selecciona `cuda` si es posible; de lo contrario, usa `cpu`. Muestra por pantalla qu√© dispositivo se est√° utilizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c067cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìü Dispositivo seleccionado: cuda\n"
     ]
    }
   ],
   "source": [
    "device = seleccionar_dispositivo(use_cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7982c9a",
   "metadata": {},
   "source": [
    "\n",
    "Recopila informaci√≥n del sistema operativo, arquitectura, procesador, versi√≥n de Python, dispositivo de c√≥mputo y, si hay GPU disponible, tambi√©n su nombre, memoria y versi√≥n de CUDA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc38f394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': 'Windows',\n",
       " 'os_version': '10.0.19041',\n",
       " 'machine': 'AMD64',\n",
       " 'processor': 'Intel64 Family 6 Model 158 Stepping 10, GenuineIntel',\n",
       " 'python_version': '3.9.21',\n",
       " 'device': 'cuda',\n",
       " 'gpu_name': 'NVIDIA GeForce GTX 1050',\n",
       " 'gpu_memory_total_GB': 2.0,\n",
       " 'cuda_version': '11.8'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_specs = get_system_specs(device)\n",
    "system_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b536b8",
   "metadata": {},
   "source": [
    "## Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cfc84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # Para reproducibilidad\n",
    "\n",
    "def generate_unique_cases(n_data):\n",
    "    \"\"\"\n",
    "    Genera casos √∫nicos evitando duplicados para asegurar diversidad en el an√°lisis.\n",
    "    \n",
    "    Args:\n",
    "        n_data: N√∫mero de casos √∫nicos a generar\n",
    "        \n",
    "    Returns:\n",
    "        Q_list: Array de potencias de heaters [W] - shape (n_data, 4)\n",
    "        T_int_list: Array de temperaturas de interfaces [K] - shape (n_data, 4)  \n",
    "        T_env_list: Array de temperaturas ambiente [K] - shape (n_data,)\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    Q_list, T_int_list, T_env_list = [], [], []\n",
    "    \n",
    "    while len(Q_list) < n_data:\n",
    "        # Generar condiciones aleatorias\n",
    "        Q = tuple(np.random.uniform(0.5, 1.5, 4).round(6))        # Potencias [0.5-1.5W]\n",
    "        T_int = tuple(np.random.uniform(270, 320, 4).round(2))    # Interfaces [270-320K]\n",
    "        T_env = round(float(np.random.uniform(270, 320)), 2)      # Ambiente [270-320K]\n",
    "        \n",
    "        # Crear clave √∫nica para evitar duplicados\n",
    "        key = Q + T_int + (T_env,)\n",
    "        \n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            Q_list.append(Q)\n",
    "            T_int_list.append(T_int)\n",
    "            T_env_list.append(T_env)\n",
    "    \n",
    "    return np.array(Q_list), np.array(T_int_list), np.array(T_env_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e070d1",
   "metadata": {},
   "source": [
    "## Simulation of a number of cases for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c769492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìä Casos a analizar: 1000\n",
      "   ‚è±Ô∏è  Tiempo m√°ximo: 50s\n"
     ]
    }
   ],
   "source": [
    "n_data = 1000          # N√∫mero de casos a analizar\n",
    "time_sim = 50         # Tiempo m√°ximo de simulaci√≥n [s]\n",
    "dt = 1                  # Paso temporal [s]\n",
    "T_init = 298.0          # Temperatura inicial [K]\n",
    "\n",
    "print(f\"   üìä Casos a analizar: {n_data}\")\n",
    "print(f\"   ‚è±Ô∏è  Tiempo m√°ximo: {time_sim}s\")\n",
    "\n",
    "Q_random, T_interfaces_random, T_env_random = generate_unique_cases(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873206e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìä Procesando caso 0/1000...\n",
      "   üìä Procesando caso 100/1000...\n",
      "   üìä Procesando caso 200/1000...\n",
      "   üìä Procesando caso 300/1000...\n",
      "   üìä Procesando caso 400/1000...\n",
      "   üìä Procesando caso 500/1000...\n",
      "   üìä Procesando caso 600/1000...\n",
      "   üìä Procesando caso 700/1000...\n",
      "   üìä Procesando caso 800/1000...\n",
      "   üìä Procesando caso 900/1000...\n",
      "üéâ An√°lisis completado!\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_data):\n",
    "    if i % 100 == 0:  # Progress indicator\n",
    "        print(f\"   üìä Procesando caso {i}/{n_data}...\")\n",
    "        \n",
    "    # Condiciones para este caso\n",
    "    Q = Q_random[i]\n",
    "    T_int = T_interfaces_random[i]\n",
    "    T_env = T_env_random[i]\n",
    "    # =============== SOLVER TRANSITORIO (EVOLUCI√ìN) ===============\n",
    "    T_transient, _, _, _ = PCB_case_2(\n",
    "        solver='transient', display=False, time=time_sim, dt=dt,\n",
    "        T_init=T_init, Q_heaters=Q, T_interfaces=T_int, Tenv=T_env\n",
    "    )\n",
    "print(f\"üéâ An√°lisis completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9aa027",
   "metadata": {},
   "source": [
    "## Importing models with adequate hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismael_minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
