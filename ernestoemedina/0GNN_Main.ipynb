{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisar esto para representar los grafos generados.\n",
    "\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos lo necesario para la GNN\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.explain import Explainer\n",
    "from torch_geometric.explain.algorithm import GNNExplainer\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "#from torchvision import transforms, models\n",
    "#from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de dónde querramos trabajar corremos un bloque u otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 12 workers para cargar los datos\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_workers = max(4, multiprocessing.cpu_count())  # Usa hasta 4 workers o el máximo de la CPU, sin embargo, es mejor que el número máximo coincida con los núcleos de la CPU, no con los procesadores lógicos\n",
    "print(f\"Usando {num_workers} workers para cargar los datos\")\n",
    "enable_cpu_affinity = True #Revisar bien como funciona esto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos los módulos a usar, incluyendo GNNExplainer para poder observar más adelante si nuestra GNN está bien planteada, permitiendo entender el motivo de su predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente. Tamaño del dataset: 20000\n",
      "<class 'Dataset_loader.PCBDataset'>\n",
      "PCB_dataset.pth\n"
     ]
    }
   ],
   "source": [
    "from Dataset_loader import PCBDataset #\n",
    "\n",
    "# Ruta al archivo .pth (relativa a tu ubicación actual)\n",
    "file_path = 'PCB_dataset.pth'\n",
    "dataset = load_dataset(file_path)\n",
    "\n",
    "print(f\"Dataset cargado exitosamente. Tamaño del dataset: {len(dataset)}\")\n",
    "print(type(dataset))\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitkeep', 'Dataset_loader.py', 'GNN_Main.ipynb', 'PCB_dataset.pth', 'pruebaGNN.ipynb', 'pruebascpu.ipynb', 'temp-plot.html', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramse\\Escritorio\\Aero Ordenador\\4to Aero\\2do Cuatri\\Repo_TFG\\ia_thermal\\ernestoemedina\n",
      "False\n",
      "['.gitkeep', 'Dataset_loader.py', 'GNN_Main.ipynb', 'PCB_dataset.pth', 'pruebaGNN.ipynb', 'pruebascpu.ipynb', 'temp-plot.html', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de nodos 4\n",
      "Numero de edges 6\n",
      "Numero de features 3\n",
      "Epoch 0, Loss: 0.7374\n",
      "Epoch 20, Loss: 0.6704\n",
      "Epoch 40, Loss: 0.6580\n",
      "Epoch 60, Loss: 0.6424\n",
      "Epoch 80, Loss: 0.6232\n",
      "Epoch 100, Loss: 0.6000\n",
      "Epoch 120, Loss: 0.5760\n",
      "Epoch 140, Loss: 0.5503\n",
      "Epoch 160, Loss: 0.5259\n",
      "Epoch 180, Loss: 0.5021\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GNNExplainer.__init__() got multiple values for argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 71\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m explainer \u001b[38;5;241m=\u001b[39m GNNExplainer(model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Explain the prediction for node 2\u001b[39;00m\n\u001b[0;32m     74\u001b[0m node_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: GNNExplainer.__init__() got multiple values for argument 'epochs'"
     ]
    }
   ],
   "source": [
    "# Define edge index (source, target) pairs\n",
    "edge_index = torch.tensor([\n",
    "    [0, 1, 1, 2, 2, 3],  # Source nodes\n",
    "    [1, 0, 2, 1, 3, 2]   # Target nodes\n",
    "], dtype=torch.long)  ## Podrias probar a hacer un bucle que vaya sobreescribiendo\n",
    "\n",
    "# Define node features (4 nodes, each with 3 features)\n",
    "x = torch.tensor([\n",
    "    [1, 0, 1], \n",
    "    [0, 1, 1], \n",
    "    [1, 1, 0], \n",
    "    [0, 0, 1]\n",
    "], dtype=torch.float)\n",
    "\n",
    "# Define node labels (for classification)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Comprobamos ciertas cosas de PCB_dataset\n",
    "#print(len(dataset))\n",
    "\n",
    "\n",
    "# Create PyG data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y).to(device)\n",
    "data.validate(raise_on_error=True) # Para validar que los datos son correctos\n",
    "print(\"Numero de nodos\", data.num_nodes)\n",
    "print(\"Numero de edges\", data.num_edges)\n",
    "print(\"Numero de features\", data.num_node_features)\n",
    "data.has_isolated_nodes()\n",
    "data.has_self_loops()\n",
    "data.is_directed()\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate model\n",
    "model = GCN(in_channels=data.num_node_features, hidden_channels=4,  out_channels=data.num_node_features).to(device) \n",
    "# Las salidas y entradas son las mismas, ya que son las temperaturas y potencias \"predichas\" por el modelo\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.NLLLoss().to(device)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Train for 200 epochs\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Revisar lo del explainer porque creo que esta mal, que ahora se llama de otra manera (fijarse abajo)\n",
    "explainer = GNNExplainer(model, epochs=200)\n",
    "\n",
    "# Explain the prediction for node 2\n",
    "node_idx = 2\n",
    "explanation = explainer.explain_node(node_idx, data.x, data.edge_index)\n",
    "\n",
    "# Visualize the explanation\n",
    "ax, G = explainer.visualize_subgraph(node_idx, data.edge_index, explanation.edge_mask, threshold=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)  # Get predicted class\n",
    "print(\"Predicted classes:\", pred.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ModelMode' has no attribute 'classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Define the model configuration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model_config \u001b[38;5;241m=\u001b[39m ModelConfig(\n\u001b[1;32m---> 15\u001b[0m     mode\u001b[38;5;241m=\u001b[39mModelMode\u001b[38;5;241m.\u001b[39mclassification,     \u001b[38;5;66;03m# Use ModelMode.classification\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     task_level\u001b[38;5;241m=\u001b[39mModelTaskLevel\u001b[38;5;241m.\u001b[39mnode,    \u001b[38;5;66;03m# Use ModelTaskLevel.node\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     return_type\u001b[38;5;241m=\u001b[39mModelReturnType\u001b[38;5;241m.\u001b[39mlog_probs \u001b[38;5;66;03m# Use ModelReturnType.log_probs\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Define edge index (source, target) pairs\u001b[39;00m\n\u001b[0;32m     20\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[0;32m     21\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],  \u001b[38;5;66;03m# Source nodes\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m]   \u001b[38;5;66;03m# Target nodes\u001b[39;00m\n\u001b[0;32m     23\u001b[0m ], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ModelMode' has no attribute 'classification'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.explain import Explainer, ModelConfig\n",
    "from torch_geometric.explain.config import ModelMode, ModelTaskLevel, ModelReturnType\n",
    "from torch_geometric.explain.algorithm import GNNExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the model configuration\n",
    "model_config = ModelConfig(\n",
    "    mode=ModelMode.classification,     # Use ModelMode.classification\n",
    "    task_level=ModelTaskLevel.node,    # Use ModelTaskLevel.node\n",
    "    return_type=ModelReturnType.log_probs # Use ModelReturnType.log_probs\n",
    ")\n",
    "# Define edge index (source, target) pairs\n",
    "edge_index = torch.tensor([\n",
    "    [0, 1, 1, 2, 2, 3],  # Source nodes\n",
    "    [1, 0, 2, 1, 3, 2]   # Target nodes\n",
    "], dtype=torch.long).to(device)\n",
    "\n",
    "# Define node features (4 nodes, each with 3 features)\n",
    "x = torch.tensor([\n",
    "    [1, 0, 1], \n",
    "    [0, 1, 1], \n",
    "    [1, 1, 0], \n",
    "    [0, 0, 1]\n",
    "], dtype=torch.float).to(device)\n",
    "\n",
    "# Define node labels (for classification)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.long).to(device)\n",
    "\n",
    "# Create PyG data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y).to(device)\n",
    "data.validate(raise_on_error=True)\n",
    "\n",
    "# Check data properties\n",
    "print(\"Number of nodes:\", data.num_nodes)\n",
    "print(\"Number of edges:\", data.num_edges)\n",
    "print(\"Number of features per node:\", data.num_node_features)\n",
    "print(\"Number of classes:\", len(torch.unique(data.y)))\n",
    "\n",
    "# Define GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate model\n",
    "model = GCN(in_channels=data.num_node_features, hidden_channels=4, \n",
    "            out_channels=len(torch.unique(data.y))).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.NLLLoss().to(device)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Train for 200 epochs\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Model evaluation\n",
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)\n",
    "print(\"Predicted classes:\", pred.tolist())\n",
    "\n",
    "# Initialize the Explainer with the GNNExplainer algorithm\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(num_epochs=200),\n",
    "    explanation_type='model',\n",
    "    model_config=model_config,\n",
    "    node_mask_type='object',\n",
    "    edge_mask_type='object'\n",
    ")\n",
    "\n",
    "# Explain the prediction for a specific node (e.g., node 2)\n",
    "node_idx = 2\n",
    "explanation = explainer(data.x, data.edge_index, index=node_idx)\n",
    "\n",
    "# Visualize the explanation\n",
    "fig, ax = explanation.visualize_graph()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
